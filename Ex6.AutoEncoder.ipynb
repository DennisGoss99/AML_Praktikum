{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91c76ea3",
   "metadata": {},
   "source": [
    "<img src=\"https://www.th-koeln.de/img/logo.svg\" style=\"float:right;\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9505dc0",
   "metadata": {},
   "source": [
    "# 6th exercise: <font color=\"#C70039\">Work with Autoencoders for anomaly detection</font>\n",
    "* Course: AML\n",
    "* Lecturer: <a href=\"https://www.gernotheisenberg.de/\">Gernot Heisenberg</a>\n",
    "* Author of notebook: <a href=\"https://www.gernotheisenberg.de/\">Gernot Heisenberg</a>\n",
    "* Date:   08.08.2023\n",
    "\n",
    "<img src=\"https://blog.keras.io/img/ae/autoencoder_schema.jpg\" style=\"float: center;\" width=\"700\">\n",
    "\n",
    "---------------------------------\n",
    "**GENERAL NOTE 1**: \n",
    "Please make sure you are reading the entire notebook, since it contains a lot of information on your tasks (e.g. regarding the set of certain paramaters or a specific computational trick), and the written mark downs as well as comments contain a lot of information on how things work together as a whole. \n",
    "\n",
    "**GENERAL NOTE 2**: \n",
    "* Please, when commenting source code, just use English language only. \n",
    "* When describing an observation please use English language, too.\n",
    "* This applies to all exercises throughout this course.\n",
    "\n",
    "---------------------------------\n",
    "\n",
    "### <font color=\"ce33ff\">DESCRIPTION</font>:\n",
    "Autoencoder is an unsupervised artificial neural network (ANN) that learns how to efficiently compress and encode data and then learns how to reconstruct the data back from the reduced encoded representation to a representation that is as close to the original input as possible.\n",
    "\n",
    "An Autoencoder reduces data dimensions by learning how to ignore the noise in the data and thus outliers.\n",
    "In the section above, you can seen an example of the input/output image from the MNIST dataset to an Autoencoder.\n",
    "\n",
    "#### Autoencoder Components:\n",
    "An Autoencoder consists of four main parts:\n",
    "\n",
    "1. Encoder: In which the model learns how to reduce the input dimensions and compress the input data into an encoded representation.\n",
    "\n",
    "2. Bottleneck: which is the layer that contains the compressed representation of the input data. This is the lowest possible dimensions of the input data. The bottlneck is also called latent vector. The concept of the latent space and latent vectors becomes important later on as we move forward to understand Generative Models. \n",
    "\n",
    "3. Decoder: In which the model learns how to reconstruct the data from the encoded representation to be as close to the original input as possible.\n",
    "\n",
    "4. Reconstruction Loss: This is the method that measures how well the decoder is performing and how close the output is to the original input.\n",
    "\n",
    "As always in ANNs, the training itself involves back propagation in order to minimize the network’s reconstruction loss.\n",
    "\n",
    "Due to this features of an Autoencoder the use cases are manyfold. One of the obviously is anomaly detection. \n",
    "\n",
    "#### Autoencoder Architecture:\n",
    "\n",
    "The network architecture for Autoencoders can vary between simple Feed Forward networks, Recurrent Neural Networks (LSTM) or Convolutional Neural Networks (CNN) depending on the use case. \n",
    "\n",
    "---------------------------------\n",
    "\n",
    "### <font color=\"FFC300\">TASKS</font>:\n",
    "The tasks that you need to work on within this notebook are always indicated below as bullet points. \n",
    "If a task is more challenging and consists of several steps, this is indicated as well. \n",
    "Make sure you have worked down the task list and commented your doings. \n",
    "This should be done by using markdown.<br> \n",
    "<font color=red>Make sure you don't forget to specify your name and your matriculation number in the notebook.</font>\n",
    "\n",
    "**YOUR TASKS in this exercise are as follows**:\n",
    "1. import the notebook to Google Colab or use your local machine.\n",
    "2. make sure you specified you name and your matriculation number in the header below my name and date. \n",
    "    * set the date too and remove mine.\n",
    "3. read the entire notebook carefully \n",
    "    * add comments whereever you feel it necessary for better understanding\n",
    "    * run the notebook for the first time.\n",
    "    * the example below shows how to use an autoencoder for anomaly detection\n",
    "\n",
    "4. <font color=green>Develop an Autoencoder for Domain Adaptation (Me -> Walter White ). You can of course also take own data, e.g. a photo of yours and someone else.</font>\n",
    "5. Set at least the following hyperparameters for training (epochs=100000, shuffle=True).\n",
    "6. Implement a CNN for working out important features for the adaptation. If you feel lost in the exercise, please visit the sample solution.\n",
    "7. There is also an implementation of data augmentation that helps you building up your data set from one single \"original\" image. \n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8ff998",
   "metadata": {},
   "source": [
    "### Auto-Encoding\n",
    "If you have correlated input data, the auto-encoder method will work very well because the encoding operation relies on the correlated features to compress the data.\n",
    "Let’s consider that an auto-encoder is trained on the MNIST dataset. \n",
    "As you know already, using a simple FeedForward neural network, this can be done by building a simple 6 layers network as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f2c0a59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "(60000, 28, 28)\n",
      "Epoch 1/10\n",
      "10/59 [====>.........................] - ETA: 0s - loss: 0.1452"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Dennis\\Desktop\\Pro\\AML_Praktikum\\Ex6.AutoEncoder.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Dennis/Desktop/Pro/AML_Praktikum/Ex6.AutoEncoder.ipynb#W3sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# train the model and finally assign the encoding to the decoder\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Dennis/Desktop/Pro/AML_Praktikum/Ex6.AutoEncoder.ipynb#W3sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Dennis/Desktop/Pro/AML_Praktikum/Ex6.AutoEncoder.ipynb#W3sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mNOTE:\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Dennis/Desktop/Pro/AML_Praktikum/Ex6.AutoEncoder.ipynb#W3sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m-----\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Dennis/Desktop/Pro/AML_Praktikum/Ex6.AutoEncoder.ipynb#W3sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39mmake sure you understand, that you are training on train_x and not on train_y but train_x again for the reconstruction\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Dennis/Desktop/Pro/AML_Praktikum/Ex6.AutoEncoder.ipynb#W3sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39mthe same for the validation (val_x, val_x)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Dennis/Desktop/Pro/AML_Praktikum/Ex6.AutoEncoder.ipynb#W3sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Dennis/Desktop/Pro/AML_Praktikum/Ex6.AutoEncoder.ipynb#W3sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m trained_model \u001b[39m=\u001b[39m autoencoder\u001b[39m.\u001b[39;49mfit(train_x, train_x, batch_size\u001b[39m=\u001b[39;49m\u001b[39m1024\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(val_x, val_x))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Dennis/Desktop/Pro/AML_Praktikum/Ex6.AutoEncoder.ipynb#W3sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m encoder \u001b[39m=\u001b[39m Model(autoencoder\u001b[39m.\u001b[39minput, autoencoder\u001b[39m.\u001b[39mget_layer(\u001b[39m'\u001b[39m\u001b[39mbottleneck\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39moutput)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Dennis/Desktop/Pro/AML_Praktikum/Ex6.AutoEncoder.ipynb#W3sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m encoded_data \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39mpredict(train_x)  \u001b[39m# bottleneck representation\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    200\u001b[0m     )\n\u001b[0;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1463\u001b[0m   )\n\u001b[0;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from   keras.datasets import mnist\n",
    "from   keras.models import Sequential, Model\n",
    "from   keras.layers import Dense, Input\n",
    "from   keras import optimizers\n",
    "from   keras.optimizers import Adam\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# load the inbuild mnist data set (8bit grayscale digits)\n",
    "# https://en.wikipedia.org/wiki/MNIST_database\n",
    "\n",
    "zebra_images = [...]\n",
    "horse_images = [...]\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(x_train.shape)\n",
    "# normalize the training and the validation data set\n",
    "train_x = x_train.reshape(60000, 784) / 255\n",
    "val_x = x_test.reshape(10000, 784) / 255\n",
    "\n",
    "# build the auto-encoding layers\n",
    "autoencoder = Sequential()\n",
    "autoencoder.add(Dense(512,  activation='elu', input_shape=(784,)))\n",
    "autoencoder.add(Dense(128,  activation='elu'))\n",
    "autoencoder.add(Dense(10,   activation='linear', name=\"bottleneck\"))\n",
    "autoencoder.add(Dense(128,  activation='elu'))\n",
    "autoencoder.add(Dense(512,  activation='elu'))\n",
    "autoencoder.add(Dense(784,  activation='sigmoid'))\n",
    "autoencoder.compile(loss='mean_squared_error', optimizer = Adam())\n",
    "\n",
    "'''\n",
    "NOTE:\n",
    "-----\n",
    "The Exponential Linear Unit (ELU) is an activation function for neural networks. \n",
    "In contrast to ReLUs (which you know), ELUs have negative values which allows them to push mean unit \n",
    "activations closer to zero like batch normalization but with lower computational complexity.\n",
    "'''    \n",
    "\n",
    "# train the model and finally assign the encoding to the decoder\n",
    "'''\n",
    "NOTE:\n",
    "-----\n",
    "make sure you understand, that you are training on train_x and not on train_y but train_x again for the reconstruction\n",
    "the same for the validation (val_x, val_x)\n",
    "'''\n",
    "trained_model = autoencoder.fit(train_x, train_x, batch_size=1024, epochs=10, verbose=1, validation_data=(val_x, val_x))\n",
    "encoder = Model(autoencoder.input, autoencoder.get_layer('bottleneck').output)\n",
    "\n",
    "encoded_data = encoder.predict(train_x)  # bottleneck representation\n",
    "\n",
    "decoded_output = autoencoder.predict(train_x)        # reconstruction\n",
    "encoding_dim = 10\n",
    "\n",
    "# return the decoder\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder = autoencoder.layers[-3](encoded_input)\n",
    "decoder = autoencoder.layers[-2](decoder)\n",
    "decoder = autoencoder.layers[-1](decoder)\n",
    "decoder = Model(encoded_input, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "730d8f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Wählen Sie ein zufälliges Encoding aus, das Sie visualisieren möchten\n",
    "random_index = np.random.randint(len(encoded_data))\n",
    "sample_encoding = encoded_data[random_index].reshape(1, -1)\n",
    "\n",
    "# Verwenden Sie das Decoder-Modell, um das Bild zu rekonstruieren\n",
    "reconstructed_image = decoder.predict(sample_encoding)\n",
    "\n",
    "print\n",
    "# Bringen Sie das Bild in die ursprüngliche Form (28x28 Pixel)\n",
    "reconstructed_image = reconstructed_image.reshape(28, 28)\n",
    "\n",
    "# Visualisieren Sie das rekonstruierte Bild\n",
    "plt.imshow(reconstructed_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8b39fb",
   "metadata": {},
   "source": [
    "As you can see in the output, the last reconstruction loss/error for the validation set is approx. 0.0197, which is great. \n",
    "Now, if we pass any normal image from the MNIST dataset, the reconstruction loss will be very low (< 0.02) BUT if we tried to pass any other different image (outlier / anomaly), we will get a high reconstruction loss value because the network failed to reconstruct the image/input that is considered an anomaly.\n",
    "\n",
    "Notice in the code above, you can use only the encoder part to compress some data or images and you can also only use the decoder part to decompress the data by loading the decoder layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf39053",
   "metadata": {},
   "source": [
    "#### Auto-Encoders for Anomaly Detection\n",
    "Now, let’s do some anomaly detection. The code below uses two different images to predict the anomaly score (reconstruction error) using the autoencoder network we trained above. \n",
    "\n",
    "The first image is from the MNIST and the result is error=2.46241018. This means that the image is not an anomaly. The second image (yoda.png) obviously does not belong to the training dataset and the result is: error=2727.0718. This high error means that the image is an anomaly. Even the third image. The same concept applies to any type of dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da9e8232",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "[2.59666646]\n"
     ]
    }
   ],
   "source": [
    "# If you are using a newer version of keras than '2.4.3', read this article below.\n",
    "# It describes a versioning issue in the keras libs\n",
    "'''https://stackoverflow.com/questions/72383347/how-to-fix-it-attributeerror-module-keras-preprocessing-image-has-no-attribu'''\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# take an image from the validation data set or the training data set, respectively\n",
    "input_img = val_x[50] \n",
    "input_img_flat = input_img.reshape(1,784)\n",
    "\n",
    "target_data = autoencoder.predict(input_img_flat)\n",
    "\n",
    "dist = np.linalg.norm(input_img_flat - target_data, axis=-1)\n",
    "\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccafc75d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 9ms/step\n",
      "[2727.437]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Now take Master Yoda as the test image. The error score will be very high (error=2727.0718)\n",
    "img = load_img(\"./data/yoda.png\", target_size=(28, 28), color_mode = \"grayscale\")\n",
    "input_img = img_to_array(img)\n",
    "\n",
    "input_img_flat = input_img.reshape(1,784)\n",
    "target_data = autoencoder.predict(input_img_flat)\n",
    "dist = np.linalg.norm(input_img_flat - target_data, axis=-1)\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b553f742",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 9ms/step\n",
      "[2551.8088]\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "Now take a Mnist image which is taken from the google image search and although it is super similar to the training data\n",
    "it does not belong to the same data distribution the auto-encoder was trained on. \n",
    "It produces an error almost as high as yoda.png (approx error=2551.99)\n",
    "This makes autoencoders being a very robust technique for anomaly detection.\n",
    "'''\n",
    "img = load_img(\"./data/similarMnistNumber.jpg\", target_size=(28, 28), color_mode = \"grayscale\")\n",
    "input_img = img_to_array(img)\n",
    "\n",
    "input_img_flat = input_img.reshape(1,784)\n",
    "target_data = autoencoder.predict(input_img_flat)\n",
    "dist = np.linalg.norm(input_img_flat - target_data, axis=-1)\n",
    "\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5de01c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Epoch 1/3000\n",
      "1/1 [==============================] - 1s 805ms/step - loss: 0.1104 - val_loss: 0.1232\n",
      "Epoch 2/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1175 - val_loss: 0.1163\n",
      "Epoch 3/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1100 - val_loss: 0.1169\n",
      "Epoch 4/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1106 - val_loss: 0.0984\n",
      "Epoch 5/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0934 - val_loss: 0.1929\n",
      "Epoch 6/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1536 - val_loss: 0.0998\n",
      "Epoch 7/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0961 - val_loss: 0.1013\n",
      "Epoch 8/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0932 - val_loss: 0.0864\n",
      "Epoch 9/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0836 - val_loss: 0.0830\n",
      "Epoch 10/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0816 - val_loss: 0.0788\n",
      "Epoch 11/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0753 - val_loss: 0.0830\n",
      "Epoch 12/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0831 - val_loss: 0.0913\n",
      "Epoch 13/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0825 - val_loss: 0.0976\n",
      "Epoch 14/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0833 - val_loss: 0.0908\n",
      "Epoch 15/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0768 - val_loss: 0.0834\n",
      "Epoch 16/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0759 - val_loss: 0.0795\n",
      "Epoch 17/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0744 - val_loss: 0.0789\n",
      "Epoch 18/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0736 - val_loss: 0.0787\n",
      "Epoch 19/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0727 - val_loss: 0.0801\n",
      "Epoch 20/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0724 - val_loss: 0.0787\n",
      "Epoch 21/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0703 - val_loss: 0.0763\n",
      "Epoch 22/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0693 - val_loss: 0.0757\n",
      "Epoch 23/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0695 - val_loss: 0.0744\n",
      "Epoch 24/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0682 - val_loss: 0.0742\n",
      "Epoch 25/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0687 - val_loss: 0.0790\n",
      "Epoch 26/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0698 - val_loss: 0.0765\n",
      "Epoch 27/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0705 - val_loss: 0.0761\n",
      "Epoch 28/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0680 - val_loss: 0.0771\n",
      "Epoch 29/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0669 - val_loss: 0.0765\n",
      "Epoch 30/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0666 - val_loss: 0.0740\n",
      "Epoch 31/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0654 - val_loss: 0.0726\n",
      "Epoch 32/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0641 - val_loss: 0.0716\n",
      "Epoch 33/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0617 - val_loss: 0.0692\n",
      "Epoch 34/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0603 - val_loss: 0.0686\n",
      "Epoch 35/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0626 - val_loss: 0.0768\n",
      "Epoch 36/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0672 - val_loss: 0.0764\n",
      "Epoch 37/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0637 - val_loss: 0.0749\n",
      "Epoch 38/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0620 - val_loss: 0.0765\n",
      "Epoch 39/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0606 - val_loss: 0.0719\n",
      "Epoch 40/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0601 - val_loss: 0.0693\n",
      "Epoch 41/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0577 - val_loss: 0.0682\n",
      "Epoch 42/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0572 - val_loss: 0.0659\n",
      "Epoch 43/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0563 - val_loss: 0.0655\n",
      "Epoch 44/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0558 - val_loss: 0.0662\n",
      "Epoch 45/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0549 - val_loss: 0.0662\n",
      "Epoch 46/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0535 - val_loss: 0.0666\n",
      "Epoch 47/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0531 - val_loss: 0.0657\n",
      "Epoch 48/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0525 - val_loss: 0.0647\n",
      "Epoch 49/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0518 - val_loss: 0.0636\n",
      "Epoch 50/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0512 - val_loss: 0.0629\n",
      "Epoch 51/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0504 - val_loss: 0.0625\n",
      "Epoch 52/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0496 - val_loss: 0.0624\n",
      "Epoch 53/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0487 - val_loss: 0.0621\n",
      "Epoch 54/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0478 - val_loss: 0.0607\n",
      "Epoch 55/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0469 - val_loss: 0.0601\n",
      "Epoch 56/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0462 - val_loss: 0.0605\n",
      "Epoch 57/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0451 - val_loss: 0.0598\n",
      "Epoch 58/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0446 - val_loss: 0.0607\n",
      "Epoch 59/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0439 - val_loss: 0.0604\n",
      "Epoch 60/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0435 - val_loss: 0.0650\n",
      "Epoch 61/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0443 - val_loss: 0.0603\n",
      "Epoch 62/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0422 - val_loss: 0.0605\n",
      "Epoch 63/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0421 - val_loss: 0.0631\n",
      "Epoch 64/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0437 - val_loss: 0.0641\n",
      "Epoch 65/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0412 - val_loss: 0.0601\n",
      "Epoch 66/3000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0398 - val_loss: 0.0595\n",
      "Epoch 67/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0388 - val_loss: 0.0593\n",
      "Epoch 68/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0380 - val_loss: 0.0605\n",
      "Epoch 69/3000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0373 - val_loss: 0.0596\n",
      "Epoch 70/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0358 - val_loss: 0.0592\n",
      "Epoch 71/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0359 - val_loss: 0.0583\n",
      "Epoch 72/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0341 - val_loss: 0.0596\n",
      "Epoch 73/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0340 - val_loss: 0.0601\n",
      "Epoch 74/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0331 - val_loss: 0.0588\n",
      "Epoch 75/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0322 - val_loss: 0.0585\n",
      "Epoch 76/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0314 - val_loss: 0.0595\n",
      "Epoch 77/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0306 - val_loss: 0.0587\n",
      "Epoch 78/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0297 - val_loss: 0.0570\n",
      "Epoch 79/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0289 - val_loss: 0.0573\n",
      "Epoch 80/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0280 - val_loss: 0.0588\n",
      "Epoch 81/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0274 - val_loss: 0.0579\n",
      "Epoch 82/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0266 - val_loss: 0.0577\n",
      "Epoch 83/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0262 - val_loss: 0.0595\n",
      "Epoch 84/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0268 - val_loss: 0.0657\n",
      "Epoch 85/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0328 - val_loss: 0.0689\n",
      "Epoch 86/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0366 - val_loss: 0.0609\n",
      "Epoch 87/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0294 - val_loss: 0.0654\n",
      "Epoch 88/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0312 - val_loss: 0.0614\n",
      "Epoch 89/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0275 - val_loss: 0.0587\n",
      "Epoch 90/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0260 - val_loss: 0.0580\n",
      "Epoch 91/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0259 - val_loss: 0.0564\n",
      "Epoch 92/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0243 - val_loss: 0.0561\n",
      "Epoch 93/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0235 - val_loss: 0.0561\n",
      "Epoch 94/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0228 - val_loss: 0.0561\n",
      "Epoch 95/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0215 - val_loss: 0.0564\n",
      "Epoch 96/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0209 - val_loss: 0.0575\n",
      "Epoch 97/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0204 - val_loss: 0.0572\n",
      "Epoch 98/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0193 - val_loss: 0.0576\n",
      "Epoch 99/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0188 - val_loss: 0.0575\n",
      "Epoch 100/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0180 - val_loss: 0.0575\n",
      "Epoch 101/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0174 - val_loss: 0.0575\n",
      "Epoch 102/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0169 - val_loss: 0.0581\n",
      "Epoch 103/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0163 - val_loss: 0.0590\n",
      "Epoch 104/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0157 - val_loss: 0.0602\n",
      "Epoch 105/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0152 - val_loss: 0.0599\n",
      "Epoch 106/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0146 - val_loss: 0.0601\n",
      "Epoch 107/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0141 - val_loss: 0.0605\n",
      "Epoch 108/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0136 - val_loss: 0.0600\n",
      "Epoch 109/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0132 - val_loss: 0.0594\n",
      "Epoch 110/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0127 - val_loss: 0.0593\n",
      "Epoch 111/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0122 - val_loss: 0.0607\n",
      "Epoch 112/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0118 - val_loss: 0.0614\n",
      "Epoch 113/3000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0114 - val_loss: 0.0613\n",
      "Epoch 114/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0110 - val_loss: 0.0616\n",
      "Epoch 115/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0107 - val_loss: 0.0616\n",
      "Epoch 116/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0103 - val_loss: 0.0621\n",
      "Epoch 117/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0099 - val_loss: 0.0619\n",
      "Epoch 118/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0097 - val_loss: 0.0634\n",
      "Epoch 119/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0096 - val_loss: 0.0633\n",
      "Epoch 120/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0098 - val_loss: 0.0662\n",
      "Epoch 121/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0107 - val_loss: 0.0654\n",
      "Epoch 122/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0129 - val_loss: 0.0674\n",
      "Epoch 123/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0113 - val_loss: 0.0636\n",
      "Epoch 124/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0085 - val_loss: 0.0637\n",
      "Epoch 125/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0098 - val_loss: 0.0652\n",
      "Epoch 126/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0081 - val_loss: 0.0671\n",
      "Epoch 127/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0089 - val_loss: 0.0659\n",
      "Epoch 128/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0079 - val_loss: 0.0659\n",
      "Epoch 129/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0077 - val_loss: 0.0660\n",
      "Epoch 130/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0072 - val_loss: 0.0654\n",
      "Epoch 131/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0072 - val_loss: 0.0644\n",
      "Epoch 132/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0065 - val_loss: 0.0658\n",
      "Epoch 133/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0066 - val_loss: 0.0662\n",
      "Epoch 134/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0061 - val_loss: 0.0664\n",
      "Epoch 135/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0060 - val_loss: 0.0656\n",
      "Epoch 136/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0056 - val_loss: 0.0656\n",
      "Epoch 137/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0055 - val_loss: 0.0661\n",
      "Epoch 138/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0052 - val_loss: 0.0668\n",
      "Epoch 139/3000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0051 - val_loss: 0.0674\n",
      "Epoch 140/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0048 - val_loss: 0.0676\n",
      "Epoch 141/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0047 - val_loss: 0.0673\n",
      "Epoch 142/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0045 - val_loss: 0.0674\n",
      "Epoch 143/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0043 - val_loss: 0.0681\n",
      "Epoch 144/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0042 - val_loss: 0.0685\n",
      "Epoch 145/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0040 - val_loss: 0.0685\n",
      "Epoch 146/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0038 - val_loss: 0.0686\n",
      "Epoch 147/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0037 - val_loss: 0.0687\n",
      "Epoch 148/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0036 - val_loss: 0.0688\n",
      "Epoch 149/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0034 - val_loss: 0.0690\n",
      "Epoch 150/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0033 - val_loss: 0.0695\n",
      "Epoch 151/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0032 - val_loss: 0.0696\n",
      "Epoch 152/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0031 - val_loss: 0.0692\n",
      "Epoch 153/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0030 - val_loss: 0.0691\n",
      "Epoch 154/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0029 - val_loss: 0.0696\n",
      "Epoch 155/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0028 - val_loss: 0.0700\n",
      "Epoch 156/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0027 - val_loss: 0.0700\n",
      "Epoch 157/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0026 - val_loss: 0.0700\n",
      "Epoch 158/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0025 - val_loss: 0.0701\n",
      "Epoch 159/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0024 - val_loss: 0.0701\n",
      "Epoch 160/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0023 - val_loss: 0.0701\n",
      "Epoch 161/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0022 - val_loss: 0.0702\n",
      "Epoch 162/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0021 - val_loss: 0.0703\n",
      "Epoch 163/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0021 - val_loss: 0.0703\n",
      "Epoch 164/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0020 - val_loss: 0.0704\n",
      "Epoch 165/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0019 - val_loss: 0.0705\n",
      "Epoch 166/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0019 - val_loss: 0.0705\n",
      "Epoch 167/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0018 - val_loss: 0.0705\n",
      "Epoch 168/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0017 - val_loss: 0.0706\n",
      "Epoch 169/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0017 - val_loss: 0.0706\n",
      "Epoch 170/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0016 - val_loss: 0.0707\n",
      "Epoch 171/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0016 - val_loss: 0.0709\n",
      "Epoch 172/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0015 - val_loss: 0.0709\n",
      "Epoch 173/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0015 - val_loss: 0.0709\n",
      "Epoch 174/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0014 - val_loss: 0.0709\n",
      "Epoch 175/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0014 - val_loss: 0.0710\n",
      "Epoch 176/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0013 - val_loss: 0.0710\n",
      "Epoch 177/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0013 - val_loss: 0.0711\n",
      "Epoch 178/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0012 - val_loss: 0.0712\n",
      "Epoch 179/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0012 - val_loss: 0.0711\n",
      "Epoch 180/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0012 - val_loss: 0.0711\n",
      "Epoch 181/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0011 - val_loss: 0.0712\n",
      "Epoch 182/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0011 - val_loss: 0.0713\n",
      "Epoch 183/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0011 - val_loss: 0.0713\n",
      "Epoch 184/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0010 - val_loss: 0.0713\n",
      "Epoch 185/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 9.9068e-04 - val_loss: 0.0712\n",
      "Epoch 186/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 9.6248e-04 - val_loss: 0.0713\n",
      "Epoch 187/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 9.3680e-04 - val_loss: 0.0714\n",
      "Epoch 188/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 9.1488e-04 - val_loss: 0.0714\n",
      "Epoch 189/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 9.0020e-04 - val_loss: 0.0714\n",
      "Epoch 190/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 8.9633e-04 - val_loss: 0.0715\n",
      "Epoch 191/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 9.1555e-04 - val_loss: 0.0715\n",
      "Epoch 192/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 9.6908e-04 - val_loss: 0.0717\n",
      "Epoch 193/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0011 - val_loss: 0.0718\n",
      "Epoch 194/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0014 - val_loss: 0.0723\n",
      "Epoch 195/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0020 - val_loss: 0.0731\n",
      "Epoch 196/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0033 - val_loss: 0.0749\n",
      "Epoch 197/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0082 - val_loss: 0.0792\n",
      "Epoch 198/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0194 - val_loss: 0.0787\n",
      "Epoch 199/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0170 - val_loss: 0.0868\n",
      "Epoch 200/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0364 - val_loss: 0.0850\n",
      "Epoch 201/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0284 - val_loss: 0.0877\n",
      "Epoch 202/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0394 - val_loss: 0.0849\n",
      "Epoch 203/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0359 - val_loss: 0.0802\n",
      "Epoch 204/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0279 - val_loss: 0.0812\n",
      "Epoch 205/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0413 - val_loss: 0.0782\n",
      "Epoch 206/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0261 - val_loss: 0.0835\n",
      "Epoch 207/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0288 - val_loss: 0.0825\n",
      "Epoch 208/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0240 - val_loss: 0.0806\n",
      "Epoch 209/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0209 - val_loss: 0.0786\n",
      "Epoch 210/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0194 - val_loss: 0.0742\n",
      "Epoch 211/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0172 - val_loss: 0.0712\n",
      "Epoch 212/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0154 - val_loss: 0.0707\n",
      "Epoch 213/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0149 - val_loss: 0.0700\n",
      "Epoch 214/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0122 - val_loss: 0.0696\n",
      "Epoch 215/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0118 - val_loss: 0.0701\n",
      "Epoch 216/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0109 - val_loss: 0.0698\n",
      "Epoch 217/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0094 - val_loss: 0.0691\n",
      "Epoch 218/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0086 - val_loss: 0.0695\n",
      "Epoch 219/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0080 - val_loss: 0.0701\n",
      "Epoch 220/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0069 - val_loss: 0.0713\n",
      "Epoch 221/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0067 - val_loss: 0.0719\n",
      "Epoch 222/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0063 - val_loss: 0.0715\n",
      "Epoch 223/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0053 - val_loss: 0.0711\n",
      "Epoch 224/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0049 - val_loss: 0.0708\n",
      "Epoch 225/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0046 - val_loss: 0.0711\n",
      "Epoch 226/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0042 - val_loss: 0.0717\n",
      "Epoch 227/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0039 - val_loss: 0.0717\n",
      "Epoch 228/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0036 - val_loss: 0.0711\n",
      "Epoch 229/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0032 - val_loss: 0.0709\n",
      "Epoch 230/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0030 - val_loss: 0.0715\n",
      "Epoch 231/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0028 - val_loss: 0.0727\n",
      "Epoch 232/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0026 - val_loss: 0.0738\n",
      "Epoch 233/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0023 - val_loss: 0.0742\n",
      "Epoch 234/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0022 - val_loss: 0.0737\n",
      "Epoch 235/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0020 - val_loss: 0.0731\n",
      "Epoch 236/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0019 - val_loss: 0.0727\n",
      "Epoch 237/3000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0017 - val_loss: 0.0726\n",
      "Epoch 238/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0016 - val_loss: 0.0727\n",
      "Epoch 239/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0015 - val_loss: 0.0727\n",
      "Epoch 240/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0014 - val_loss: 0.0726\n",
      "Epoch 241/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0013 - val_loss: 0.0725\n",
      "Epoch 242/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0012 - val_loss: 0.0725\n",
      "Epoch 243/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0011 - val_loss: 0.0726\n",
      "Epoch 244/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0011 - val_loss: 0.0725\n",
      "Epoch 245/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0010 - val_loss: 0.0724\n",
      "Epoch 246/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 9.5552e-04 - val_loss: 0.0722\n",
      "Epoch 247/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 8.8485e-04 - val_loss: 0.0721\n",
      "Epoch 248/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 8.4005e-04 - val_loss: 0.0722\n",
      "Epoch 249/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 8.0020e-04 - val_loss: 0.0724\n",
      "Epoch 250/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 7.5154e-04 - val_loss: 0.0724\n",
      "Epoch 251/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 7.0946e-04 - val_loss: 0.0724\n",
      "Epoch 252/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 6.7732e-04 - val_loss: 0.0723\n",
      "Epoch 253/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 6.4342e-04 - val_loss: 0.0723\n",
      "Epoch 254/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 6.1031e-04 - val_loss: 0.0723\n",
      "Epoch 255/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 5.8181e-04 - val_loss: 0.0725\n",
      "Epoch 256/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 5.5637e-04 - val_loss: 0.0726\n",
      "Epoch 257/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 5.3184e-04 - val_loss: 0.0726\n",
      "Epoch 258/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 5.0571e-04 - val_loss: 0.0725\n",
      "Epoch 259/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 4.8290e-04 - val_loss: 0.0723\n",
      "Epoch 260/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 4.6448e-04 - val_loss: 0.0722\n",
      "Epoch 261/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 4.4528e-04 - val_loss: 0.0721\n",
      "Epoch 262/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 4.2857e-04 - val_loss: 0.0721\n",
      "Epoch 263/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 4.1314e-04 - val_loss: 0.0722\n",
      "Epoch 264/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.9619e-04 - val_loss: 0.0723\n",
      "Epoch 265/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 3.8236e-04 - val_loss: 0.0723\n",
      "Epoch 266/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.7005e-04 - val_loss: 0.0723\n",
      "Epoch 267/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.5640e-04 - val_loss: 0.0723\n",
      "Epoch 268/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.4386e-04 - val_loss: 0.0723\n",
      "Epoch 269/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 3.3369e-04 - val_loss: 0.0723\n",
      "Epoch 270/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.2378e-04 - val_loss: 0.0723\n",
      "Epoch 271/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.1289e-04 - val_loss: 0.0723\n",
      "Epoch 272/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 3.0341e-04 - val_loss: 0.0722\n",
      "Epoch 273/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.9549e-04 - val_loss: 0.0723\n",
      "Epoch 274/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.8675e-04 - val_loss: 0.0723\n",
      "Epoch 275/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.7831e-04 - val_loss: 0.0723\n",
      "Epoch 276/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.7115e-04 - val_loss: 0.0723\n",
      "Epoch 277/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.6389e-04 - val_loss: 0.0722\n",
      "Epoch 278/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.5697e-04 - val_loss: 0.0722\n",
      "Epoch 279/3000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 2.5075e-04 - val_loss: 0.0722\n",
      "Epoch 280/3000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 2.4451e-04 - val_loss: 0.0723\n",
      "Epoch 281/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 2.3850e-04 - val_loss: 0.0723\n",
      "Epoch 282/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 2.3293e-04 - val_loss: 0.0723\n",
      "Epoch 283/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.2739e-04 - val_loss: 0.0723\n",
      "Epoch 284/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.2227e-04 - val_loss: 0.0723\n",
      "Epoch 285/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.1742e-04 - val_loss: 0.0723\n",
      "Epoch 286/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.1239e-04 - val_loss: 0.0723\n",
      "Epoch 287/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.0785e-04 - val_loss: 0.0723\n",
      "Epoch 288/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.0361e-04 - val_loss: 0.0723\n",
      "Epoch 289/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.9922e-04 - val_loss: 0.0723\n",
      "Epoch 290/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.9509e-04 - val_loss: 0.0723\n",
      "Epoch 291/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.9116e-04 - val_loss: 0.0723\n",
      "Epoch 292/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.8732e-04 - val_loss: 0.0723\n",
      "Epoch 293/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.8366e-04 - val_loss: 0.0723\n",
      "Epoch 294/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.8009e-04 - val_loss: 0.0723\n",
      "Epoch 295/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.7661e-04 - val_loss: 0.0723\n",
      "Epoch 296/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.7324e-04 - val_loss: 0.0723\n",
      "Epoch 297/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.7004e-04 - val_loss: 0.0723\n",
      "Epoch 298/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.6690e-04 - val_loss: 0.0723\n",
      "Epoch 299/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.6380e-04 - val_loss: 0.0723\n",
      "Epoch 300/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.6086e-04 - val_loss: 0.0723\n",
      "Epoch 301/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.5799e-04 - val_loss: 0.0723\n",
      "Epoch 302/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.5517e-04 - val_loss: 0.0723\n",
      "Epoch 303/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.5248e-04 - val_loss: 0.0723\n",
      "Epoch 304/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.4983e-04 - val_loss: 0.0723\n",
      "Epoch 305/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.4722e-04 - val_loss: 0.0723\n",
      "Epoch 306/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.4473e-04 - val_loss: 0.0723\n",
      "Epoch 307/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 1.4230e-04 - val_loss: 0.0723\n",
      "Epoch 308/3000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 1.3990e-04 - val_loss: 0.0723\n",
      "Epoch 309/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 1.3758e-04 - val_loss: 0.0723\n",
      "Epoch 310/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.3531e-04 - val_loss: 0.0723\n",
      "Epoch 311/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.3310e-04 - val_loss: 0.0723\n",
      "Epoch 312/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.3094e-04 - val_loss: 0.0723\n",
      "Epoch 313/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.2884e-04 - val_loss: 0.0723\n",
      "Epoch 314/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.2678e-04 - val_loss: 0.0723\n",
      "Epoch 315/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.2476e-04 - val_loss: 0.0723\n",
      "Epoch 316/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.2280e-04 - val_loss: 0.0723\n",
      "Epoch 317/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.2088e-04 - val_loss: 0.0723\n",
      "Epoch 318/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.1900e-04 - val_loss: 0.0723\n",
      "Epoch 319/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.1716e-04 - val_loss: 0.0723\n",
      "Epoch 320/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.1536e-04 - val_loss: 0.0723\n",
      "Epoch 321/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.1360e-04 - val_loss: 0.0723\n",
      "Epoch 322/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.1188e-04 - val_loss: 0.0723\n",
      "Epoch 323/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.1019e-04 - val_loss: 0.0723\n",
      "Epoch 324/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.0854e-04 - val_loss: 0.0723\n",
      "Epoch 325/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.0692e-04 - val_loss: 0.0723\n",
      "Epoch 326/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.0534e-04 - val_loss: 0.0723\n",
      "Epoch 327/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.0378e-04 - val_loss: 0.0723\n",
      "Epoch 328/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.0226e-04 - val_loss: 0.0723\n",
      "Epoch 329/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.0077e-04 - val_loss: 0.0723\n",
      "Epoch 330/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 9.9305e-05 - val_loss: 0.0723\n",
      "Epoch 331/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 9.7870e-05 - val_loss: 0.0723\n",
      "Epoch 332/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 9.6463e-05 - val_loss: 0.0723\n",
      "Epoch 333/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 9.5084e-05 - val_loss: 0.0723\n",
      "Epoch 334/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 9.3731e-05 - val_loss: 0.0723\n",
      "Epoch 335/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 9.2403e-05 - val_loss: 0.0723\n",
      "Epoch 336/3000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 9.1101e-05 - val_loss: 0.0723\n",
      "Epoch 337/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 8.9825e-05 - val_loss: 0.0723\n",
      "Epoch 338/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 8.8571e-05 - val_loss: 0.0723\n",
      "Epoch 339/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 8.7341e-05 - val_loss: 0.0723\n",
      "Epoch 340/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 8.6135e-05 - val_loss: 0.0723\n",
      "Epoch 341/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 8.4950e-05 - val_loss: 0.0723\n",
      "Epoch 342/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 8.3787e-05 - val_loss: 0.0723\n",
      "Epoch 343/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 8.2647e-05 - val_loss: 0.0723\n",
      "Epoch 344/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 8.1527e-05 - val_loss: 0.0723\n",
      "Epoch 345/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 8.0427e-05 - val_loss: 0.0723\n",
      "Epoch 346/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 7.9347e-05 - val_loss: 0.0723\n",
      "Epoch 347/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.8286e-05 - val_loss: 0.0723\n",
      "Epoch 348/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 7.7245e-05 - val_loss: 0.0723\n",
      "Epoch 349/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 7.6222e-05 - val_loss: 0.0723\n",
      "Epoch 350/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 7.5216e-05 - val_loss: 0.0723\n",
      "Epoch 351/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 7.4229e-05 - val_loss: 0.0723\n",
      "Epoch 352/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 7.3258e-05 - val_loss: 0.0723\n",
      "Epoch 353/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 7.2304e-05 - val_loss: 0.0723\n",
      "Epoch 354/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 7.1367e-05 - val_loss: 0.0723\n",
      "Epoch 355/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 7.0445e-05 - val_loss: 0.0723\n",
      "Epoch 356/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 6.9539e-05 - val_loss: 0.0723\n",
      "Epoch 357/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 6.8649e-05 - val_loss: 0.0723\n",
      "Epoch 358/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 6.7773e-05 - val_loss: 0.0723\n",
      "Epoch 359/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 6.6911e-05 - val_loss: 0.0723\n",
      "Epoch 360/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 6.6064e-05 - val_loss: 0.0723\n",
      "Epoch 361/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 6.5231e-05 - val_loss: 0.0723\n",
      "Epoch 362/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 6.4412e-05 - val_loss: 0.0723\n",
      "Epoch 363/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 6.3606e-05 - val_loss: 0.0723\n",
      "Epoch 364/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 6.2812e-05 - val_loss: 0.0723\n",
      "Epoch 365/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 6.2032e-05 - val_loss: 0.0723\n",
      "Epoch 366/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 6.1264e-05 - val_loss: 0.0723\n",
      "Epoch 367/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 6.0509e-05 - val_loss: 0.0724\n",
      "Epoch 368/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 5.9765e-05 - val_loss: 0.0724\n",
      "Epoch 369/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 5.9033e-05 - val_loss: 0.0724\n",
      "Epoch 370/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 5.8313e-05 - val_loss: 0.0724\n",
      "Epoch 371/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 5.7604e-05 - val_loss: 0.0724\n",
      "Epoch 372/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 5.6906e-05 - val_loss: 0.0724\n",
      "Epoch 373/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 5.6219e-05 - val_loss: 0.0724\n",
      "Epoch 374/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 5.5542e-05 - val_loss: 0.0724\n",
      "Epoch 375/3000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 5.4876e-05 - val_loss: 0.0724\n",
      "Epoch 376/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 5.4220e-05 - val_loss: 0.0724\n",
      "Epoch 377/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 5.3574e-05 - val_loss: 0.0724\n",
      "Epoch 378/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 5.2939e-05 - val_loss: 0.0724\n",
      "Epoch 379/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 5.2312e-05 - val_loss: 0.0724\n",
      "Epoch 380/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 5.1696e-05 - val_loss: 0.0724\n",
      "Epoch 381/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 5.1088e-05 - val_loss: 0.0724\n",
      "Epoch 382/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 5.0490e-05 - val_loss: 0.0724\n",
      "Epoch 383/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 4.9900e-05 - val_loss: 0.0724\n",
      "Epoch 384/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 4.9320e-05 - val_loss: 0.0724\n",
      "Epoch 385/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 4.8748e-05 - val_loss: 0.0724\n",
      "Epoch 386/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 4.8184e-05 - val_loss: 0.0724\n",
      "Epoch 387/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 4.7629e-05 - val_loss: 0.0724\n",
      "Epoch 388/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 4.7082e-05 - val_loss: 0.0724\n",
      "Epoch 389/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 4.6543e-05 - val_loss: 0.0724\n",
      "Epoch 390/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 4.6012e-05 - val_loss: 0.0724\n",
      "Epoch 391/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 4.5488e-05 - val_loss: 0.0724\n",
      "Epoch 392/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 4.4972e-05 - val_loss: 0.0724\n",
      "Epoch 393/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 4.4463e-05 - val_loss: 0.0724\n",
      "Epoch 394/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 4.3962e-05 - val_loss: 0.0724\n",
      "Epoch 395/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 4.3468e-05 - val_loss: 0.0724\n",
      "Epoch 396/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 4.2981e-05 - val_loss: 0.0724\n",
      "Epoch 397/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 4.2501e-05 - val_loss: 0.0724\n",
      "Epoch 398/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 4.2027e-05 - val_loss: 0.0724\n",
      "Epoch 399/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 4.1560e-05 - val_loss: 0.0724\n",
      "Epoch 400/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 4.1100e-05 - val_loss: 0.0724\n",
      "Epoch 401/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 4.0646e-05 - val_loss: 0.0724\n",
      "Epoch 402/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 4.0198e-05 - val_loss: 0.0724\n",
      "Epoch 403/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.9757e-05 - val_loss: 0.0724\n",
      "Epoch 404/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.9321e-05 - val_loss: 0.0724\n",
      "Epoch 405/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 3.8892e-05 - val_loss: 0.0724\n",
      "Epoch 406/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 3.8469e-05 - val_loss: 0.0724\n",
      "Epoch 407/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 3.8051e-05 - val_loss: 0.0724\n",
      "Epoch 408/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 3.7639e-05 - val_loss: 0.0724\n",
      "Epoch 409/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.7233e-05 - val_loss: 0.0724\n",
      "Epoch 410/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 3.6832e-05 - val_loss: 0.0724\n",
      "Epoch 411/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.6437e-05 - val_loss: 0.0724\n",
      "Epoch 412/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.6047e-05 - val_loss: 0.0724\n",
      "Epoch 413/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 3.5662e-05 - val_loss: 0.0724\n",
      "Epoch 414/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 3.5282e-05 - val_loss: 0.0724\n",
      "Epoch 415/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 3.4908e-05 - val_loss: 0.0724\n",
      "Epoch 416/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.4539e-05 - val_loss: 0.0724\n",
      "Epoch 417/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.4174e-05 - val_loss: 0.0724\n",
      "Epoch 418/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.3815e-05 - val_loss: 0.0724\n",
      "Epoch 419/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 3.3460e-05 - val_loss: 0.0724\n",
      "Epoch 420/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 3.3110e-05 - val_loss: 0.0724\n",
      "Epoch 421/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.2765e-05 - val_loss: 0.0724\n",
      "Epoch 422/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 3.2424e-05 - val_loss: 0.0724\n",
      "Epoch 423/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.2088e-05 - val_loss: 0.0724\n",
      "Epoch 424/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.1756e-05 - val_loss: 0.0724\n",
      "Epoch 425/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 3.1428e-05 - val_loss: 0.0724\n",
      "Epoch 426/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.1105e-05 - val_loss: 0.0724\n",
      "Epoch 427/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.0786e-05 - val_loss: 0.0724\n",
      "Epoch 428/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 3.0472e-05 - val_loss: 0.0724\n",
      "Epoch 429/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 3.0161e-05 - val_loss: 0.0724\n",
      "Epoch 430/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 2.9855e-05 - val_loss: 0.0724\n",
      "Epoch 431/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 2.9552e-05 - val_loss: 0.0724\n",
      "Epoch 432/3000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 2.9254e-05 - val_loss: 0.0724\n",
      "Epoch 433/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 2.8959e-05 - val_loss: 0.0724\n",
      "Epoch 434/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.8668e-05 - val_loss: 0.0724\n",
      "Epoch 435/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.8381e-05 - val_loss: 0.0724\n",
      "Epoch 436/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.8097e-05 - val_loss: 0.0724\n",
      "Epoch 437/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.7817e-05 - val_loss: 0.0724\n",
      "Epoch 438/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.7541e-05 - val_loss: 0.0724\n",
      "Epoch 439/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.7268e-05 - val_loss: 0.0724\n",
      "Epoch 440/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.6999e-05 - val_loss: 0.0724\n",
      "Epoch 441/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.6733e-05 - val_loss: 0.0724\n",
      "Epoch 442/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.6470e-05 - val_loss: 0.0724\n",
      "Epoch 443/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.6211e-05 - val_loss: 0.0724\n",
      "Epoch 444/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.5955e-05 - val_loss: 0.0724\n",
      "Epoch 445/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 2.5702e-05 - val_loss: 0.0724\n",
      "Epoch 446/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.5452e-05 - val_loss: 0.0724\n",
      "Epoch 447/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.5205e-05 - val_loss: 0.0724\n",
      "Epoch 448/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.4961e-05 - val_loss: 0.0724\n",
      "Epoch 449/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.4721e-05 - val_loss: 0.0724\n",
      "Epoch 450/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.4483e-05 - val_loss: 0.0724\n",
      "Epoch 451/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.4248e-05 - val_loss: 0.0724\n",
      "Epoch 452/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.4016e-05 - val_loss: 0.0724\n",
      "Epoch 453/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.3787e-05 - val_loss: 0.0724\n",
      "Epoch 454/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.3560e-05 - val_loss: 0.0724\n",
      "Epoch 455/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.3336e-05 - val_loss: 0.0724\n",
      "Epoch 456/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.3115e-05 - val_loss: 0.0724\n",
      "Epoch 457/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.2897e-05 - val_loss: 0.0724\n",
      "Epoch 458/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.2681e-05 - val_loss: 0.0724\n",
      "Epoch 459/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.2468e-05 - val_loss: 0.0724\n",
      "Epoch 460/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.2257e-05 - val_loss: 0.0724\n",
      "Epoch 461/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 2.2049e-05 - val_loss: 0.0724\n",
      "Epoch 462/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 2.1844e-05 - val_loss: 0.0724\n",
      "Epoch 463/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.1641e-05 - val_loss: 0.0724\n",
      "Epoch 464/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.1440e-05 - val_loss: 0.0724\n",
      "Epoch 465/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.1242e-05 - val_loss: 0.0724\n",
      "Epoch 466/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.1046e-05 - val_loss: 0.0724\n",
      "Epoch 467/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.0853e-05 - val_loss: 0.0724\n",
      "Epoch 468/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.0661e-05 - val_loss: 0.0724\n",
      "Epoch 469/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.0473e-05 - val_loss: 0.0724\n",
      "Epoch 470/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.0286e-05 - val_loss: 0.0724\n",
      "Epoch 471/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.0101e-05 - val_loss: 0.0724\n",
      "Epoch 472/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.9919e-05 - val_loss: 0.0724\n",
      "Epoch 473/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.9739e-05 - val_loss: 0.0724\n",
      "Epoch 474/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.9561e-05 - val_loss: 0.0724\n",
      "Epoch 475/3000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 1.9385e-05 - val_loss: 0.0724\n",
      "Epoch 476/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 1.9212e-05 - val_loss: 0.0724\n",
      "Epoch 477/3000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 1.9040e-05 - val_loss: 0.0724\n",
      "Epoch 478/3000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 1.8870e-05 - val_loss: 0.0724\n",
      "Epoch 479/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1.8702e-05 - val_loss: 0.0724\n",
      "Epoch 480/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.8536e-05 - val_loss: 0.0724\n",
      "Epoch 481/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.8373e-05 - val_loss: 0.0724\n",
      "Epoch 482/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.8210e-05 - val_loss: 0.0724\n",
      "Epoch 483/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.8050e-05 - val_loss: 0.0724\n",
      "Epoch 484/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.7892e-05 - val_loss: 0.0724\n",
      "Epoch 485/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.7735e-05 - val_loss: 0.0724\n",
      "Epoch 486/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.7580e-05 - val_loss: 0.0724\n",
      "Epoch 487/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.7427e-05 - val_loss: 0.0724\n",
      "Epoch 488/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.7276e-05 - val_loss: 0.0724\n",
      "Epoch 489/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.7126e-05 - val_loss: 0.0724\n",
      "Epoch 490/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.6978e-05 - val_loss: 0.0724\n",
      "Epoch 491/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.6832e-05 - val_loss: 0.0724\n",
      "Epoch 492/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.6687e-05 - val_loss: 0.0724\n",
      "Epoch 493/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.6543e-05 - val_loss: 0.0724\n",
      "Epoch 494/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.6402e-05 - val_loss: 0.0724\n",
      "Epoch 495/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.6262e-05 - val_loss: 0.0725\n",
      "Epoch 496/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.6123e-05 - val_loss: 0.0725\n",
      "Epoch 497/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.5986e-05 - val_loss: 0.0725\n",
      "Epoch 498/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.5850e-05 - val_loss: 0.0725\n",
      "Epoch 499/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.5716e-05 - val_loss: 0.0725\n",
      "Epoch 500/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1.5583e-05 - val_loss: 0.0725\n",
      "Epoch 501/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.5451e-05 - val_loss: 0.0725\n",
      "Epoch 502/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.5321e-05 - val_loss: 0.0725\n",
      "Epoch 503/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.5193e-05 - val_loss: 0.0725\n",
      "Epoch 504/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.5065e-05 - val_loss: 0.0725\n",
      "Epoch 505/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.4940e-05 - val_loss: 0.0725\n",
      "Epoch 506/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.4815e-05 - val_loss: 0.0725\n",
      "Epoch 507/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.4692e-05 - val_loss: 0.0725\n",
      "Epoch 508/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.4570e-05 - val_loss: 0.0725\n",
      "Epoch 509/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.4449e-05 - val_loss: 0.0725\n",
      "Epoch 510/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.4329e-05 - val_loss: 0.0725\n",
      "Epoch 511/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.4211e-05 - val_loss: 0.0725\n",
      "Epoch 512/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.4094e-05 - val_loss: 0.0725\n",
      "Epoch 513/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.3978e-05 - val_loss: 0.0725\n",
      "Epoch 514/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.3864e-05 - val_loss: 0.0725\n",
      "Epoch 515/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.3750e-05 - val_loss: 0.0725\n",
      "Epoch 516/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.3638e-05 - val_loss: 0.0725\n",
      "Epoch 517/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.3527e-05 - val_loss: 0.0725\n",
      "Epoch 518/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.3417e-05 - val_loss: 0.0725\n",
      "Epoch 519/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.3308e-05 - val_loss: 0.0725\n",
      "Epoch 520/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.3200e-05 - val_loss: 0.0725\n",
      "Epoch 521/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.3093e-05 - val_loss: 0.0725\n",
      "Epoch 522/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.2988e-05 - val_loss: 0.0725\n",
      "Epoch 523/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.2883e-05 - val_loss: 0.0725\n",
      "Epoch 524/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.2780e-05 - val_loss: 0.0725\n",
      "Epoch 525/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.2677e-05 - val_loss: 0.0725\n",
      "Epoch 526/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.2576e-05 - val_loss: 0.0725\n",
      "Epoch 527/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.2475e-05 - val_loss: 0.0725\n",
      "Epoch 528/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.2376e-05 - val_loss: 0.0725\n",
      "Epoch 529/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.2277e-05 - val_loss: 0.0725\n",
      "Epoch 530/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.2180e-05 - val_loss: 0.0725\n",
      "Epoch 531/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 1.2083e-05 - val_loss: 0.0725\n",
      "Epoch 532/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 1.1988e-05 - val_loss: 0.0725\n",
      "Epoch 533/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 1.1893e-05 - val_loss: 0.0725\n",
      "Epoch 534/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 1.1800e-05 - val_loss: 0.0725\n",
      "Epoch 535/3000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 1.1707e-05 - val_loss: 0.0725\n",
      "Epoch 536/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.1615e-05 - val_loss: 0.0725\n",
      "Epoch 537/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 1.1524e-05 - val_loss: 0.0725\n",
      "Epoch 538/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.1434e-05 - val_loss: 0.0725\n",
      "Epoch 539/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.1345e-05 - val_loss: 0.0725\n",
      "Epoch 540/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.1256e-05 - val_loss: 0.0725\n",
      "Epoch 541/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.1169e-05 - val_loss: 0.0725\n",
      "Epoch 542/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.1082e-05 - val_loss: 0.0725\n",
      "Epoch 543/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.0996e-05 - val_loss: 0.0725\n",
      "Epoch 544/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.0911e-05 - val_loss: 0.0725\n",
      "Epoch 545/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.0827e-05 - val_loss: 0.0725\n",
      "Epoch 546/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.0744e-05 - val_loss: 0.0725\n",
      "Epoch 547/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.0661e-05 - val_loss: 0.0725\n",
      "Epoch 548/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.0580e-05 - val_loss: 0.0725\n",
      "Epoch 549/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.0499e-05 - val_loss: 0.0725\n",
      "Epoch 550/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.0419e-05 - val_loss: 0.0725\n",
      "Epoch 551/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.0339e-05 - val_loss: 0.0725\n",
      "Epoch 552/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.0261e-05 - val_loss: 0.0725\n",
      "Epoch 553/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.0183e-05 - val_loss: 0.0725\n",
      "Epoch 554/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 1.0106e-05 - val_loss: 0.0725\n",
      "Epoch 555/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 1.0029e-05 - val_loss: 0.0725\n",
      "Epoch 556/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 9.9537e-06 - val_loss: 0.0725\n",
      "Epoch 557/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 9.8788e-06 - val_loss: 0.0725\n",
      "Epoch 558/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 9.8046e-06 - val_loss: 0.0725\n",
      "Epoch 559/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 9.7312e-06 - val_loss: 0.0725\n",
      "Epoch 560/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 9.6584e-06 - val_loss: 0.0725\n",
      "Epoch 561/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 9.5863e-06 - val_loss: 0.0725\n",
      "Epoch 562/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 9.5150e-06 - val_loss: 0.0725\n",
      "Epoch 563/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 9.4443e-06 - val_loss: 0.0725\n",
      "Epoch 564/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 9.3743e-06 - val_loss: 0.0725\n",
      "Epoch 565/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 9.3049e-06 - val_loss: 0.0725\n",
      "Epoch 566/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 9.2362e-06 - val_loss: 0.0725\n",
      "Epoch 567/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 9.1681e-06 - val_loss: 0.0725\n",
      "Epoch 568/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 9.1007e-06 - val_loss: 0.0725\n",
      "Epoch 569/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 9.0339e-06 - val_loss: 0.0725\n",
      "Epoch 570/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 8.9678e-06 - val_loss: 0.0725\n",
      "Epoch 571/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 8.9022e-06 - val_loss: 0.0725\n",
      "Epoch 572/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 8.8373e-06 - val_loss: 0.0725\n",
      "Epoch 573/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 8.7729e-06 - val_loss: 0.0725\n",
      "Epoch 574/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 8.7091e-06 - val_loss: 0.0725\n",
      "Epoch 575/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 8.6460e-06 - val_loss: 0.0725\n",
      "Epoch 576/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 8.5834e-06 - val_loss: 0.0725\n",
      "Epoch 577/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 8.5213e-06 - val_loss: 0.0725\n",
      "Epoch 578/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 8.4598e-06 - val_loss: 0.0725\n",
      "Epoch 579/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 8.3989e-06 - val_loss: 0.0725\n",
      "Epoch 580/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 8.3385e-06 - val_loss: 0.0725\n",
      "Epoch 581/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 8.2787e-06 - val_loss: 0.0725\n",
      "Epoch 582/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 8.2194e-06 - val_loss: 0.0725\n",
      "Epoch 583/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 8.1606e-06 - val_loss: 0.0725\n",
      "Epoch 584/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 8.1023e-06 - val_loss: 0.0725\n",
      "Epoch 585/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 8.0446e-06 - val_loss: 0.0725\n",
      "Epoch 586/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 7.9873e-06 - val_loss: 0.0725\n",
      "Epoch 587/3000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 7.9306e-06 - val_loss: 0.0725\n",
      "Epoch 588/3000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 7.8743e-06 - val_loss: 0.0725\n",
      "Epoch 589/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 7.8186e-06 - val_loss: 0.0725\n",
      "Epoch 590/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 7.7633e-06 - val_loss: 0.0725\n",
      "Epoch 591/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 7.7085e-06 - val_loss: 0.0725\n",
      "Epoch 592/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 7.6542e-06 - val_loss: 0.0725\n",
      "Epoch 593/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 7.6003e-06 - val_loss: 0.0725\n",
      "Epoch 594/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 7.5469e-06 - val_loss: 0.0725\n",
      "Epoch 595/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 7.4939e-06 - val_loss: 0.0725\n",
      "Epoch 596/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 7.4414e-06 - val_loss: 0.0725\n",
      "Epoch 597/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 7.3894e-06 - val_loss: 0.0725\n",
      "Epoch 598/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.3377e-06 - val_loss: 0.0725\n",
      "Epoch 599/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.2866e-06 - val_loss: 0.0725\n",
      "Epoch 600/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 7.2358e-06 - val_loss: 0.0725\n",
      "Epoch 601/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.1855e-06 - val_loss: 0.0725\n",
      "Epoch 602/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 7.1356e-06 - val_loss: 0.0725\n",
      "Epoch 603/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 7.0861e-06 - val_loss: 0.0725\n",
      "Epoch 604/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 7.0370e-06 - val_loss: 0.0725\n",
      "Epoch 605/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 6.9883e-06 - val_loss: 0.0725\n",
      "Epoch 606/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 6.9401e-06 - val_loss: 0.0725\n",
      "Epoch 607/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 6.8922e-06 - val_loss: 0.0725\n",
      "Epoch 608/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 6.8447e-06 - val_loss: 0.0725\n",
      "Epoch 609/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 6.7976e-06 - val_loss: 0.0725\n",
      "Epoch 610/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 6.7509e-06 - val_loss: 0.0725\n",
      "Epoch 611/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 6.7046e-06 - val_loss: 0.0725\n",
      "Epoch 612/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 6.6587e-06 - val_loss: 0.0725\n",
      "Epoch 613/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 6.6131e-06 - val_loss: 0.0725\n",
      "Epoch 614/3000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 6.5679e-06 - val_loss: 0.0725\n",
      "Epoch 615/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 6.5231e-06 - val_loss: 0.0725\n",
      "Epoch 616/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 6.4786e-06 - val_loss: 0.0725\n",
      "Epoch 617/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 6.4345e-06 - val_loss: 0.0725\n",
      "Epoch 618/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 6.3908e-06 - val_loss: 0.0725\n",
      "Epoch 619/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 6.3474e-06 - val_loss: 0.0725\n",
      "Epoch 620/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 6.3044e-06 - val_loss: 0.0725\n",
      "Epoch 621/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 6.2617e-06 - val_loss: 0.0725\n",
      "Epoch 622/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 6.2193e-06 - val_loss: 0.0725\n",
      "Epoch 623/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 6.1773e-06 - val_loss: 0.0725\n",
      "Epoch 624/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 6.1357e-06 - val_loss: 0.0725\n",
      "Epoch 625/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 6.0943e-06 - val_loss: 0.0725\n",
      "Epoch 626/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 6.0533e-06 - val_loss: 0.0725\n",
      "Epoch 627/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 6.0127e-06 - val_loss: 0.0725\n",
      "Epoch 628/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 5.9723e-06 - val_loss: 0.0725\n",
      "Epoch 629/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 5.9323e-06 - val_loss: 0.0725\n",
      "Epoch 630/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 5.8926e-06 - val_loss: 0.0725\n",
      "Epoch 631/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 5.8532e-06 - val_loss: 0.0725\n",
      "Epoch 632/3000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 5.8142e-06 - val_loss: 0.0725\n",
      "Epoch 633/3000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 5.7754e-06 - val_loss: 0.0725\n",
      "Epoch 634/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 5.7370e-06 - val_loss: 0.0725\n",
      "Epoch 635/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 5.6988e-06 - val_loss: 0.0725\n",
      "Epoch 636/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 5.6610e-06 - val_loss: 0.0725\n",
      "Epoch 637/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 5.6235e-06 - val_loss: 0.0725\n",
      "Epoch 638/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 5.5862e-06 - val_loss: 0.0725\n",
      "Epoch 639/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 5.5493e-06 - val_loss: 0.0725\n",
      "Epoch 640/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 5.5126e-06 - val_loss: 0.0725\n",
      "Epoch 641/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 5.4762e-06 - val_loss: 0.0725\n",
      "Epoch 642/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 5.4401e-06 - val_loss: 0.0725\n",
      "Epoch 643/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 5.4043e-06 - val_loss: 0.0725\n",
      "Epoch 644/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 5.3688e-06 - val_loss: 0.0725\n",
      "Epoch 645/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 5.3336e-06 - val_loss: 0.0725\n",
      "Epoch 646/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 5.2986e-06 - val_loss: 0.0725\n",
      "Epoch 647/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 5.2639e-06 - val_loss: 0.0725\n",
      "Epoch 648/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 5.2295e-06 - val_loss: 0.0725\n",
      "Epoch 649/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 5.1953e-06 - val_loss: 0.0725\n",
      "Epoch 650/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 5.1614e-06 - val_loss: 0.0725\n",
      "Epoch 651/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 5.1278e-06 - val_loss: 0.0725\n",
      "Epoch 652/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 5.0944e-06 - val_loss: 0.0725\n",
      "Epoch 653/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 5.0613e-06 - val_loss: 0.0725\n",
      "Epoch 654/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 5.0284e-06 - val_loss: 0.0725\n",
      "Epoch 655/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 4.9958e-06 - val_loss: 0.0725\n",
      "Epoch 656/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 4.9634e-06 - val_loss: 0.0725\n",
      "Epoch 657/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 4.9313e-06 - val_loss: 0.0725\n",
      "Epoch 658/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 4.8994e-06 - val_loss: 0.0725\n",
      "Epoch 659/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 4.8678e-06 - val_loss: 0.0725\n",
      "Epoch 660/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 4.8364e-06 - val_loss: 0.0725\n",
      "Epoch 661/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 4.8053e-06 - val_loss: 0.0725\n",
      "Epoch 662/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 4.7744e-06 - val_loss: 0.0725\n",
      "Epoch 663/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 4.7437e-06 - val_loss: 0.0725\n",
      "Epoch 664/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 4.7133e-06 - val_loss: 0.0725\n",
      "Epoch 665/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 4.6831e-06 - val_loss: 0.0725\n",
      "Epoch 666/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 4.6531e-06 - val_loss: 0.0725\n",
      "Epoch 667/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 4.6234e-06 - val_loss: 0.0725\n",
      "Epoch 668/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 4.5938e-06 - val_loss: 0.0725\n",
      "Epoch 669/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 4.5645e-06 - val_loss: 0.0725\n",
      "Epoch 670/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 4.5355e-06 - val_loss: 0.0725\n",
      "Epoch 671/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 4.5066e-06 - val_loss: 0.0725\n",
      "Epoch 672/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 4.4780e-06 - val_loss: 0.0725\n",
      "Epoch 673/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 4.4495e-06 - val_loss: 0.0725\n",
      "Epoch 674/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 4.4213e-06 - val_loss: 0.0725\n",
      "Epoch 675/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 4.3933e-06 - val_loss: 0.0725\n",
      "Epoch 676/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 4.3656e-06 - val_loss: 0.0725\n",
      "Epoch 677/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 4.3380e-06 - val_loss: 0.0725\n",
      "Epoch 678/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 4.3106e-06 - val_loss: 0.0725\n",
      "Epoch 679/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 4.2835e-06 - val_loss: 0.0725\n",
      "Epoch 680/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 4.2565e-06 - val_loss: 0.0725\n",
      "Epoch 681/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 4.2298e-06 - val_loss: 0.0725\n",
      "Epoch 682/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 4.2032e-06 - val_loss: 0.0725\n",
      "Epoch 683/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 4.1769e-06 - val_loss: 0.0725\n",
      "Epoch 684/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 4.1508e-06 - val_loss: 0.0725\n",
      "Epoch 685/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 4.1248e-06 - val_loss: 0.0725\n",
      "Epoch 686/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 4.0991e-06 - val_loss: 0.0725\n",
      "Epoch 687/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 4.0735e-06 - val_loss: 0.0725\n",
      "Epoch 688/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 4.0482e-06 - val_loss: 0.0725\n",
      "Epoch 689/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 4.0230e-06 - val_loss: 0.0725\n",
      "Epoch 690/3000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 3.9980e-06 - val_loss: 0.0725\n",
      "Epoch 691/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 3.9732e-06 - val_loss: 0.0725\n",
      "Epoch 692/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 3.9486e-06 - val_loss: 0.0725\n",
      "Epoch 693/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 3.9242e-06 - val_loss: 0.0725\n",
      "Epoch 694/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 3.9000e-06 - val_loss: 0.0725\n",
      "Epoch 695/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.8760e-06 - val_loss: 0.0725\n",
      "Epoch 696/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 3.8521e-06 - val_loss: 0.0725\n",
      "Epoch 697/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.8285e-06 - val_loss: 0.0725\n",
      "Epoch 698/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 3.8050e-06 - val_loss: 0.0725\n",
      "Epoch 699/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 3.7817e-06 - val_loss: 0.0725\n",
      "Epoch 700/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 3.7585e-06 - val_loss: 0.0725\n",
      "Epoch 701/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 3.7356e-06 - val_loss: 0.0725\n",
      "Epoch 702/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 3.7128e-06 - val_loss: 0.0725\n",
      "Epoch 703/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.6902e-06 - val_loss: 0.0725\n",
      "Epoch 704/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 3.6678e-06 - val_loss: 0.0725\n",
      "Epoch 705/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 3.6455e-06 - val_loss: 0.0725\n",
      "Epoch 706/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 3.6234e-06 - val_loss: 0.0725\n",
      "Epoch 707/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 3.6015e-06 - val_loss: 0.0725\n",
      "Epoch 708/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.5798e-06 - val_loss: 0.0725\n",
      "Epoch 709/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 3.5582e-06 - val_loss: 0.0725\n",
      "Epoch 710/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.5368e-06 - val_loss: 0.0725\n",
      "Epoch 711/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.5155e-06 - val_loss: 0.0725\n",
      "Epoch 712/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.4944e-06 - val_loss: 0.0725\n",
      "Epoch 713/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.4735e-06 - val_loss: 0.0725\n",
      "Epoch 714/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.4528e-06 - val_loss: 0.0725\n",
      "Epoch 715/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.4321e-06 - val_loss: 0.0725\n",
      "Epoch 716/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.4117e-06 - val_loss: 0.0725\n",
      "Epoch 717/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 3.3914e-06 - val_loss: 0.0725\n",
      "Epoch 718/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 3.3713e-06 - val_loss: 0.0725\n",
      "Epoch 719/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 3.3513e-06 - val_loss: 0.0725\n",
      "Epoch 720/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.3315e-06 - val_loss: 0.0725\n",
      "Epoch 721/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 3.3118e-06 - val_loss: 0.0725\n",
      "Epoch 722/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.2922e-06 - val_loss: 0.0725\n",
      "Epoch 723/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 3.2729e-06 - val_loss: 0.0725\n",
      "Epoch 724/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 3.2536e-06 - val_loss: 0.0726\n",
      "Epoch 725/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 3.2345e-06 - val_loss: 0.0726\n",
      "Epoch 726/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 3.2156e-06 - val_loss: 0.0726\n",
      "Epoch 727/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.1968e-06 - val_loss: 0.0726\n",
      "Epoch 728/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.1781e-06 - val_loss: 0.0726\n",
      "Epoch 729/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 3.1595e-06 - val_loss: 0.0726\n",
      "Epoch 730/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 3.1412e-06 - val_loss: 0.0726\n",
      "Epoch 731/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 3.1229e-06 - val_loss: 0.0726\n",
      "Epoch 732/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 3.1048e-06 - val_loss: 0.0726\n",
      "Epoch 733/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 3.0868e-06 - val_loss: 0.0726\n",
      "Epoch 734/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.0689e-06 - val_loss: 0.0726\n",
      "Epoch 735/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.0512e-06 - val_loss: 0.0726\n",
      "Epoch 736/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 3.0336e-06 - val_loss: 0.0726\n",
      "Epoch 737/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 3.0161e-06 - val_loss: 0.0726\n",
      "Epoch 738/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.9987e-06 - val_loss: 0.0726\n",
      "Epoch 739/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.9815e-06 - val_loss: 0.0726\n",
      "Epoch 740/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 2.9644e-06 - val_loss: 0.0726\n",
      "Epoch 741/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.9474e-06 - val_loss: 0.0726\n",
      "Epoch 742/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 2.9306e-06 - val_loss: 0.0726\n",
      "Epoch 743/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 2.9138e-06 - val_loss: 0.0726\n",
      "Epoch 744/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 2.8972e-06 - val_loss: 0.0726\n",
      "Epoch 745/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 2.8807e-06 - val_loss: 0.0726\n",
      "Epoch 746/3000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 2.8643e-06 - val_loss: 0.0726\n",
      "Epoch 747/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 2.8480e-06 - val_loss: 0.0726\n",
      "Epoch 748/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 2.8319e-06 - val_loss: 0.0726\n",
      "Epoch 749/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.8158e-06 - val_loss: 0.0726\n",
      "Epoch 750/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.7999e-06 - val_loss: 0.0726\n",
      "Epoch 751/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.7841e-06 - val_loss: 0.0726\n",
      "Epoch 752/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.7684e-06 - val_loss: 0.0726\n",
      "Epoch 753/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.7528e-06 - val_loss: 0.0726\n",
      "Epoch 754/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.7373e-06 - val_loss: 0.0726\n",
      "Epoch 755/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.7219e-06 - val_loss: 0.0726\n",
      "Epoch 756/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.7066e-06 - val_loss: 0.0726\n",
      "Epoch 757/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 2.6914e-06 - val_loss: 0.0726\n",
      "Epoch 758/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 2.6763e-06 - val_loss: 0.0726\n",
      "Epoch 759/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.6614e-06 - val_loss: 0.0726\n",
      "Epoch 760/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 2.6465e-06 - val_loss: 0.0726\n",
      "Epoch 761/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 2.6317e-06 - val_loss: 0.0726\n",
      "Epoch 762/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.6171e-06 - val_loss: 0.0726\n",
      "Epoch 763/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 2.6025e-06 - val_loss: 0.0726\n",
      "Epoch 764/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.5880e-06 - val_loss: 0.0726\n",
      "Epoch 765/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.5736e-06 - val_loss: 0.0726\n",
      "Epoch 766/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.5594e-06 - val_loss: 0.0726\n",
      "Epoch 767/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.5452e-06 - val_loss: 0.0726\n",
      "Epoch 768/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.5311e-06 - val_loss: 0.0726\n",
      "Epoch 769/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.5171e-06 - val_loss: 0.0726\n",
      "Epoch 770/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 2.5032e-06 - val_loss: 0.0726\n",
      "Epoch 771/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 2.4894e-06 - val_loss: 0.0726\n",
      "Epoch 772/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 2.4757e-06 - val_loss: 0.0726\n",
      "Epoch 773/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.4621e-06 - val_loss: 0.0726\n",
      "Epoch 774/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.4485e-06 - val_loss: 0.0726\n",
      "Epoch 775/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.4351e-06 - val_loss: 0.0726\n",
      "Epoch 776/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.4217e-06 - val_loss: 0.0726\n",
      "Epoch 777/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.4085e-06 - val_loss: 0.0726\n",
      "Epoch 778/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 2.3953e-06 - val_loss: 0.0726\n",
      "Epoch 779/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 2.3822e-06 - val_loss: 0.0726\n",
      "Epoch 780/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.3692e-06 - val_loss: 0.0726\n",
      "Epoch 781/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.3563e-06 - val_loss: 0.0726\n",
      "Epoch 782/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.3434e-06 - val_loss: 0.0726\n",
      "Epoch 783/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.3307e-06 - val_loss: 0.0726\n",
      "Epoch 784/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.3180e-06 - val_loss: 0.0726\n",
      "Epoch 785/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.3054e-06 - val_loss: 0.0726\n",
      "Epoch 786/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.2929e-06 - val_loss: 0.0726\n",
      "Epoch 787/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.2805e-06 - val_loss: 0.0726\n",
      "Epoch 788/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.2682e-06 - val_loss: 0.0726\n",
      "Epoch 789/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.2559e-06 - val_loss: 0.0726\n",
      "Epoch 790/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.2437e-06 - val_loss: 0.0726\n",
      "Epoch 791/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.2316e-06 - val_loss: 0.0726\n",
      "Epoch 792/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.2196e-06 - val_loss: 0.0726\n",
      "Epoch 793/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.2076e-06 - val_loss: 0.0726\n",
      "Epoch 794/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.1958e-06 - val_loss: 0.0726\n",
      "Epoch 795/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.1840e-06 - val_loss: 0.0726\n",
      "Epoch 796/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.1722e-06 - val_loss: 0.0726\n",
      "Epoch 797/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.1606e-06 - val_loss: 0.0726\n",
      "Epoch 798/3000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 2.1490e-06 - val_loss: 0.0726\n",
      "Epoch 799/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 2.1375e-06 - val_loss: 0.0726\n",
      "Epoch 800/3000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 2.1261e-06 - val_loss: 0.0726\n",
      "Epoch 801/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.1147e-06 - val_loss: 0.0726\n",
      "Epoch 802/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.1034e-06 - val_loss: 0.0726\n",
      "Epoch 803/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.0922e-06 - val_loss: 0.0726\n",
      "Epoch 804/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.0811e-06 - val_loss: 0.0726\n",
      "Epoch 805/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.0700e-06 - val_loss: 0.0726\n",
      "Epoch 806/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.0590e-06 - val_loss: 0.0726\n",
      "Epoch 807/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.0480e-06 - val_loss: 0.0726\n",
      "Epoch 808/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.0371e-06 - val_loss: 0.0726\n",
      "Epoch 809/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.0263e-06 - val_loss: 0.0726\n",
      "Epoch 810/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.0156e-06 - val_loss: 0.0726\n",
      "Epoch 811/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.0049e-06 - val_loss: 0.0726\n",
      "Epoch 812/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.9943e-06 - val_loss: 0.0726\n",
      "Epoch 813/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.9838e-06 - val_loss: 0.0726\n",
      "Epoch 814/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.9733e-06 - val_loss: 0.0726\n",
      "Epoch 815/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.9628e-06 - val_loss: 0.0726\n",
      "Epoch 816/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.9525e-06 - val_loss: 0.0726\n",
      "Epoch 817/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.9422e-06 - val_loss: 0.0726\n",
      "Epoch 818/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.9320e-06 - val_loss: 0.0726\n",
      "Epoch 819/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.9218e-06 - val_loss: 0.0726\n",
      "Epoch 820/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.9117e-06 - val_loss: 0.0726\n",
      "Epoch 821/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.9016e-06 - val_loss: 0.0726\n",
      "Epoch 822/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.8916e-06 - val_loss: 0.0726\n",
      "Epoch 823/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.8817e-06 - val_loss: 0.0726\n",
      "Epoch 824/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.8718e-06 - val_loss: 0.0726\n",
      "Epoch 825/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.8620e-06 - val_loss: 0.0726\n",
      "Epoch 826/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.8522e-06 - val_loss: 0.0726\n",
      "Epoch 827/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.8425e-06 - val_loss: 0.0726\n",
      "Epoch 828/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.8329e-06 - val_loss: 0.0726\n",
      "Epoch 829/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.8233e-06 - val_loss: 0.0726\n",
      "Epoch 830/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.8138e-06 - val_loss: 0.0726\n",
      "Epoch 831/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.8043e-06 - val_loss: 0.0726\n",
      "Epoch 832/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.7948e-06 - val_loss: 0.0726\n",
      "Epoch 833/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.7855e-06 - val_loss: 0.0726\n",
      "Epoch 834/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.7761e-06 - val_loss: 0.0726\n",
      "Epoch 835/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 1.7669e-06 - val_loss: 0.0726\n",
      "Epoch 836/3000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 1.7577e-06 - val_loss: 0.0726\n",
      "Epoch 837/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 1.7485e-06 - val_loss: 0.0726\n",
      "Epoch 838/3000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 1.7394e-06 - val_loss: 0.0726\n",
      "Epoch 839/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.7303e-06 - val_loss: 0.0726\n",
      "Epoch 840/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.7213e-06 - val_loss: 0.0726\n",
      "Epoch 841/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.7124e-06 - val_loss: 0.0726\n",
      "Epoch 842/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.7035e-06 - val_loss: 0.0726\n",
      "Epoch 843/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.6946e-06 - val_loss: 0.0726\n",
      "Epoch 844/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.6858e-06 - val_loss: 0.0726\n",
      "Epoch 845/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.6770e-06 - val_loss: 0.0726\n",
      "Epoch 846/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.6683e-06 - val_loss: 0.0726\n",
      "Epoch 847/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.6596e-06 - val_loss: 0.0726\n",
      "Epoch 848/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.6510e-06 - val_loss: 0.0726\n",
      "Epoch 849/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.6425e-06 - val_loss: 0.0726\n",
      "Epoch 850/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.6339e-06 - val_loss: 0.0726\n",
      "Epoch 851/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.6255e-06 - val_loss: 0.0726\n",
      "Epoch 852/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.6170e-06 - val_loss: 0.0726\n",
      "Epoch 853/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.6087e-06 - val_loss: 0.0726\n",
      "Epoch 854/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.6003e-06 - val_loss: 0.0726\n",
      "Epoch 855/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.5920e-06 - val_loss: 0.0726\n",
      "Epoch 856/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.5838e-06 - val_loss: 0.0726\n",
      "Epoch 857/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.5756e-06 - val_loss: 0.0726\n",
      "Epoch 858/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.5674e-06 - val_loss: 0.0726\n",
      "Epoch 859/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.5593e-06 - val_loss: 0.0726\n",
      "Epoch 860/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.5513e-06 - val_loss: 0.0726\n",
      "Epoch 861/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.5432e-06 - val_loss: 0.0726\n",
      "Epoch 862/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.5353e-06 - val_loss: 0.0726\n",
      "Epoch 863/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.5273e-06 - val_loss: 0.0726\n",
      "Epoch 864/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.5195e-06 - val_loss: 0.0726\n",
      "Epoch 865/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.5116e-06 - val_loss: 0.0726\n",
      "Epoch 866/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.5038e-06 - val_loss: 0.0726\n",
      "Epoch 867/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.4961e-06 - val_loss: 0.0726\n",
      "Epoch 868/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.4883e-06 - val_loss: 0.0726\n",
      "Epoch 869/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.4807e-06 - val_loss: 0.0726\n",
      "Epoch 870/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.4730e-06 - val_loss: 0.0726\n",
      "Epoch 871/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.4655e-06 - val_loss: 0.0726\n",
      "Epoch 872/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.4579e-06 - val_loss: 0.0726\n",
      "Epoch 873/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 1.4504e-06 - val_loss: 0.0726\n",
      "Epoch 874/3000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 1.4430e-06 - val_loss: 0.0726\n",
      "Epoch 875/3000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 1.4356e-06 - val_loss: 0.0726\n",
      "Epoch 876/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 1.4282e-06 - val_loss: 0.0726\n",
      "Epoch 877/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.4209e-06 - val_loss: 0.0726\n",
      "Epoch 878/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.4136e-06 - val_loss: 0.0726\n",
      "Epoch 879/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.4063e-06 - val_loss: 0.0726\n",
      "Epoch 880/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.3992e-06 - val_loss: 0.0726\n",
      "Epoch 881/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.3920e-06 - val_loss: 0.0726\n",
      "Epoch 882/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.3849e-06 - val_loss: 0.0726\n",
      "Epoch 883/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.3778e-06 - val_loss: 0.0726\n",
      "Epoch 884/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.3708e-06 - val_loss: 0.0726\n",
      "Epoch 885/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.3638e-06 - val_loss: 0.0726\n",
      "Epoch 886/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.3568e-06 - val_loss: 0.0726\n",
      "Epoch 887/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.3499e-06 - val_loss: 0.0726\n",
      "Epoch 888/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.3431e-06 - val_loss: 0.0726\n",
      "Epoch 889/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.3362e-06 - val_loss: 0.0726\n",
      "Epoch 890/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.3295e-06 - val_loss: 0.0726\n",
      "Epoch 891/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.3227e-06 - val_loss: 0.0726\n",
      "Epoch 892/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.3160e-06 - val_loss: 0.0726\n",
      "Epoch 893/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.3093e-06 - val_loss: 0.0726\n",
      "Epoch 894/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.3027e-06 - val_loss: 0.0726\n",
      "Epoch 895/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.2961e-06 - val_loss: 0.0726\n",
      "Epoch 896/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.2896e-06 - val_loss: 0.0726\n",
      "Epoch 897/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.2831e-06 - val_loss: 0.0726\n",
      "Epoch 898/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.2766e-06 - val_loss: 0.0726\n",
      "Epoch 899/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.2702e-06 - val_loss: 0.0726\n",
      "Epoch 900/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.2638e-06 - val_loss: 0.0726\n",
      "Epoch 901/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.2574e-06 - val_loss: 0.0726\n",
      "Epoch 902/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.2511e-06 - val_loss: 0.0726\n",
      "Epoch 903/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.2448e-06 - val_loss: 0.0726\n",
      "Epoch 904/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.2386e-06 - val_loss: 0.0726\n",
      "Epoch 905/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.2324e-06 - val_loss: 0.0726\n",
      "Epoch 906/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.2262e-06 - val_loss: 0.0726\n",
      "Epoch 907/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.2201e-06 - val_loss: 0.0726\n",
      "Epoch 908/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.2140e-06 - val_loss: 0.0726\n",
      "Epoch 909/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.2079e-06 - val_loss: 0.0726\n",
      "Epoch 910/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.2019e-06 - val_loss: 0.0726\n",
      "Epoch 911/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.1959e-06 - val_loss: 0.0726\n",
      "Epoch 912/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.1899e-06 - val_loss: 0.0726\n",
      "Epoch 913/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.1840e-06 - val_loss: 0.0726\n",
      "Epoch 914/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.1781e-06 - val_loss: 0.0726\n",
      "Epoch 915/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.1723e-06 - val_loss: 0.0726\n",
      "Epoch 916/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.1664e-06 - val_loss: 0.0726\n",
      "Epoch 917/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.1606e-06 - val_loss: 0.0726\n",
      "Epoch 918/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.1549e-06 - val_loss: 0.0726\n",
      "Epoch 919/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.1491e-06 - val_loss: 0.0726\n",
      "Epoch 920/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.1434e-06 - val_loss: 0.0726\n",
      "Epoch 921/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.1378e-06 - val_loss: 0.0726\n",
      "Epoch 922/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.1321e-06 - val_loss: 0.0726\n",
      "Epoch 923/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.1265e-06 - val_loss: 0.0726\n",
      "Epoch 924/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.1209e-06 - val_loss: 0.0726\n",
      "Epoch 925/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.1154e-06 - val_loss: 0.0726\n",
      "Epoch 926/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.1099e-06 - val_loss: 0.0726\n",
      "Epoch 927/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.1044e-06 - val_loss: 0.0726\n",
      "Epoch 928/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.0989e-06 - val_loss: 0.0726\n",
      "Epoch 929/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 1.0935e-06 - val_loss: 0.0726\n",
      "Epoch 930/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 1.0881e-06 - val_loss: 0.0726\n",
      "Epoch 931/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 1.0827e-06 - val_loss: 0.0726\n",
      "Epoch 932/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 1.0774e-06 - val_loss: 0.0726\n",
      "Epoch 933/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 1.0721e-06 - val_loss: 0.0726\n",
      "Epoch 934/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1.0668e-06 - val_loss: 0.0726\n",
      "Epoch 935/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.0616e-06 - val_loss: 0.0726\n",
      "Epoch 936/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.0563e-06 - val_loss: 0.0726\n",
      "Epoch 937/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.0511e-06 - val_loss: 0.0726\n",
      "Epoch 938/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.0460e-06 - val_loss: 0.0726\n",
      "Epoch 939/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.0408e-06 - val_loss: 0.0726\n",
      "Epoch 940/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.0357e-06 - val_loss: 0.0726\n",
      "Epoch 941/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.0306e-06 - val_loss: 0.0726\n",
      "Epoch 942/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.0255e-06 - val_loss: 0.0726\n",
      "Epoch 943/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.0205e-06 - val_loss: 0.0726\n",
      "Epoch 944/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.0155e-06 - val_loss: 0.0726\n",
      "Epoch 945/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.0105e-06 - val_loss: 0.0726\n",
      "Epoch 946/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.0055e-06 - val_loss: 0.0726\n",
      "Epoch 947/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.0006e-06 - val_loss: 0.0726\n",
      "Epoch 948/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 9.9568e-07 - val_loss: 0.0726\n",
      "Epoch 949/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 9.9079e-07 - val_loss: 0.0726\n",
      "Epoch 950/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 9.8593e-07 - val_loss: 0.0726\n",
      "Epoch 951/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 9.8109e-07 - val_loss: 0.0726\n",
      "Epoch 952/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 9.7628e-07 - val_loss: 0.0726\n",
      "Epoch 953/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 9.7150e-07 - val_loss: 0.0726\n",
      "Epoch 954/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 9.6673e-07 - val_loss: 0.0726\n",
      "Epoch 955/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 9.6200e-07 - val_loss: 0.0726\n",
      "Epoch 956/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 9.5728e-07 - val_loss: 0.0726\n",
      "Epoch 957/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 9.5259e-07 - val_loss: 0.0726\n",
      "Epoch 958/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 9.4793e-07 - val_loss: 0.0726\n",
      "Epoch 959/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 9.4329e-07 - val_loss: 0.0726\n",
      "Epoch 960/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 9.3867e-07 - val_loss: 0.0726\n",
      "Epoch 961/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 9.3407e-07 - val_loss: 0.0726\n",
      "Epoch 962/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 9.2950e-07 - val_loss: 0.0726\n",
      "Epoch 963/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 9.2495e-07 - val_loss: 0.0726\n",
      "Epoch 964/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 9.2043e-07 - val_loss: 0.0726\n",
      "Epoch 965/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 9.1593e-07 - val_loss: 0.0726\n",
      "Epoch 966/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 9.1145e-07 - val_loss: 0.0726\n",
      "Epoch 967/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 9.0699e-07 - val_loss: 0.0726\n",
      "Epoch 968/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 9.0256e-07 - val_loss: 0.0726\n",
      "Epoch 969/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 8.9814e-07 - val_loss: 0.0726\n",
      "Epoch 970/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 8.9376e-07 - val_loss: 0.0726\n",
      "Epoch 971/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 8.8939e-07 - val_loss: 0.0726\n",
      "Epoch 972/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 8.8504e-07 - val_loss: 0.0726\n",
      "Epoch 973/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 8.8072e-07 - val_loss: 0.0726\n",
      "Epoch 974/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 8.7642e-07 - val_loss: 0.0726\n",
      "Epoch 975/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 8.7214e-07 - val_loss: 0.0726\n",
      "Epoch 976/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 8.6789e-07 - val_loss: 0.0726\n",
      "Epoch 977/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 8.6365e-07 - val_loss: 0.0726\n",
      "Epoch 978/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 8.5944e-07 - val_loss: 0.0726\n",
      "Epoch 979/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 8.5525e-07 - val_loss: 0.0726\n",
      "Epoch 980/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 8.5108e-07 - val_loss: 0.0726\n",
      "Epoch 981/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 8.4693e-07 - val_loss: 0.0726\n",
      "Epoch 982/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 8.4280e-07 - val_loss: 0.0726\n",
      "Epoch 983/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 8.3870e-07 - val_loss: 0.0726\n",
      "Epoch 984/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 8.3461e-07 - val_loss: 0.0726\n",
      "Epoch 985/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 8.3055e-07 - val_loss: 0.0726\n",
      "Epoch 986/3000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 8.2651e-07 - val_loss: 0.0726\n",
      "Epoch 987/3000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 8.2249e-07 - val_loss: 0.0726\n",
      "Epoch 988/3000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 8.1849e-07 - val_loss: 0.0726\n",
      "Epoch 989/3000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 8.1451e-07 - val_loss: 0.0726\n",
      "Epoch 990/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 8.1055e-07 - val_loss: 0.0726\n",
      "Epoch 991/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 8.0661e-07 - val_loss: 0.0726\n",
      "Epoch 992/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 8.0270e-07 - val_loss: 0.0726\n",
      "Epoch 993/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 7.9881e-07 - val_loss: 0.0726\n",
      "Epoch 994/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 7.9494e-07 - val_loss: 0.0726\n",
      "Epoch 995/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.9109e-07 - val_loss: 0.0726\n",
      "Epoch 996/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 7.8728e-07 - val_loss: 0.0726\n",
      "Epoch 997/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 7.8350e-07 - val_loss: 0.0726\n",
      "Epoch 998/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 7.7977e-07 - val_loss: 0.0726\n",
      "Epoch 999/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 7.7610e-07 - val_loss: 0.0726\n",
      "Epoch 1000/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 7.7254e-07 - val_loss: 0.0726\n",
      "Epoch 1001/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 7.6916e-07 - val_loss: 0.0726\n",
      "Epoch 1002/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.6606e-07 - val_loss: 0.0726\n",
      "Epoch 1003/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 7.6350e-07 - val_loss: 0.0726\n",
      "Epoch 1004/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 7.6190e-07 - val_loss: 0.0726\n",
      "Epoch 1005/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.6207e-07 - val_loss: 0.0726\n",
      "Epoch 1006/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.6556e-07 - val_loss: 0.0726\n",
      "Epoch 1007/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 7.7539e-07 - val_loss: 0.0726\n",
      "Epoch 1008/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 7.9719e-07 - val_loss: 0.0726\n",
      "Epoch 1009/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 8.4241e-07 - val_loss: 0.0726\n",
      "Epoch 1010/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 9.3227e-07 - val_loss: 0.0726\n",
      "Epoch 1011/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.1119e-06 - val_loss: 0.0726\n",
      "Epoch 1012/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.4628e-06 - val_loss: 0.0726\n",
      "Epoch 1013/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.1707e-06 - val_loss: 0.0726\n",
      "Epoch 1014/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 3.5487e-06 - val_loss: 0.0726\n",
      "Epoch 1015/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 6.4007e-06 - val_loss: 0.0726\n",
      "Epoch 1016/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.1897e-05 - val_loss: 0.0726\n",
      "Epoch 1017/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.3701e-05 - val_loss: 0.0725\n",
      "Epoch 1018/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 4.5670e-05 - val_loss: 0.0727\n",
      "Epoch 1019/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 9.5235e-05 - val_loss: 0.0725\n",
      "Epoch 1020/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.7957e-04 - val_loss: 0.0728\n",
      "Epoch 1021/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.6527e-04 - val_loss: 0.0723\n",
      "Epoch 1022/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 6.1525e-04 - val_loss: 0.0731\n",
      "Epoch 1023/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0011 - val_loss: 0.0725\n",
      "Epoch 1024/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0016 - val_loss: 0.0742\n",
      "Epoch 1025/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0020 - val_loss: 0.0729\n",
      "Epoch 1026/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0011 - val_loss: 0.0726\n",
      "Epoch 1027/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 7.0146e-04 - val_loss: 0.0725\n",
      "Epoch 1028/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 9.6296e-04 - val_loss: 0.0709\n",
      "Epoch 1029/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 4.0901e-04 - val_loss: 0.0710\n",
      "Epoch 1030/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 6.2183e-04 - val_loss: 0.0723\n",
      "Epoch 1031/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 4.1085e-04 - val_loss: 0.0728\n",
      "Epoch 1032/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 4.7928e-04 - val_loss: 0.0712\n",
      "Epoch 1033/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.7394e-04 - val_loss: 0.0704\n",
      "Epoch 1034/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 4.0897e-04 - val_loss: 0.0711\n",
      "Epoch 1035/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 2.1651e-04 - val_loss: 0.0718\n",
      "Epoch 1036/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 3.0233e-04 - val_loss: 0.0714\n",
      "Epoch 1037/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.1571e-04 - val_loss: 0.0710\n",
      "Epoch 1038/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.0938e-04 - val_loss: 0.0708\n",
      "Epoch 1039/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.8829e-04 - val_loss: 0.0711\n",
      "Epoch 1040/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.6743e-04 - val_loss: 0.0716\n",
      "Epoch 1041/3000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 1.5623e-04 - val_loss: 0.0713\n",
      "Epoch 1042/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 1.2734e-04 - val_loss: 0.0706\n",
      "Epoch 1043/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 1.3983e-04 - val_loss: 0.0708\n",
      "Epoch 1044/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 9.2585e-05 - val_loss: 0.0717\n",
      "Epoch 1045/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 1.1647e-04 - val_loss: 0.0715\n",
      "Epoch 1046/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 8.0123e-05 - val_loss: 0.0707\n",
      "Epoch 1047/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 8.4044e-05 - val_loss: 0.0707\n",
      "Epoch 1048/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.8117e-05 - val_loss: 0.0711\n",
      "Epoch 1049/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 5.7496e-05 - val_loss: 0.0713\n",
      "Epoch 1050/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 6.9938e-05 - val_loss: 0.0711\n",
      "Epoch 1051/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 4.6786e-05 - val_loss: 0.0710\n",
      "Epoch 1052/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 5.2720e-05 - val_loss: 0.0710\n",
      "Epoch 1053/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 4.4014e-05 - val_loss: 0.0711\n",
      "Epoch 1054/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.8517e-05 - val_loss: 0.0713\n",
      "Epoch 1055/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 3.9622e-05 - val_loss: 0.0711\n",
      "Epoch 1056/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.9035e-05 - val_loss: 0.0708\n",
      "Epoch 1057/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 3.3849e-05 - val_loss: 0.0709\n",
      "Epoch 1058/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.4464e-05 - val_loss: 0.0713\n",
      "Epoch 1059/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.5483e-05 - val_loss: 0.0713\n",
      "Epoch 1060/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.3531e-05 - val_loss: 0.0710\n",
      "Epoch 1061/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.7982e-05 - val_loss: 0.0709\n",
      "Epoch 1062/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.1178e-05 - val_loss: 0.0710\n",
      "Epoch 1063/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.4680e-05 - val_loss: 0.0712\n",
      "Epoch 1064/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.6447e-05 - val_loss: 0.0712\n",
      "Epoch 1065/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.3917e-05 - val_loss: 0.0710\n",
      "Epoch 1066/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.2051e-05 - val_loss: 0.0709\n",
      "Epoch 1067/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.2637e-05 - val_loss: 0.0710\n",
      "Epoch 1068/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 9.6194e-06 - val_loss: 0.0712\n",
      "Epoch 1069/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.0647e-05 - val_loss: 0.0712\n",
      "Epoch 1070/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 8.3795e-06 - val_loss: 0.0710\n",
      "Epoch 1071/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 8.2378e-06 - val_loss: 0.0709\n",
      "Epoch 1072/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.9585e-06 - val_loss: 0.0710\n",
      "Epoch 1073/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 6.1177e-06 - val_loss: 0.0712\n",
      "Epoch 1074/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 7.1168e-06 - val_loss: 0.0712\n",
      "Epoch 1075/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 5.3518e-06 - val_loss: 0.0710\n",
      "Epoch 1076/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 5.5417e-06 - val_loss: 0.0710\n",
      "Epoch 1077/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 5.1761e-06 - val_loss: 0.0711\n",
      "Epoch 1078/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 4.2608e-06 - val_loss: 0.0711\n",
      "Epoch 1079/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 4.6986e-06 - val_loss: 0.0711\n",
      "Epoch 1080/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.6544e-06 - val_loss: 0.0711\n",
      "Epoch 1081/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 3.9110e-06 - val_loss: 0.0710\n",
      "Epoch 1082/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 3.3880e-06 - val_loss: 0.0711\n",
      "Epoch 1083/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.1526e-06 - val_loss: 0.0711\n",
      "Epoch 1084/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.1676e-06 - val_loss: 0.0711\n",
      "Epoch 1085/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.6558e-06 - val_loss: 0.0710\n",
      "Epoch 1086/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.8002e-06 - val_loss: 0.0710\n",
      "Epoch 1087/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.4059e-06 - val_loss: 0.0711\n",
      "Epoch 1088/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.3919e-06 - val_loss: 0.0711\n",
      "Epoch 1089/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.2306e-06 - val_loss: 0.0710\n",
      "Epoch 1090/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.0914e-06 - val_loss: 0.0710\n",
      "Epoch 1091/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.0184e-06 - val_loss: 0.0711\n",
      "Epoch 1092/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.8706e-06 - val_loss: 0.0711\n",
      "Epoch 1093/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.8533e-06 - val_loss: 0.0711\n",
      "Epoch 1094/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.6649e-06 - val_loss: 0.0711\n",
      "Epoch 1095/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.7066e-06 - val_loss: 0.0711\n",
      "Epoch 1096/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.5378e-06 - val_loss: 0.0711\n",
      "Epoch 1097/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.5311e-06 - val_loss: 0.0711\n",
      "Epoch 1098/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.4676e-06 - val_loss: 0.0711\n",
      "Epoch 1099/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.3592e-06 - val_loss: 0.0710\n",
      "Epoch 1100/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.4113e-06 - val_loss: 0.0710\n",
      "Epoch 1101/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.2484e-06 - val_loss: 0.0711\n",
      "Epoch 1102/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.2912e-06 - val_loss: 0.0711\n",
      "Epoch 1103/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.2243e-06 - val_loss: 0.0711\n",
      "Epoch 1104/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.1650e-06 - val_loss: 0.0711\n",
      "Epoch 1105/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.1755e-06 - val_loss: 0.0711\n",
      "Epoch 1106/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.1026e-06 - val_loss: 0.0711\n",
      "Epoch 1107/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.1043e-06 - val_loss: 0.0711\n",
      "Epoch 1108/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.0512e-06 - val_loss: 0.0711\n",
      "Epoch 1109/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.0482e-06 - val_loss: 0.0711\n",
      "Epoch 1110/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.0112e-06 - val_loss: 0.0711\n",
      "Epoch 1111/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 9.8817e-07 - val_loss: 0.0711\n",
      "Epoch 1112/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 9.7978e-07 - val_loss: 0.0711\n",
      "Epoch 1113/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 9.4260e-07 - val_loss: 0.0711\n",
      "Epoch 1114/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 9.3981e-07 - val_loss: 0.0711\n",
      "Epoch 1115/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 9.1199e-07 - val_loss: 0.0711\n",
      "Epoch 1116/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 9.0065e-07 - val_loss: 0.0711\n",
      "Epoch 1117/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 8.8445e-07 - val_loss: 0.0711\n",
      "Epoch 1118/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 8.6696e-07 - val_loss: 0.0711\n",
      "Epoch 1119/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 8.5781e-07 - val_loss: 0.0711\n",
      "Epoch 1120/3000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 8.3977e-07 - val_loss: 0.0711\n",
      "Epoch 1121/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 8.3099e-07 - val_loss: 0.0711\n",
      "Epoch 1122/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 8.1676e-07 - val_loss: 0.0711\n",
      "Epoch 1123/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 8.0604e-07 - val_loss: 0.0711\n",
      "Epoch 1124/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.9600e-07 - val_loss: 0.0711\n",
      "Epoch 1125/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.8337e-07 - val_loss: 0.0711\n",
      "Epoch 1126/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 7.7610e-07 - val_loss: 0.0711\n",
      "Epoch 1127/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 7.6401e-07 - val_loss: 0.0711\n",
      "Epoch 1128/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.5657e-07 - val_loss: 0.0711\n",
      "Epoch 1129/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 7.4693e-07 - val_loss: 0.0711\n",
      "Epoch 1130/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 7.3802e-07 - val_loss: 0.0711\n",
      "Epoch 1131/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 7.3109e-07 - val_loss: 0.0711\n",
      "Epoch 1132/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 7.2121e-07 - val_loss: 0.0711\n",
      "Epoch 1133/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 7.1556e-07 - val_loss: 0.0711\n",
      "Epoch 1134/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 7.0648e-07 - val_loss: 0.0711\n",
      "Epoch 1135/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 7.0014e-07 - val_loss: 0.0711\n",
      "Epoch 1136/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 6.9309e-07 - val_loss: 0.0711\n",
      "Epoch 1137/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 6.8571e-07 - val_loss: 0.0711\n",
      "Epoch 1138/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 6.7992e-07 - val_loss: 0.0711\n",
      "Epoch 1139/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 6.7283e-07 - val_loss: 0.0711\n",
      "Epoch 1140/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 6.6703e-07 - val_loss: 0.0711\n",
      "Epoch 1141/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 6.6062e-07 - val_loss: 0.0711\n",
      "Epoch 1142/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 6.5502e-07 - val_loss: 0.0711\n",
      "Epoch 1143/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 6.4889e-07 - val_loss: 0.0711\n",
      "Epoch 1144/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 6.4346e-07 - val_loss: 0.0711\n",
      "Epoch 1145/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 6.3796e-07 - val_loss: 0.0711\n",
      "Epoch 1146/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 6.3230e-07 - val_loss: 0.0711\n",
      "Epoch 1147/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 6.2744e-07 - val_loss: 0.0711\n",
      "Epoch 1148/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 6.2186e-07 - val_loss: 0.0711\n",
      "Epoch 1149/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 6.1711e-07 - val_loss: 0.0711\n",
      "Epoch 1150/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 6.1200e-07 - val_loss: 0.0711\n",
      "Epoch 1151/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 6.0719e-07 - val_loss: 0.0711\n",
      "Epoch 1152/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 6.0247e-07 - val_loss: 0.0711\n",
      "Epoch 1153/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 5.9771e-07 - val_loss: 0.0711\n",
      "Epoch 1154/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 5.9327e-07 - val_loss: 0.0711\n",
      "Epoch 1155/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 5.8861e-07 - val_loss: 0.0711\n",
      "Epoch 1156/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 5.8435e-07 - val_loss: 0.0711\n",
      "Epoch 1157/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 5.7986e-07 - val_loss: 0.0711\n",
      "Epoch 1158/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 5.7573e-07 - val_loss: 0.0711\n",
      "Epoch 1159/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 5.7141e-07 - val_loss: 0.0711\n",
      "Epoch 1160/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 5.6739e-07 - val_loss: 0.0711\n",
      "Epoch 1161/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 5.6327e-07 - val_loss: 0.0711\n",
      "Epoch 1162/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 5.5928e-07 - val_loss: 0.0711\n",
      "Epoch 1163/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 5.5539e-07 - val_loss: 0.0711\n",
      "Epoch 1164/3000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 5.5144e-07 - val_loss: 0.0711\n",
      "Epoch 1165/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 5.4773e-07 - val_loss: 0.0711\n",
      "Epoch 1166/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 5.4387e-07 - val_loss: 0.0711\n",
      "Epoch 1167/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 5.4027e-07 - val_loss: 0.0711\n",
      "Epoch 1168/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 5.3654e-07 - val_loss: 0.0711\n",
      "Epoch 1169/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 5.3299e-07 - val_loss: 0.0711\n",
      "Epoch 1170/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 5.2944e-07 - val_loss: 0.0711\n",
      "Epoch 1171/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 5.2591e-07 - val_loss: 0.0711\n",
      "Epoch 1172/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 5.2251e-07 - val_loss: 0.0711\n",
      "Epoch 1173/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 5.1906e-07 - val_loss: 0.0711\n",
      "Epoch 1174/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 5.1575e-07 - val_loss: 0.0711\n",
      "Epoch 1175/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 5.1240e-07 - val_loss: 0.0711\n",
      "Epoch 1176/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 5.0916e-07 - val_loss: 0.0711\n",
      "Epoch 1177/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 5.0591e-07 - val_loss: 0.0711\n",
      "Epoch 1178/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 5.0273e-07 - val_loss: 0.0711\n",
      "Epoch 1179/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 4.9959e-07 - val_loss: 0.0711\n",
      "Epoch 1180/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 4.9646e-07 - val_loss: 0.0711\n",
      "Epoch 1181/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 4.9341e-07 - val_loss: 0.0711\n",
      "Epoch 1182/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 4.9035e-07 - val_loss: 0.0711\n",
      "Epoch 1183/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 4.8737e-07 - val_loss: 0.0711\n",
      "Epoch 1184/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 4.8440e-07 - val_loss: 0.0711\n",
      "Epoch 1185/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 4.8148e-07 - val_loss: 0.0711\n",
      "Epoch 1186/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 4.7858e-07 - val_loss: 0.0711\n",
      "Epoch 1187/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 4.7572e-07 - val_loss: 0.0711\n",
      "Epoch 1188/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 4.7289e-07 - val_loss: 0.0711\n",
      "Epoch 1189/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 4.7009e-07 - val_loss: 0.0711\n",
      "Epoch 1190/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 4.6733e-07 - val_loss: 0.0711\n",
      "Epoch 1191/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 4.6459e-07 - val_loss: 0.0711\n",
      "Epoch 1192/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 4.6189e-07 - val_loss: 0.0711\n",
      "Epoch 1193/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 4.5921e-07 - val_loss: 0.0711\n",
      "Epoch 1194/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 4.5656e-07 - val_loss: 0.0711\n",
      "Epoch 1195/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 4.5394e-07 - val_loss: 0.0711\n",
      "Epoch 1196/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 4.5135e-07 - val_loss: 0.0711\n",
      "Epoch 1197/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 4.4878e-07 - val_loss: 0.0711\n",
      "Epoch 1198/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 4.4624e-07 - val_loss: 0.0711\n",
      "Epoch 1199/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 4.4373e-07 - val_loss: 0.0711\n",
      "Epoch 1200/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 4.4124e-07 - val_loss: 0.0711\n",
      "Epoch 1201/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 4.3878e-07 - val_loss: 0.0711\n",
      "Epoch 1202/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 4.3634e-07 - val_loss: 0.0711\n",
      "Epoch 1203/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 4.3393e-07 - val_loss: 0.0711\n",
      "Epoch 1204/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 4.3154e-07 - val_loss: 0.0711\n",
      "Epoch 1205/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 4.2917e-07 - val_loss: 0.0711\n",
      "Epoch 1206/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 4.2682e-07 - val_loss: 0.0711\n",
      "Epoch 1207/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 4.2450e-07 - val_loss: 0.0711\n",
      "Epoch 1208/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 4.2220e-07 - val_loss: 0.0711\n",
      "Epoch 1209/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 4.1992e-07 - val_loss: 0.0711\n",
      "Epoch 1210/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 4.1767e-07 - val_loss: 0.0711\n",
      "Epoch 1211/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 4.1543e-07 - val_loss: 0.0711\n",
      "Epoch 1212/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 4.1322e-07 - val_loss: 0.0711\n",
      "Epoch 1213/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 4.1102e-07 - val_loss: 0.0711\n",
      "Epoch 1214/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 4.0885e-07 - val_loss: 0.0711\n",
      "Epoch 1215/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 4.0670e-07 - val_loss: 0.0711\n",
      "Epoch 1216/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 4.0456e-07 - val_loss: 0.0711\n",
      "Epoch 1217/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 4.0244e-07 - val_loss: 0.0711\n",
      "Epoch 1218/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 4.0035e-07 - val_loss: 0.0711\n",
      "Epoch 1219/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 3.9827e-07 - val_loss: 0.0711\n",
      "Epoch 1220/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.9621e-07 - val_loss: 0.0711\n",
      "Epoch 1221/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.9416e-07 - val_loss: 0.0711\n",
      "Epoch 1222/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 3.9214e-07 - val_loss: 0.0711\n",
      "Epoch 1223/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.9013e-07 - val_loss: 0.0711\n",
      "Epoch 1224/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 3.8814e-07 - val_loss: 0.0711\n",
      "Epoch 1225/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.8617e-07 - val_loss: 0.0711\n",
      "Epoch 1226/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.8421e-07 - val_loss: 0.0711\n",
      "Epoch 1227/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 3.8227e-07 - val_loss: 0.0711\n",
      "Epoch 1228/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 3.8034e-07 - val_loss: 0.0711\n",
      "Epoch 1229/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 3.7843e-07 - val_loss: 0.0711\n",
      "Epoch 1230/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 3.7654e-07 - val_loss: 0.0711\n",
      "Epoch 1231/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.7466e-07 - val_loss: 0.0711\n",
      "Epoch 1232/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 3.7280e-07 - val_loss: 0.0711\n",
      "Epoch 1233/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 3.7095e-07 - val_loss: 0.0711\n",
      "Epoch 1234/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 3.6912e-07 - val_loss: 0.0711\n",
      "Epoch 1235/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.6730e-07 - val_loss: 0.0711\n",
      "Epoch 1236/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.6550e-07 - val_loss: 0.0711\n",
      "Epoch 1237/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 3.6371e-07 - val_loss: 0.0711\n",
      "Epoch 1238/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.6194e-07 - val_loss: 0.0711\n",
      "Epoch 1239/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.6018e-07 - val_loss: 0.0711\n",
      "Epoch 1240/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 3.5843e-07 - val_loss: 0.0711\n",
      "Epoch 1241/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 3.5669e-07 - val_loss: 0.0711\n",
      "Epoch 1242/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.5497e-07 - val_loss: 0.0711\n",
      "Epoch 1243/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 3.5327e-07 - val_loss: 0.0711\n",
      "Epoch 1244/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.5157e-07 - val_loss: 0.0711\n",
      "Epoch 1245/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 3.4989e-07 - val_loss: 0.0711\n",
      "Epoch 1246/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 3.4822e-07 - val_loss: 0.0711\n",
      "Epoch 1247/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 3.4656e-07 - val_loss: 0.0711\n",
      "Epoch 1248/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 3.4492e-07 - val_loss: 0.0711\n",
      "Epoch 1249/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 3.4329e-07 - val_loss: 0.0711\n",
      "Epoch 1250/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.4167e-07 - val_loss: 0.0711\n",
      "Epoch 1251/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.4006e-07 - val_loss: 0.0711\n",
      "Epoch 1252/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.3846e-07 - val_loss: 0.0711\n",
      "Epoch 1253/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 3.3688e-07 - val_loss: 0.0711\n",
      "Epoch 1254/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.3531e-07 - val_loss: 0.0711\n",
      "Epoch 1255/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.3374e-07 - val_loss: 0.0711\n",
      "Epoch 1256/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 3.3219e-07 - val_loss: 0.0711\n",
      "Epoch 1257/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 3.3065e-07 - val_loss: 0.0711\n",
      "Epoch 1258/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 3.2912e-07 - val_loss: 0.0711\n",
      "Epoch 1259/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 3.2761e-07 - val_loss: 0.0711\n",
      "Epoch 1260/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.2610e-07 - val_loss: 0.0711\n",
      "Epoch 1261/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 3.2460e-07 - val_loss: 0.0711\n",
      "Epoch 1262/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 3.2312e-07 - val_loss: 0.0711\n",
      "Epoch 1263/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.2164e-07 - val_loss: 0.0711\n",
      "Epoch 1264/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 3.2017e-07 - val_loss: 0.0711\n",
      "Epoch 1265/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 3.1872e-07 - val_loss: 0.0711\n",
      "Epoch 1266/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 3.1727e-07 - val_loss: 0.0711\n",
      "Epoch 1267/3000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 3.1584e-07 - val_loss: 0.0711\n",
      "Epoch 1268/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 3.1441e-07 - val_loss: 0.0711\n",
      "Epoch 1269/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 3.1299e-07 - val_loss: 0.0711\n",
      "Epoch 1270/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 3.1159e-07 - val_loss: 0.0711\n",
      "Epoch 1271/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 3.1019e-07 - val_loss: 0.0711\n",
      "Epoch 1272/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 3.0880e-07 - val_loss: 0.0711\n",
      "Epoch 1273/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.0742e-07 - val_loss: 0.0711\n",
      "Epoch 1274/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 3.0605e-07 - val_loss: 0.0711\n",
      "Epoch 1275/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 3.0469e-07 - val_loss: 0.0711\n",
      "Epoch 1276/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 3.0334e-07 - val_loss: 0.0711\n",
      "Epoch 1277/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 3.0200e-07 - val_loss: 0.0711\n",
      "Epoch 1278/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.0066e-07 - val_loss: 0.0711\n",
      "Epoch 1279/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.9934e-07 - val_loss: 0.0711\n",
      "Epoch 1280/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.9802e-07 - val_loss: 0.0711\n",
      "Epoch 1281/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.9671e-07 - val_loss: 0.0711\n",
      "Epoch 1282/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.9541e-07 - val_loss: 0.0711\n",
      "Epoch 1283/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.9412e-07 - val_loss: 0.0711\n",
      "Epoch 1284/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.9283e-07 - val_loss: 0.0711\n",
      "Epoch 1285/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.9156e-07 - val_loss: 0.0711\n",
      "Epoch 1286/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.9029e-07 - val_loss: 0.0711\n",
      "Epoch 1287/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.8903e-07 - val_loss: 0.0711\n",
      "Epoch 1288/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.8778e-07 - val_loss: 0.0711\n",
      "Epoch 1289/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.8654e-07 - val_loss: 0.0711\n",
      "Epoch 1290/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.8530e-07 - val_loss: 0.0711\n",
      "Epoch 1291/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.8407e-07 - val_loss: 0.0711\n",
      "Epoch 1292/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.8285e-07 - val_loss: 0.0711\n",
      "Epoch 1293/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.8164e-07 - val_loss: 0.0711\n",
      "Epoch 1294/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.8043e-07 - val_loss: 0.0711\n",
      "Epoch 1295/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.7923e-07 - val_loss: 0.0711\n",
      "Epoch 1296/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.7804e-07 - val_loss: 0.0711\n",
      "Epoch 1297/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.7685e-07 - val_loss: 0.0711\n",
      "Epoch 1298/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.7568e-07 - val_loss: 0.0711\n",
      "Epoch 1299/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 2.7451e-07 - val_loss: 0.0711\n",
      "Epoch 1300/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 2.7334e-07 - val_loss: 0.0711\n",
      "Epoch 1301/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.7219e-07 - val_loss: 0.0711\n",
      "Epoch 1302/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.7104e-07 - val_loss: 0.0711\n",
      "Epoch 1303/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.6990e-07 - val_loss: 0.0711\n",
      "Epoch 1304/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.6876e-07 - val_loss: 0.0711\n",
      "Epoch 1305/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.6763e-07 - val_loss: 0.0711\n",
      "Epoch 1306/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.6651e-07 - val_loss: 0.0711\n",
      "Epoch 1307/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.6539e-07 - val_loss: 0.0711\n",
      "Epoch 1308/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.6428e-07 - val_loss: 0.0711\n",
      "Epoch 1309/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.6318e-07 - val_loss: 0.0711\n",
      "Epoch 1310/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.6208e-07 - val_loss: 0.0711\n",
      "Epoch 1311/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.6099e-07 - val_loss: 0.0711\n",
      "Epoch 1312/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.5991e-07 - val_loss: 0.0711\n",
      "Epoch 1313/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.5883e-07 - val_loss: 0.0711\n",
      "Epoch 1314/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.5776e-07 - val_loss: 0.0711\n",
      "Epoch 1315/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 2.5670e-07 - val_loss: 0.0711\n",
      "Epoch 1316/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.5564e-07 - val_loss: 0.0711\n",
      "Epoch 1317/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 2.5458e-07 - val_loss: 0.0711\n",
      "Epoch 1318/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.5353e-07 - val_loss: 0.0711\n",
      "Epoch 1319/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.5249e-07 - val_loss: 0.0711\n",
      "Epoch 1320/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.5146e-07 - val_loss: 0.0711\n",
      "Epoch 1321/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.5043e-07 - val_loss: 0.0711\n",
      "Epoch 1322/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.4940e-07 - val_loss: 0.0711\n",
      "Epoch 1323/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.4838e-07 - val_loss: 0.0711\n",
      "Epoch 1324/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.4737e-07 - val_loss: 0.0711\n",
      "Epoch 1325/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.4636e-07 - val_loss: 0.0711\n",
      "Epoch 1326/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.4536e-07 - val_loss: 0.0711\n",
      "Epoch 1327/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.4437e-07 - val_loss: 0.0711\n",
      "Epoch 1328/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.4338e-07 - val_loss: 0.0711\n",
      "Epoch 1329/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.4239e-07 - val_loss: 0.0711\n",
      "Epoch 1330/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.4141e-07 - val_loss: 0.0711\n",
      "Epoch 1331/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.4043e-07 - val_loss: 0.0711\n",
      "Epoch 1332/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.3947e-07 - val_loss: 0.0711\n",
      "Epoch 1333/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.3850e-07 - val_loss: 0.0711\n",
      "Epoch 1334/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.3754e-07 - val_loss: 0.0711\n",
      "Epoch 1335/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.3659e-07 - val_loss: 0.0711\n",
      "Epoch 1336/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.3564e-07 - val_loss: 0.0711\n",
      "Epoch 1337/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.3470e-07 - val_loss: 0.0711\n",
      "Epoch 1338/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.3376e-07 - val_loss: 0.0711\n",
      "Epoch 1339/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.3282e-07 - val_loss: 0.0711\n",
      "Epoch 1340/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.3189e-07 - val_loss: 0.0711\n",
      "Epoch 1341/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 2.3097e-07 - val_loss: 0.0711\n",
      "Epoch 1342/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 2.3005e-07 - val_loss: 0.0711\n",
      "Epoch 1343/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.2914e-07 - val_loss: 0.0711\n",
      "Epoch 1344/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.2823e-07 - val_loss: 0.0711\n",
      "Epoch 1345/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.2732e-07 - val_loss: 0.0711\n",
      "Epoch 1346/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.2642e-07 - val_loss: 0.0711\n",
      "Epoch 1347/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.2553e-07 - val_loss: 0.0711\n",
      "Epoch 1348/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 2.2464e-07 - val_loss: 0.0711\n",
      "Epoch 1349/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 2.2375e-07 - val_loss: 0.0711\n",
      "Epoch 1350/3000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 2.2287e-07 - val_loss: 0.0711\n",
      "Epoch 1351/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 2.2199e-07 - val_loss: 0.0711\n",
      "Epoch 1352/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 2.2112e-07 - val_loss: 0.0711\n",
      "Epoch 1353/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 2.2025e-07 - val_loss: 0.0711\n",
      "Epoch 1354/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 2.1939e-07 - val_loss: 0.0711\n",
      "Epoch 1355/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 2.1853e-07 - val_loss: 0.0711\n",
      "Epoch 1356/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.1767e-07 - val_loss: 0.0711\n",
      "Epoch 1357/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.1682e-07 - val_loss: 0.0711\n",
      "Epoch 1358/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.1598e-07 - val_loss: 0.0711\n",
      "Epoch 1359/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.1513e-07 - val_loss: 0.0711\n",
      "Epoch 1360/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.1430e-07 - val_loss: 0.0711\n",
      "Epoch 1361/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.1346e-07 - val_loss: 0.0711\n",
      "Epoch 1362/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.1263e-07 - val_loss: 0.0711\n",
      "Epoch 1363/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.1181e-07 - val_loss: 0.0711\n",
      "Epoch 1364/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.1099e-07 - val_loss: 0.0711\n",
      "Epoch 1365/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.1017e-07 - val_loss: 0.0711\n",
      "Epoch 1366/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.0936e-07 - val_loss: 0.0711\n",
      "Epoch 1367/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 2.0855e-07 - val_loss: 0.0711\n",
      "Epoch 1368/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 2.0774e-07 - val_loss: 0.0711\n",
      "Epoch 1369/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.0694e-07 - val_loss: 0.0711\n",
      "Epoch 1370/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.0615e-07 - val_loss: 0.0711\n",
      "Epoch 1371/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.0535e-07 - val_loss: 0.0711\n",
      "Epoch 1372/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 2.0456e-07 - val_loss: 0.0711\n",
      "Epoch 1373/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.0378e-07 - val_loss: 0.0711\n",
      "Epoch 1374/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.0300e-07 - val_loss: 0.0711\n",
      "Epoch 1375/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.0222e-07 - val_loss: 0.0711\n",
      "Epoch 1376/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 2.0145e-07 - val_loss: 0.0711\n",
      "Epoch 1377/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.0068e-07 - val_loss: 0.0711\n",
      "Epoch 1378/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.9991e-07 - val_loss: 0.0711\n",
      "Epoch 1379/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.9915e-07 - val_loss: 0.0711\n",
      "Epoch 1380/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.9839e-07 - val_loss: 0.0711\n",
      "Epoch 1381/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.9763e-07 - val_loss: 0.0711\n",
      "Epoch 1382/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.9688e-07 - val_loss: 0.0711\n",
      "Epoch 1383/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1.9613e-07 - val_loss: 0.0711\n",
      "Epoch 1384/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 1.9539e-07 - val_loss: 0.0711\n",
      "Epoch 1385/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.9465e-07 - val_loss: 0.0711\n",
      "Epoch 1386/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.9391e-07 - val_loss: 0.0711\n",
      "Epoch 1387/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.9318e-07 - val_loss: 0.0711\n",
      "Epoch 1388/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.9245e-07 - val_loss: 0.0711\n",
      "Epoch 1389/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.9172e-07 - val_loss: 0.0711\n",
      "Epoch 1390/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.9100e-07 - val_loss: 0.0711\n",
      "Epoch 1391/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.9028e-07 - val_loss: 0.0711\n",
      "Epoch 1392/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.8956e-07 - val_loss: 0.0711\n",
      "Epoch 1393/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.8885e-07 - val_loss: 0.0711\n",
      "Epoch 1394/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.8814e-07 - val_loss: 0.0711\n",
      "Epoch 1395/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.8743e-07 - val_loss: 0.0711\n",
      "Epoch 1396/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.8673e-07 - val_loss: 0.0711\n",
      "Epoch 1397/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.8603e-07 - val_loss: 0.0711\n",
      "Epoch 1398/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.8534e-07 - val_loss: 0.0711\n",
      "Epoch 1399/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.8464e-07 - val_loss: 0.0711\n",
      "Epoch 1400/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.8395e-07 - val_loss: 0.0711\n",
      "Epoch 1401/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.8327e-07 - val_loss: 0.0711\n",
      "Epoch 1402/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.8258e-07 - val_loss: 0.0711\n",
      "Epoch 1403/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 1.8190e-07 - val_loss: 0.0711\n",
      "Epoch 1404/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.8123e-07 - val_loss: 0.0711\n",
      "Epoch 1405/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.8055e-07 - val_loss: 0.0711\n",
      "Epoch 1406/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.7988e-07 - val_loss: 0.0711\n",
      "Epoch 1407/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.7922e-07 - val_loss: 0.0711\n",
      "Epoch 1408/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.7855e-07 - val_loss: 0.0711\n",
      "Epoch 1409/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.7789e-07 - val_loss: 0.0711\n",
      "Epoch 1410/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.7723e-07 - val_loss: 0.0711\n",
      "Epoch 1411/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1.7658e-07 - val_loss: 0.0711\n",
      "Epoch 1412/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.7593e-07 - val_loss: 0.0711\n",
      "Epoch 1413/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.7528e-07 - val_loss: 0.0711\n",
      "Epoch 1414/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.7463e-07 - val_loss: 0.0711\n",
      "Epoch 1415/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.7399e-07 - val_loss: 0.0711\n",
      "Epoch 1416/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.7335e-07 - val_loss: 0.0711\n",
      "Epoch 1417/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.7271e-07 - val_loss: 0.0711\n",
      "Epoch 1418/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.7208e-07 - val_loss: 0.0711\n",
      "Epoch 1419/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.7145e-07 - val_loss: 0.0711\n",
      "Epoch 1420/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.7082e-07 - val_loss: 0.0712\n",
      "Epoch 1421/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.7019e-07 - val_loss: 0.0712\n",
      "Epoch 1422/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.6957e-07 - val_loss: 0.0712\n",
      "Epoch 1423/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.6895e-07 - val_loss: 0.0712\n",
      "Epoch 1424/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.6834e-07 - val_loss: 0.0712\n",
      "Epoch 1425/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.6772e-07 - val_loss: 0.0712\n",
      "Epoch 1426/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.6711e-07 - val_loss: 0.0712\n",
      "Epoch 1427/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.6651e-07 - val_loss: 0.0712\n",
      "Epoch 1428/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 1.6590e-07 - val_loss: 0.0712\n",
      "Epoch 1429/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.6530e-07 - val_loss: 0.0712\n",
      "Epoch 1430/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.6470e-07 - val_loss: 0.0712\n",
      "Epoch 1431/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.6410e-07 - val_loss: 0.0712\n",
      "Epoch 1432/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.6351e-07 - val_loss: 0.0712\n",
      "Epoch 1433/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.6292e-07 - val_loss: 0.0712\n",
      "Epoch 1434/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.6233e-07 - val_loss: 0.0712\n",
      "Epoch 1435/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.6174e-07 - val_loss: 0.0712\n",
      "Epoch 1436/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.6116e-07 - val_loss: 0.0712\n",
      "Epoch 1437/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.6058e-07 - val_loss: 0.0712\n",
      "Epoch 1438/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.6000e-07 - val_loss: 0.0712\n",
      "Epoch 1439/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.5943e-07 - val_loss: 0.0712\n",
      "Epoch 1440/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 1.5886e-07 - val_loss: 0.0712\n",
      "Epoch 1441/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 1.5829e-07 - val_loss: 0.0712\n",
      "Epoch 1442/3000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 1.5772e-07 - val_loss: 0.0712\n",
      "Epoch 1443/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 1.5715e-07 - val_loss: 0.0712\n",
      "Epoch 1444/3000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 1.5659e-07 - val_loss: 0.0712\n",
      "Epoch 1445/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 1.5603e-07 - val_loss: 0.0712\n",
      "Epoch 1446/3000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 1.5548e-07 - val_loss: 0.0712\n",
      "Epoch 1447/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 1.5492e-07 - val_loss: 0.0712\n",
      "Epoch 1448/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 1.5437e-07 - val_loss: 0.0712\n",
      "Epoch 1449/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.5382e-07 - val_loss: 0.0712\n",
      "Epoch 1450/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.5328e-07 - val_loss: 0.0712\n",
      "Epoch 1451/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.5273e-07 - val_loss: 0.0712\n",
      "Epoch 1452/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.5219e-07 - val_loss: 0.0712\n",
      "Epoch 1453/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 1.5165e-07 - val_loss: 0.0712\n",
      "Epoch 1454/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.5112e-07 - val_loss: 0.0712\n",
      "Epoch 1455/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.5058e-07 - val_loss: 0.0712\n",
      "Epoch 1456/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.5005e-07 - val_loss: 0.0712\n",
      "Epoch 1457/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.4952e-07 - val_loss: 0.0712\n",
      "Epoch 1458/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.4900e-07 - val_loss: 0.0712\n",
      "Epoch 1459/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.4847e-07 - val_loss: 0.0712\n",
      "Epoch 1460/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.4795e-07 - val_loss: 0.0712\n",
      "Epoch 1461/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.4743e-07 - val_loss: 0.0712\n",
      "Epoch 1462/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.4692e-07 - val_loss: 0.0712\n",
      "Epoch 1463/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.4640e-07 - val_loss: 0.0712\n",
      "Epoch 1464/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.4589e-07 - val_loss: 0.0712\n",
      "Epoch 1465/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.4538e-07 - val_loss: 0.0712\n",
      "Epoch 1466/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.4488e-07 - val_loss: 0.0712\n",
      "Epoch 1467/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.4437e-07 - val_loss: 0.0712\n",
      "Epoch 1468/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.4387e-07 - val_loss: 0.0712\n",
      "Epoch 1469/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.4337e-07 - val_loss: 0.0712\n",
      "Epoch 1470/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.4287e-07 - val_loss: 0.0712\n",
      "Epoch 1471/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.4238e-07 - val_loss: 0.0712\n",
      "Epoch 1472/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.4188e-07 - val_loss: 0.0712\n",
      "Epoch 1473/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.4139e-07 - val_loss: 0.0712\n",
      "Epoch 1474/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.4090e-07 - val_loss: 0.0712\n",
      "Epoch 1475/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.4042e-07 - val_loss: 0.0712\n",
      "Epoch 1476/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.3993e-07 - val_loss: 0.0712\n",
      "Epoch 1477/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.3945e-07 - val_loss: 0.0712\n",
      "Epoch 1478/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 1.3897e-07 - val_loss: 0.0712\n",
      "Epoch 1479/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.3850e-07 - val_loss: 0.0712\n",
      "Epoch 1480/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.3802e-07 - val_loss: 0.0712\n",
      "Epoch 1481/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.3755e-07 - val_loss: 0.0712\n",
      "Epoch 1482/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.3708e-07 - val_loss: 0.0712\n",
      "Epoch 1483/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.3661e-07 - val_loss: 0.0712\n",
      "Epoch 1484/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.3614e-07 - val_loss: 0.0712\n",
      "Epoch 1485/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.3568e-07 - val_loss: 0.0712\n",
      "Epoch 1486/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 1.3522e-07 - val_loss: 0.0712\n",
      "Epoch 1487/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.3476e-07 - val_loss: 0.0712\n",
      "Epoch 1488/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.3430e-07 - val_loss: 0.0712\n",
      "Epoch 1489/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.3385e-07 - val_loss: 0.0712\n",
      "Epoch 1490/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.3339e-07 - val_loss: 0.0712\n",
      "Epoch 1491/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.3294e-07 - val_loss: 0.0712\n",
      "Epoch 1492/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.3249e-07 - val_loss: 0.0712\n",
      "Epoch 1493/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.3205e-07 - val_loss: 0.0712\n",
      "Epoch 1494/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.3160e-07 - val_loss: 0.0712\n",
      "Epoch 1495/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.3116e-07 - val_loss: 0.0712\n",
      "Epoch 1496/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.3072e-07 - val_loss: 0.0712\n",
      "Epoch 1497/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.3028e-07 - val_loss: 0.0712\n",
      "Epoch 1498/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.2984e-07 - val_loss: 0.0712\n",
      "Epoch 1499/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.2941e-07 - val_loss: 0.0712\n",
      "Epoch 1500/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.2897e-07 - val_loss: 0.0712\n",
      "Epoch 1501/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.2854e-07 - val_loss: 0.0712\n",
      "Epoch 1502/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.2811e-07 - val_loss: 0.0712\n",
      "Epoch 1503/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.2769e-07 - val_loss: 0.0712\n",
      "Epoch 1504/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 1.2726e-07 - val_loss: 0.0712\n",
      "Epoch 1505/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 1.2684e-07 - val_loss: 0.0712\n",
      "Epoch 1506/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.2642e-07 - val_loss: 0.0712\n",
      "Epoch 1507/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.2600e-07 - val_loss: 0.0712\n",
      "Epoch 1508/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.2558e-07 - val_loss: 0.0712\n",
      "Epoch 1509/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.2517e-07 - val_loss: 0.0712\n",
      "Epoch 1510/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.2475e-07 - val_loss: 0.0712\n",
      "Epoch 1511/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.2434e-07 - val_loss: 0.0712\n",
      "Epoch 1512/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.2393e-07 - val_loss: 0.0712\n",
      "Epoch 1513/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.2353e-07 - val_loss: 0.0712\n",
      "Epoch 1514/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.2312e-07 - val_loss: 0.0712\n",
      "Epoch 1515/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.2272e-07 - val_loss: 0.0712\n",
      "Epoch 1516/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.2231e-07 - val_loss: 0.0712\n",
      "Epoch 1517/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.2191e-07 - val_loss: 0.0712\n",
      "Epoch 1518/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.2151e-07 - val_loss: 0.0712\n",
      "Epoch 1519/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.2112e-07 - val_loss: 0.0712\n",
      "Epoch 1520/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.2072e-07 - val_loss: 0.0712\n",
      "Epoch 1521/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.2033e-07 - val_loss: 0.0712\n",
      "Epoch 1522/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.1994e-07 - val_loss: 0.0712\n",
      "Epoch 1523/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.1955e-07 - val_loss: 0.0712\n",
      "Epoch 1524/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.1916e-07 - val_loss: 0.0712\n",
      "Epoch 1525/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.1877e-07 - val_loss: 0.0712\n",
      "Epoch 1526/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.1839e-07 - val_loss: 0.0712\n",
      "Epoch 1527/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 1.1801e-07 - val_loss: 0.0712\n",
      "Epoch 1528/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.1763e-07 - val_loss: 0.0712\n",
      "Epoch 1529/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.1725e-07 - val_loss: 0.0712\n",
      "Epoch 1530/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.1687e-07 - val_loss: 0.0712\n",
      "Epoch 1531/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.1649e-07 - val_loss: 0.0712\n",
      "Epoch 1532/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.1612e-07 - val_loss: 0.0712\n",
      "Epoch 1533/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.1575e-07 - val_loss: 0.0712\n",
      "Epoch 1534/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.1537e-07 - val_loss: 0.0712\n",
      "Epoch 1535/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.1500e-07 - val_loss: 0.0712\n",
      "Epoch 1536/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.1464e-07 - val_loss: 0.0712\n",
      "Epoch 1537/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.1427e-07 - val_loss: 0.0712\n",
      "Epoch 1538/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.1391e-07 - val_loss: 0.0712\n",
      "Epoch 1539/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.1354e-07 - val_loss: 0.0712\n",
      "Epoch 1540/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.1318e-07 - val_loss: 0.0712\n",
      "Epoch 1541/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.1282e-07 - val_loss: 0.0712\n",
      "Epoch 1542/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 1.1246e-07 - val_loss: 0.0712\n",
      "Epoch 1543/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 1.1211e-07 - val_loss: 0.0712\n",
      "Epoch 1544/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 1.1175e-07 - val_loss: 0.0712\n",
      "Epoch 1545/3000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 1.1140e-07 - val_loss: 0.0712\n",
      "Epoch 1546/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 1.1104e-07 - val_loss: 0.0712\n",
      "Epoch 1547/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 1.1069e-07 - val_loss: 0.0712\n",
      "Epoch 1548/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 1.1034e-07 - val_loss: 0.0712\n",
      "Epoch 1549/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 1.1000e-07 - val_loss: 0.0712\n",
      "Epoch 1550/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 1.0965e-07 - val_loss: 0.0712\n",
      "Epoch 1551/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1.0931e-07 - val_loss: 0.0712\n",
      "Epoch 1552/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.0896e-07 - val_loss: 0.0712\n",
      "Epoch 1553/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.0862e-07 - val_loss: 0.0712\n",
      "Epoch 1554/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.0828e-07 - val_loss: 0.0712\n",
      "Epoch 1555/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.0794e-07 - val_loss: 0.0712\n",
      "Epoch 1556/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.0760e-07 - val_loss: 0.0712\n",
      "Epoch 1557/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.0727e-07 - val_loss: 0.0712\n",
      "Epoch 1558/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.0693e-07 - val_loss: 0.0712\n",
      "Epoch 1559/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.0660e-07 - val_loss: 0.0712\n",
      "Epoch 1560/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.0627e-07 - val_loss: 0.0712\n",
      "Epoch 1561/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.0594e-07 - val_loss: 0.0712\n",
      "Epoch 1562/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.0561e-07 - val_loss: 0.0712\n",
      "Epoch 1563/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.0528e-07 - val_loss: 0.0712\n",
      "Epoch 1564/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.0495e-07 - val_loss: 0.0712\n",
      "Epoch 1565/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.0463e-07 - val_loss: 0.0712\n",
      "Epoch 1566/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.0431e-07 - val_loss: 0.0712\n",
      "Epoch 1567/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.0398e-07 - val_loss: 0.0712\n",
      "Epoch 1568/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.0366e-07 - val_loss: 0.0712\n",
      "Epoch 1569/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.0334e-07 - val_loss: 0.0712\n",
      "Epoch 1570/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.0302e-07 - val_loss: 0.0712\n",
      "Epoch 1571/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.0271e-07 - val_loss: 0.0712\n",
      "Epoch 1572/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.0239e-07 - val_loss: 0.0712\n",
      "Epoch 1573/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.0208e-07 - val_loss: 0.0712\n",
      "Epoch 1574/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.0176e-07 - val_loss: 0.0712\n",
      "Epoch 1575/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.0145e-07 - val_loss: 0.0712\n",
      "Epoch 1576/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.0114e-07 - val_loss: 0.0712\n",
      "Epoch 1577/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.0083e-07 - val_loss: 0.0712\n",
      "Epoch 1578/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.0052e-07 - val_loss: 0.0712\n",
      "Epoch 1579/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 1.0022e-07 - val_loss: 0.0712\n",
      "Epoch 1580/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 9.9910e-08 - val_loss: 0.0712\n",
      "Epoch 1581/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 9.9606e-08 - val_loss: 0.0712\n",
      "Epoch 1582/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 9.9303e-08 - val_loss: 0.0712\n",
      "Epoch 1583/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 9.9001e-08 - val_loss: 0.0712\n",
      "Epoch 1584/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 9.8700e-08 - val_loss: 0.0712\n",
      "Epoch 1585/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 9.8400e-08 - val_loss: 0.0712\n",
      "Epoch 1586/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 9.8102e-08 - val_loss: 0.0712\n",
      "Epoch 1587/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 9.7805e-08 - val_loss: 0.0712\n",
      "Epoch 1588/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 9.7509e-08 - val_loss: 0.0712\n",
      "Epoch 1589/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 9.7214e-08 - val_loss: 0.0712\n",
      "Epoch 1590/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 9.6921e-08 - val_loss: 0.0712\n",
      "Epoch 1591/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 9.6628e-08 - val_loss: 0.0712\n",
      "Epoch 1592/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 9.6337e-08 - val_loss: 0.0712\n",
      "Epoch 1593/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 9.6047e-08 - val_loss: 0.0712\n",
      "Epoch 1594/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 9.5758e-08 - val_loss: 0.0712\n",
      "Epoch 1595/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 9.5470e-08 - val_loss: 0.0712\n",
      "Epoch 1596/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 9.5184e-08 - val_loss: 0.0712\n",
      "Epoch 1597/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 9.4898e-08 - val_loss: 0.0712\n",
      "Epoch 1598/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 9.4614e-08 - val_loss: 0.0712\n",
      "Epoch 1599/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 9.4330e-08 - val_loss: 0.0712\n",
      "Epoch 1600/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 9.4048e-08 - val_loss: 0.0712\n",
      "Epoch 1601/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 9.3767e-08 - val_loss: 0.0712\n",
      "Epoch 1602/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 9.3487e-08 - val_loss: 0.0712\n",
      "Epoch 1603/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 9.3208e-08 - val_loss: 0.0712\n",
      "Epoch 1604/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 9.2931e-08 - val_loss: 0.0712\n",
      "Epoch 1605/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 9.2654e-08 - val_loss: 0.0712\n",
      "Epoch 1606/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 9.2378e-08 - val_loss: 0.0712\n",
      "Epoch 1607/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 9.2104e-08 - val_loss: 0.0712\n",
      "Epoch 1608/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 9.1831e-08 - val_loss: 0.0712\n",
      "Epoch 1609/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 9.1558e-08 - val_loss: 0.0712\n",
      "Epoch 1610/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 9.1287e-08 - val_loss: 0.0712\n",
      "Epoch 1611/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 9.1017e-08 - val_loss: 0.0712\n",
      "Epoch 1612/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 9.0747e-08 - val_loss: 0.0712\n",
      "Epoch 1613/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 9.0479e-08 - val_loss: 0.0712\n",
      "Epoch 1614/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 9.0212e-08 - val_loss: 0.0712\n",
      "Epoch 1615/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 8.9946e-08 - val_loss: 0.0712\n",
      "Epoch 1616/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 8.9681e-08 - val_loss: 0.0712\n",
      "Epoch 1617/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 8.9417e-08 - val_loss: 0.0712\n",
      "Epoch 1618/3000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 8.9154e-08 - val_loss: 0.0712\n",
      "Epoch 1619/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 8.8892e-08 - val_loss: 0.0712\n",
      "Epoch 1620/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 8.8631e-08 - val_loss: 0.0712\n",
      "Epoch 1621/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 8.8371e-08 - val_loss: 0.0712\n",
      "Epoch 1622/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 8.8112e-08 - val_loss: 0.0712\n",
      "Epoch 1623/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 8.7854e-08 - val_loss: 0.0712\n",
      "Epoch 1624/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 8.7597e-08 - val_loss: 0.0712\n",
      "Epoch 1625/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 8.7341e-08 - val_loss: 0.0712\n",
      "Epoch 1626/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 8.7086e-08 - val_loss: 0.0712\n",
      "Epoch 1627/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 8.6832e-08 - val_loss: 0.0712\n",
      "Epoch 1628/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 8.6579e-08 - val_loss: 0.0712\n",
      "Epoch 1629/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 8.6327e-08 - val_loss: 0.0712\n",
      "Epoch 1630/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 8.6076e-08 - val_loss: 0.0712\n",
      "Epoch 1631/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 8.5826e-08 - val_loss: 0.0712\n",
      "Epoch 1632/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 8.5577e-08 - val_loss: 0.0712\n",
      "Epoch 1633/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 8.5328e-08 - val_loss: 0.0712\n",
      "Epoch 1634/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 8.5081e-08 - val_loss: 0.0712\n",
      "Epoch 1635/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 8.4835e-08 - val_loss: 0.0712\n",
      "Epoch 1636/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 8.4589e-08 - val_loss: 0.0712\n",
      "Epoch 1637/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 8.4345e-08 - val_loss: 0.0712\n",
      "Epoch 1638/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 8.4101e-08 - val_loss: 0.0712\n",
      "Epoch 1639/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 8.3858e-08 - val_loss: 0.0712\n",
      "Epoch 1640/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 8.3617e-08 - val_loss: 0.0712\n",
      "Epoch 1641/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 8.3376e-08 - val_loss: 0.0712\n",
      "Epoch 1642/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 8.3136e-08 - val_loss: 0.0712\n",
      "Epoch 1643/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 8.2897e-08 - val_loss: 0.0712\n",
      "Epoch 1644/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 8.2659e-08 - val_loss: 0.0712\n",
      "Epoch 1645/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 8.2421e-08 - val_loss: 0.0712\n",
      "Epoch 1646/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 8.2185e-08 - val_loss: 0.0712\n",
      "Epoch 1647/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 8.1950e-08 - val_loss: 0.0712\n",
      "Epoch 1648/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 8.1715e-08 - val_loss: 0.0712\n",
      "Epoch 1649/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 8.1481e-08 - val_loss: 0.0712\n",
      "Epoch 1650/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 8.1249e-08 - val_loss: 0.0712\n",
      "Epoch 1651/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 8.1017e-08 - val_loss: 0.0712\n",
      "Epoch 1652/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 8.0786e-08 - val_loss: 0.0712\n",
      "Epoch 1653/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 8.0555e-08 - val_loss: 0.0712\n",
      "Epoch 1654/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 8.0326e-08 - val_loss: 0.0712\n",
      "Epoch 1655/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 8.0097e-08 - val_loss: 0.0712\n",
      "Epoch 1656/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.9870e-08 - val_loss: 0.0712\n",
      "Epoch 1657/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.9643e-08 - val_loss: 0.0712\n",
      "Epoch 1658/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 7.9417e-08 - val_loss: 0.0712\n",
      "Epoch 1659/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 7.9192e-08 - val_loss: 0.0712\n",
      "Epoch 1660/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 7.8968e-08 - val_loss: 0.0712\n",
      "Epoch 1661/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 7.8744e-08 - val_loss: 0.0712\n",
      "Epoch 1662/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.8522e-08 - val_loss: 0.0712\n",
      "Epoch 1663/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 7.8300e-08 - val_loss: 0.0712\n",
      "Epoch 1664/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 7.8079e-08 - val_loss: 0.0712\n",
      "Epoch 1665/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.7859e-08 - val_loss: 0.0712\n",
      "Epoch 1666/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.7640e-08 - val_loss: 0.0712\n",
      "Epoch 1667/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 7.7421e-08 - val_loss: 0.0712\n",
      "Epoch 1668/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.7204e-08 - val_loss: 0.0712\n",
      "Epoch 1669/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 7.6987e-08 - val_loss: 0.0712\n",
      "Epoch 1670/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 7.6771e-08 - val_loss: 0.0712\n",
      "Epoch 1671/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 7.6555e-08 - val_loss: 0.0712\n",
      "Epoch 1672/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.6341e-08 - val_loss: 0.0712\n",
      "Epoch 1673/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 7.6127e-08 - val_loss: 0.0712\n",
      "Epoch 1674/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.5914e-08 - val_loss: 0.0712\n",
      "Epoch 1675/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.5702e-08 - val_loss: 0.0712\n",
      "Epoch 1676/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 7.5491e-08 - val_loss: 0.0712\n",
      "Epoch 1677/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 7.5281e-08 - val_loss: 0.0712\n",
      "Epoch 1678/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 7.5071e-08 - val_loss: 0.0712\n",
      "Epoch 1679/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.4863e-08 - val_loss: 0.0712\n",
      "Epoch 1680/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 7.4655e-08 - val_loss: 0.0712\n",
      "Epoch 1681/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 7.4449e-08 - val_loss: 0.0712\n",
      "Epoch 1682/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 7.4244e-08 - val_loss: 0.0712\n",
      "Epoch 1683/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 7.4040e-08 - val_loss: 0.0712\n",
      "Epoch 1684/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.3839e-08 - val_loss: 0.0712\n",
      "Epoch 1685/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 7.3640e-08 - val_loss: 0.0712\n",
      "Epoch 1686/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 7.3446e-08 - val_loss: 0.0712\n",
      "Epoch 1687/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 7.3258e-08 - val_loss: 0.0712\n",
      "Epoch 1688/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 7.3079e-08 - val_loss: 0.0712\n",
      "Epoch 1689/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 7.2917e-08 - val_loss: 0.0712\n",
      "Epoch 1690/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 7.2779e-08 - val_loss: 0.0712\n",
      "Epoch 1691/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.2681e-08 - val_loss: 0.0712\n",
      "Epoch 1692/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 7.2651e-08 - val_loss: 0.0712\n",
      "Epoch 1693/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 7.2735e-08 - val_loss: 0.0712\n",
      "Epoch 1694/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 7.3011e-08 - val_loss: 0.0712\n",
      "Epoch 1695/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 7.3614e-08 - val_loss: 0.0712\n",
      "Epoch 1696/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 7.4781e-08 - val_loss: 0.0712\n",
      "Epoch 1697/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 7.6925e-08 - val_loss: 0.0712\n",
      "Epoch 1698/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 8.0768e-08 - val_loss: 0.0712\n",
      "Epoch 1699/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 8.7610e-08 - val_loss: 0.0712\n",
      "Epoch 1700/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 9.9727e-08 - val_loss: 0.0712\n",
      "Epoch 1701/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.2131e-07 - val_loss: 0.0712\n",
      "Epoch 1702/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.5971e-07 - val_loss: 0.0712\n",
      "Epoch 1703/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.2884e-07 - val_loss: 0.0712\n",
      "Epoch 1704/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.5296e-07 - val_loss: 0.0712\n",
      "Epoch 1705/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 5.7970e-07 - val_loss: 0.0712\n",
      "Epoch 1706/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 9.9065e-07 - val_loss: 0.0712\n",
      "Epoch 1707/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.7551e-06 - val_loss: 0.0712\n",
      "Epoch 1708/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 3.1502e-06 - val_loss: 0.0712\n",
      "Epoch 1709/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 5.8047e-06 - val_loss: 0.0712\n",
      "Epoch 1710/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.0656e-05 - val_loss: 0.0712\n",
      "Epoch 1711/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 2.0143e-05 - val_loss: 0.0712\n",
      "Epoch 1712/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 3.7291e-05 - val_loss: 0.0713\n",
      "Epoch 1713/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.2173e-05 - val_loss: 0.0712\n",
      "Epoch 1714/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.3374e-04 - val_loss: 0.0715\n",
      "Epoch 1715/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 2.6970e-04 - val_loss: 0.0716\n",
      "Epoch 1716/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 5.3540e-04 - val_loss: 0.0726\n",
      "Epoch 1717/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0016 - val_loss: 0.0809\n",
      "Epoch 1718/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0126 - val_loss: 0.1361\n",
      "Epoch 1719/3000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.1224 - val_loss: 0.1849\n",
      "Epoch 1720/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.1364 - val_loss: 0.1625\n",
      "Epoch 1721/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.1373 - val_loss: 0.2076\n",
      "Epoch 1722/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.1828 - val_loss: 0.2476\n",
      "Epoch 1723/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.2652 - val_loss: 0.2442\n",
      "Epoch 1724/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.2172 - val_loss: 0.2233\n",
      "Epoch 1725/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.1950 - val_loss: 0.2116\n",
      "Epoch 1726/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.2012 - val_loss: 0.2335\n",
      "Epoch 1727/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.2221 - val_loss: 0.2475\n",
      "Epoch 1728/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.2132 - val_loss: 0.2468\n",
      "Epoch 1729/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.2162 - val_loss: 0.2395\n",
      "Epoch 1730/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.1989 - val_loss: 0.2024\n",
      "Epoch 1731/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.1826 - val_loss: 0.2541\n",
      "Epoch 1732/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.2274 - val_loss: 0.1903\n",
      "Epoch 1733/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1898 - val_loss: 0.1906\n",
      "Epoch 1734/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1932 - val_loss: 0.2203\n",
      "Epoch 1735/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.2181 - val_loss: 0.2028\n",
      "Epoch 1736/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.2054 - val_loss: 0.2372\n",
      "Epoch 1737/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1990 - val_loss: 0.2446\n",
      "Epoch 1738/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.2092 - val_loss: 0.2444\n",
      "Epoch 1739/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.2020 - val_loss: 0.2461\n",
      "Epoch 1740/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.2030 - val_loss: 0.2465\n",
      "Epoch 1741/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.2038 - val_loss: 0.2220\n",
      "Epoch 1742/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1994 - val_loss: 0.2225\n",
      "Epoch 1743/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1971 - val_loss: 0.2119\n",
      "Epoch 1744/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1943 - val_loss: 0.1989\n",
      "Epoch 1745/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1964 - val_loss: 0.1931\n",
      "Epoch 1746/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1908 - val_loss: 0.2026\n",
      "Epoch 1747/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1913 - val_loss: 0.1934\n",
      "Epoch 1748/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1879 - val_loss: 0.1921\n",
      "Epoch 1749/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1867 - val_loss: 0.1897\n",
      "Epoch 1750/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.1840 - val_loss: 0.1875\n",
      "Epoch 1751/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1814 - val_loss: 0.1995\n",
      "Epoch 1752/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1862 - val_loss: 0.2243\n",
      "Epoch 1753/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1907 - val_loss: 0.2197\n",
      "Epoch 1754/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1873 - val_loss: 0.2246\n",
      "Epoch 1755/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.1893 - val_loss: 0.2267\n",
      "Epoch 1756/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.1874 - val_loss: 0.2285\n",
      "Epoch 1757/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1865 - val_loss: 0.2283\n",
      "Epoch 1758/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1849 - val_loss: 0.2299\n",
      "Epoch 1759/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1835 - val_loss: 0.2325\n",
      "Epoch 1760/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1815 - val_loss: 0.2384\n",
      "Epoch 1761/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.1798 - val_loss: 0.2407\n",
      "Epoch 1762/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1785 - val_loss: 0.2404\n",
      "Epoch 1763/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1769 - val_loss: 0.2411\n",
      "Epoch 1764/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1765 - val_loss: 0.2422\n",
      "Epoch 1765/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1788 - val_loss: 0.2417\n",
      "Epoch 1766/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1759 - val_loss: 0.2424\n",
      "Epoch 1767/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1763 - val_loss: 0.2426\n",
      "Epoch 1768/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1789 - val_loss: 0.2418\n",
      "Epoch 1769/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1776 - val_loss: 0.2416\n",
      "Epoch 1770/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1766 - val_loss: 0.2418\n",
      "Epoch 1771/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1762 - val_loss: 0.2417\n",
      "Epoch 1772/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1747 - val_loss: 0.2413\n",
      "Epoch 1773/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1735 - val_loss: 0.2407\n",
      "Epoch 1774/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1729 - val_loss: 0.2412\n",
      "Epoch 1775/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.1719 - val_loss: 0.2405\n",
      "Epoch 1776/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1713 - val_loss: 0.2412\n",
      "Epoch 1777/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1715 - val_loss: 0.2413\n",
      "Epoch 1778/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.1742 - val_loss: 0.2409\n",
      "Epoch 1779/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1717 - val_loss: 0.2394\n",
      "Epoch 1780/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1693 - val_loss: 0.2391\n",
      "Epoch 1781/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.1698 - val_loss: 0.2385\n",
      "Epoch 1782/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.1678 - val_loss: 0.2378\n",
      "Epoch 1783/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1677 - val_loss: 0.2358\n",
      "Epoch 1784/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1665 - val_loss: 0.2349\n",
      "Epoch 1785/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1662 - val_loss: 0.2282\n",
      "Epoch 1786/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1655 - val_loss: 0.2291\n",
      "Epoch 1787/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1655 - val_loss: 0.2271\n",
      "Epoch 1788/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1663 - val_loss: 0.2295\n",
      "Epoch 1789/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1651 - val_loss: 0.2218\n",
      "Epoch 1790/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1641 - val_loss: 0.2122\n",
      "Epoch 1791/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1639 - val_loss: 0.2277\n",
      "Epoch 1792/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1647 - val_loss: 0.2120\n",
      "Epoch 1793/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1647 - val_loss: 0.2191\n",
      "Epoch 1794/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1628 - val_loss: 0.2299\n",
      "Epoch 1795/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.1645 - val_loss: 0.2279\n",
      "Epoch 1796/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1645 - val_loss: 0.2319\n",
      "Epoch 1797/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1628 - val_loss: 0.2349\n",
      "Epoch 1798/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1638 - val_loss: 0.2310\n",
      "Epoch 1799/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1619 - val_loss: 0.2275\n",
      "Epoch 1800/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1620 - val_loss: 0.2314\n",
      "Epoch 1801/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.1612 - val_loss: 0.2343\n",
      "Epoch 1802/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1610 - val_loss: 0.2218\n",
      "Epoch 1803/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1604 - val_loss: 0.2107\n",
      "Epoch 1804/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.1600 - val_loss: 0.2101\n",
      "Epoch 1805/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1594 - val_loss: 0.2103\n",
      "Epoch 1806/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1592 - val_loss: 0.2093\n",
      "Epoch 1807/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.1586 - val_loss: 0.2092\n",
      "Epoch 1808/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.1584 - val_loss: 0.2092\n",
      "Epoch 1809/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1577 - val_loss: 0.2091\n",
      "Epoch 1810/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1574 - val_loss: 0.2091\n",
      "Epoch 1811/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1570 - val_loss: 0.2088\n",
      "Epoch 1812/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1564 - val_loss: 0.2084\n",
      "Epoch 1813/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1561 - val_loss: 0.2087\n",
      "Epoch 1814/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1558 - val_loss: 0.2084\n",
      "Epoch 1815/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1555 - val_loss: 0.2083\n",
      "Epoch 1816/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1550 - val_loss: 0.2083\n",
      "Epoch 1817/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.1547 - val_loss: 0.2082\n",
      "Epoch 1818/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.1544 - val_loss: 0.2081\n",
      "Epoch 1819/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1541 - val_loss: 0.2076\n",
      "Epoch 1820/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.1538 - val_loss: 0.2077\n",
      "Epoch 1821/3000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.1534 - val_loss: 0.2075\n",
      "Epoch 1822/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.1531 - val_loss: 0.2079\n",
      "Epoch 1823/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.1531 - val_loss: 0.2064\n",
      "Epoch 1824/3000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.1530 - val_loss: 0.2077\n",
      "Epoch 1825/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.1531 - val_loss: 0.2061\n",
      "Epoch 1826/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.1535 - val_loss: 0.2069\n",
      "Epoch 1827/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.1522 - val_loss: 0.2058\n",
      "Epoch 1828/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.1515 - val_loss: 0.2046\n",
      "Epoch 1829/3000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.1517 - val_loss: 0.2069\n",
      "Epoch 1830/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.1518 - val_loss: 0.2056\n",
      "Epoch 1831/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1523 - val_loss: 0.2065\n",
      "Epoch 1832/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1510 - val_loss: 0.2067\n",
      "Epoch 1833/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1516 - val_loss: 0.2090\n",
      "Epoch 1834/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.1528 - val_loss: 0.1951\n",
      "Epoch 1835/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1522 - val_loss: 0.1721\n",
      "Epoch 1836/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1543 - val_loss: 0.1662\n",
      "Epoch 1837/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1544 - val_loss: 0.1662\n",
      "Epoch 1838/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.1523 - val_loss: 0.1692\n",
      "Epoch 1839/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1524 - val_loss: 0.1664\n",
      "Epoch 1840/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1506 - val_loss: 0.1628\n",
      "Epoch 1841/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1509 - val_loss: 0.1640\n",
      "Epoch 1842/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1498 - val_loss: 0.1661\n",
      "Epoch 1843/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.1506 - val_loss: 0.1629\n",
      "Epoch 1844/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1484 - val_loss: 0.1627\n",
      "Epoch 1845/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.1485 - val_loss: 0.1635\n",
      "Epoch 1846/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1475 - val_loss: 0.1636\n",
      "Epoch 1847/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1438 - val_loss: 0.1733\n",
      "Epoch 1848/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.1450 - val_loss: 0.1632\n",
      "Epoch 1849/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1431 - val_loss: 0.1641\n",
      "Epoch 1850/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1451 - val_loss: 0.1644\n",
      "Epoch 1851/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.1464 - val_loss: 0.1637\n",
      "Epoch 1852/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1436 - val_loss: 0.1652\n",
      "Epoch 1853/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1405 - val_loss: 0.1658\n",
      "Epoch 1854/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1375 - val_loss: 0.1661\n",
      "Epoch 1855/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1337 - val_loss: 0.1783\n",
      "Epoch 1856/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1491 - val_loss: 0.1641\n",
      "Epoch 1857/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1477 - val_loss: 0.1761\n",
      "Epoch 1858/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1554 - val_loss: 0.1863\n",
      "Epoch 1859/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.1459 - val_loss: 0.1779\n",
      "Epoch 1860/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.1445 - val_loss: 0.1569\n",
      "Epoch 1861/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1411 - val_loss: 0.1474\n",
      "Epoch 1862/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1348 - val_loss: 0.1486\n",
      "Epoch 1863/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1356 - val_loss: 0.1827\n",
      "Epoch 1864/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1598 - val_loss: 0.1562\n",
      "Epoch 1865/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.1433 - val_loss: 0.1541\n",
      "Epoch 1866/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1452 - val_loss: 0.1624\n",
      "Epoch 1867/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1426 - val_loss: 0.1611\n",
      "Epoch 1868/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1347 - val_loss: 0.1439\n",
      "Epoch 1869/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1285 - val_loss: 0.1348\n",
      "Epoch 1870/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1193 - val_loss: 0.1624\n",
      "Epoch 1871/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1307 - val_loss: 0.1439\n",
      "Epoch 1872/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1198 - val_loss: 0.1281\n",
      "Epoch 1873/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1152 - val_loss: 0.1236\n",
      "Epoch 1874/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1060 - val_loss: 0.1272\n",
      "Epoch 1875/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.1062 - val_loss: 0.1202\n",
      "Epoch 1876/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0959 - val_loss: 0.1118\n",
      "Epoch 1877/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0910 - val_loss: 0.1181\n",
      "Epoch 1878/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0905 - val_loss: 0.1163\n",
      "Epoch 1879/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0879 - val_loss: 0.1074\n",
      "Epoch 1880/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0816 - val_loss: 0.0998\n",
      "Epoch 1881/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0785 - val_loss: 0.0984\n",
      "Epoch 1882/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0765 - val_loss: 0.0970\n",
      "Epoch 1883/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0724 - val_loss: 0.0961\n",
      "Epoch 1884/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0724 - val_loss: 0.0921\n",
      "Epoch 1885/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0677 - val_loss: 0.0924\n",
      "Epoch 1886/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0661 - val_loss: 0.0896\n",
      "Epoch 1887/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0648 - val_loss: 0.0858\n",
      "Epoch 1888/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0608 - val_loss: 0.0860\n",
      "Epoch 1889/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0601 - val_loss: 0.0824\n",
      "Epoch 1890/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0578 - val_loss: 0.0841\n",
      "Epoch 1891/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0571 - val_loss: 0.0798\n",
      "Epoch 1892/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0556 - val_loss: 0.0832\n",
      "Epoch 1893/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0553 - val_loss: 0.0814\n",
      "Epoch 1894/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0529 - val_loss: 0.0827\n",
      "Epoch 1895/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0498 - val_loss: 0.0799\n",
      "Epoch 1896/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0498 - val_loss: 0.0802\n",
      "Epoch 1897/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0492 - val_loss: 0.0795\n",
      "Epoch 1898/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0470 - val_loss: 0.0772\n",
      "Epoch 1899/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0451 - val_loss: 0.0775\n",
      "Epoch 1900/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0449 - val_loss: 0.0775\n",
      "Epoch 1901/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0441 - val_loss: 0.0758\n",
      "Epoch 1902/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0424 - val_loss: 0.0776\n",
      "Epoch 1903/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0416 - val_loss: 0.0797\n",
      "Epoch 1904/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0411 - val_loss: 0.0762\n",
      "Epoch 1905/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0400 - val_loss: 0.0762\n",
      "Epoch 1906/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0387 - val_loss: 0.0769\n",
      "Epoch 1907/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0384 - val_loss: 0.0776\n",
      "Epoch 1908/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0381 - val_loss: 0.0749\n",
      "Epoch 1909/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0374 - val_loss: 0.0948\n",
      "Epoch 1910/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0385 - val_loss: 0.0798\n",
      "Epoch 1911/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0444 - val_loss: 0.1194\n",
      "Epoch 1912/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0435 - val_loss: 0.0735\n",
      "Epoch 1913/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0371 - val_loss: 0.0771\n",
      "Epoch 1914/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0413 - val_loss: 0.0809\n",
      "Epoch 1915/3000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0410 - val_loss: 0.0767\n",
      "Epoch 1916/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0379 - val_loss: 0.0762\n",
      "Epoch 1917/3000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0379 - val_loss: 0.0761\n",
      "Epoch 1918/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0348 - val_loss: 0.0830\n",
      "Epoch 1919/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0369 - val_loss: 0.0767\n",
      "Epoch 1920/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0342 - val_loss: 0.0755\n",
      "Epoch 1921/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0338 - val_loss: 0.0759\n",
      "Epoch 1922/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0328 - val_loss: 0.0778\n",
      "Epoch 1923/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0330 - val_loss: 0.0758\n",
      "Epoch 1924/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0312 - val_loss: 0.0759\n",
      "Epoch 1925/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0312 - val_loss: 0.0771\n",
      "Epoch 1926/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0304 - val_loss: 0.0787\n",
      "Epoch 1927/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0298 - val_loss: 0.0763\n",
      "Epoch 1928/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0293 - val_loss: 0.0769\n",
      "Epoch 1929/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0287 - val_loss: 0.0761\n",
      "Epoch 1930/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0282 - val_loss: 0.0761\n",
      "Epoch 1931/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0278 - val_loss: 0.0773\n",
      "Epoch 1932/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0273 - val_loss: 0.0768\n",
      "Epoch 1933/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0266 - val_loss: 0.0769\n",
      "Epoch 1934/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0265 - val_loss: 0.0784\n",
      "Epoch 1935/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0258 - val_loss: 0.0788\n",
      "Epoch 1936/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0256 - val_loss: 0.0783\n",
      "Epoch 1937/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0249 - val_loss: 0.0786\n",
      "Epoch 1938/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0249 - val_loss: 0.0783\n",
      "Epoch 1939/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0241 - val_loss: 0.0793\n",
      "Epoch 1940/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0241 - val_loss: 0.0785\n",
      "Epoch 1941/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0235 - val_loss: 0.0787\n",
      "Epoch 1942/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0233 - val_loss: 0.0792\n",
      "Epoch 1943/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0228 - val_loss: 0.0800\n",
      "Epoch 1944/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0225 - val_loss: 0.0800\n",
      "Epoch 1945/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0222 - val_loss: 0.0798\n",
      "Epoch 1946/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0218 - val_loss: 0.0812\n",
      "Epoch 1947/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0216 - val_loss: 0.0803\n",
      "Epoch 1948/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0212 - val_loss: 0.0806\n",
      "Epoch 1949/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0210 - val_loss: 0.0805\n",
      "Epoch 1950/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0208 - val_loss: 0.0828\n",
      "Epoch 1951/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0207 - val_loss: 0.0812\n",
      "Epoch 1952/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0208 - val_loss: 0.0850\n",
      "Epoch 1953/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0213 - val_loss: 0.0833\n",
      "Epoch 1954/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0238 - val_loss: 0.0938\n",
      "Epoch 1955/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0262 - val_loss: 0.0872\n",
      "Epoch 1956/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0282 - val_loss: 0.0853\n",
      "Epoch 1957/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0235 - val_loss: 0.1085\n",
      "Epoch 1958/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0263 - val_loss: 0.0819\n",
      "Epoch 1959/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0263 - val_loss: 0.0804\n",
      "Epoch 1960/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0219 - val_loss: 0.0839\n",
      "Epoch 1961/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0229 - val_loss: 0.0807\n",
      "Epoch 1962/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0210 - val_loss: 0.0801\n",
      "Epoch 1963/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0213 - val_loss: 0.0791\n",
      "Epoch 1964/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0203 - val_loss: 0.0814\n",
      "Epoch 1965/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0200 - val_loss: 0.0830\n",
      "Epoch 1966/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0196 - val_loss: 0.0822\n",
      "Epoch 1967/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0192 - val_loss: 0.0812\n",
      "Epoch 1968/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0188 - val_loss: 0.0816\n",
      "Epoch 1969/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0184 - val_loss: 0.0817\n",
      "Epoch 1970/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0183 - val_loss: 0.0811\n",
      "Epoch 1971/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0177 - val_loss: 0.0816\n",
      "Epoch 1972/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0177 - val_loss: 0.0808\n",
      "Epoch 1973/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0171 - val_loss: 0.0811\n",
      "Epoch 1974/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0172 - val_loss: 0.0818\n",
      "Epoch 1975/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0166 - val_loss: 0.0815\n",
      "Epoch 1976/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0166 - val_loss: 0.0817\n",
      "Epoch 1977/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0163 - val_loss: 0.0823\n",
      "Epoch 1978/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0162 - val_loss: 0.0821\n",
      "Epoch 1979/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0159 - val_loss: 0.0821\n",
      "Epoch 1980/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0157 - val_loss: 0.0830\n",
      "Epoch 1981/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0156 - val_loss: 0.0832\n",
      "Epoch 1982/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0153 - val_loss: 0.0830\n",
      "Epoch 1983/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0153 - val_loss: 0.0826\n",
      "Epoch 1984/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0150 - val_loss: 0.0827\n",
      "Epoch 1985/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0149 - val_loss: 0.0834\n",
      "Epoch 1986/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0147 - val_loss: 0.0837\n",
      "Epoch 1987/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0146 - val_loss: 0.0833\n",
      "Epoch 1988/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0144 - val_loss: 0.0833\n",
      "Epoch 1989/3000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0143 - val_loss: 0.0841\n",
      "Epoch 1990/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0141 - val_loss: 0.0842\n",
      "Epoch 1991/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0140 - val_loss: 0.0839\n",
      "Epoch 1992/3000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0139 - val_loss: 0.0837\n",
      "Epoch 1993/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0138 - val_loss: 0.0838\n",
      "Epoch 1994/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0137 - val_loss: 0.0842\n",
      "Epoch 1995/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0136 - val_loss: 0.0845\n",
      "Epoch 1996/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0135 - val_loss: 0.0843\n",
      "Epoch 1997/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0134 - val_loss: 0.0842\n",
      "Epoch 1998/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0133 - val_loss: 0.0846\n",
      "Epoch 1999/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0132 - val_loss: 0.0847\n",
      "Epoch 2000/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0130 - val_loss: 0.0846\n",
      "Epoch 2001/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0130 - val_loss: 0.0847\n",
      "Epoch 2002/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0129 - val_loss: 0.0849\n",
      "Epoch 2003/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0128 - val_loss: 0.0848\n",
      "Epoch 2004/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0127 - val_loss: 0.0847\n",
      "Epoch 2005/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0126 - val_loss: 0.0848\n",
      "Epoch 2006/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0126 - val_loss: 0.0852\n",
      "Epoch 2007/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0125 - val_loss: 0.0853\n",
      "Epoch 2008/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0124 - val_loss: 0.0852\n",
      "Epoch 2009/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0123 - val_loss: 0.0853\n",
      "Epoch 2010/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0122 - val_loss: 0.0856\n",
      "Epoch 2011/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0121 - val_loss: 0.0855\n",
      "Epoch 2012/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0121 - val_loss: 0.0854\n",
      "Epoch 2013/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0120 - val_loss: 0.0854\n",
      "Epoch 2014/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0119 - val_loss: 0.0856\n",
      "Epoch 2015/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0118 - val_loss: 0.0858\n",
      "Epoch 2016/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0118 - val_loss: 0.0857\n",
      "Epoch 2017/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0117 - val_loss: 0.0857\n",
      "Epoch 2018/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0116 - val_loss: 0.0858\n",
      "Epoch 2019/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0115 - val_loss: 0.0860\n",
      "Epoch 2020/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0115 - val_loss: 0.0860\n",
      "Epoch 2021/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0114 - val_loss: 0.0860\n",
      "Epoch 2022/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0113 - val_loss: 0.0861\n",
      "Epoch 2023/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0113 - val_loss: 0.0863\n",
      "Epoch 2024/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0112 - val_loss: 0.0863\n",
      "Epoch 2025/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0112 - val_loss: 0.0863\n",
      "Epoch 2026/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0111 - val_loss: 0.0864\n",
      "Epoch 2027/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0110 - val_loss: 0.0864\n",
      "Epoch 2028/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0110 - val_loss: 0.0865\n",
      "Epoch 2029/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0109 - val_loss: 0.0865\n",
      "Epoch 2030/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0109 - val_loss: 0.0865\n",
      "Epoch 2031/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0108 - val_loss: 0.0866\n",
      "Epoch 2032/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0107 - val_loss: 0.0866\n",
      "Epoch 2033/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0107 - val_loss: 0.0867\n",
      "Epoch 2034/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0107 - val_loss: 0.0867\n",
      "Epoch 2035/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0106 - val_loss: 0.0868\n",
      "Epoch 2036/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0105 - val_loss: 0.0869\n",
      "Epoch 2037/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0105 - val_loss: 0.0868\n",
      "Epoch 2038/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0104 - val_loss: 0.0869\n",
      "Epoch 2039/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0104 - val_loss: 0.0869\n",
      "Epoch 2040/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0104 - val_loss: 0.0870\n",
      "Epoch 2041/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0103 - val_loss: 0.0870\n",
      "Epoch 2042/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0103 - val_loss: 0.0870\n",
      "Epoch 2043/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0102 - val_loss: 0.0870\n",
      "Epoch 2044/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0102 - val_loss: 0.0870\n",
      "Epoch 2045/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0101 - val_loss: 0.0871\n",
      "Epoch 2046/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0101 - val_loss: 0.0870\n",
      "Epoch 2047/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0100 - val_loss: 0.0871\n",
      "Epoch 2048/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0100 - val_loss: 0.0872\n",
      "Epoch 2049/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0100 - val_loss: 0.0872\n",
      "Epoch 2050/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0099 - val_loss: 0.0872\n",
      "Epoch 2051/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0099 - val_loss: 0.0871\n",
      "Epoch 2052/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0098 - val_loss: 0.0872\n",
      "Epoch 2053/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0098 - val_loss: 0.0871\n",
      "Epoch 2054/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0097 - val_loss: 0.0872\n",
      "Epoch 2055/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0097 - val_loss: 0.0872\n",
      "Epoch 2056/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0096 - val_loss: 0.0872\n",
      "Epoch 2057/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0096 - val_loss: 0.0873\n",
      "Epoch 2058/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0096 - val_loss: 0.0873\n",
      "Epoch 2059/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0095 - val_loss: 0.0873\n",
      "Epoch 2060/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0095 - val_loss: 0.0873\n",
      "Epoch 2061/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0095 - val_loss: 0.0873\n",
      "Epoch 2062/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0094 - val_loss: 0.0873\n",
      "Epoch 2063/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0094 - val_loss: 0.0873\n",
      "Epoch 2064/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0094 - val_loss: 0.0874\n",
      "Epoch 2065/3000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0093 - val_loss: 0.0875\n",
      "Epoch 2066/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0093 - val_loss: 0.0874\n",
      "Epoch 2067/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0093 - val_loss: 0.0875\n",
      "Epoch 2068/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0092 - val_loss: 0.0874\n",
      "Epoch 2069/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0092 - val_loss: 0.0875\n",
      "Epoch 2070/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0092 - val_loss: 0.0875\n",
      "Epoch 2071/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0092 - val_loss: 0.0876\n",
      "Epoch 2072/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0092 - val_loss: 0.0875\n",
      "Epoch 2073/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0092 - val_loss: 0.0877\n",
      "Epoch 2074/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0092 - val_loss: 0.0875\n",
      "Epoch 2075/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0093 - val_loss: 0.0879\n",
      "Epoch 2076/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0095 - val_loss: 0.0875\n",
      "Epoch 2077/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0096 - val_loss: 0.0881\n",
      "Epoch 2078/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0096 - val_loss: 0.0873\n",
      "Epoch 2079/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0093 - val_loss: 0.0878\n",
      "Epoch 2080/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0090 - val_loss: 0.0874\n",
      "Epoch 2081/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0091 - val_loss: 0.0875\n",
      "Epoch 2082/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0092 - val_loss: 0.0874\n",
      "Epoch 2083/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0090 - val_loss: 0.0871\n",
      "Epoch 2084/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0088 - val_loss: 0.0874\n",
      "Epoch 2085/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0089 - val_loss: 0.0873\n",
      "Epoch 2086/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0088 - val_loss: 0.0870\n",
      "Epoch 2087/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0088 - val_loss: 0.0871\n",
      "Epoch 2088/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0087 - val_loss: 0.0873\n",
      "Epoch 2089/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0087 - val_loss: 0.0871\n",
      "Epoch 2090/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0087 - val_loss: 0.0872\n",
      "Epoch 2091/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0086 - val_loss: 0.0873\n",
      "Epoch 2092/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0086 - val_loss: 0.0871\n",
      "Epoch 2093/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0086 - val_loss: 0.0873\n",
      "Epoch 2094/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0085 - val_loss: 0.0873\n",
      "Epoch 2095/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0085 - val_loss: 0.0872\n",
      "Epoch 2096/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0085 - val_loss: 0.0873\n",
      "Epoch 2097/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0085 - val_loss: 0.0873\n",
      "Epoch 2098/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0084 - val_loss: 0.0872\n",
      "Epoch 2099/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0084 - val_loss: 0.0873\n",
      "Epoch 2100/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0084 - val_loss: 0.0874\n",
      "Epoch 2101/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0083 - val_loss: 0.0872\n",
      "Epoch 2102/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0083 - val_loss: 0.0872\n",
      "Epoch 2103/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0083 - val_loss: 0.0872\n",
      "Epoch 2104/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0083 - val_loss: 0.0872\n",
      "Epoch 2105/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0083 - val_loss: 0.0873\n",
      "Epoch 2106/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0082 - val_loss: 0.0873\n",
      "Epoch 2107/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0082 - val_loss: 0.0873\n",
      "Epoch 2108/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0082 - val_loss: 0.0874\n",
      "Epoch 2109/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0082 - val_loss: 0.0874\n",
      "Epoch 2110/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0082 - val_loss: 0.0872\n",
      "Epoch 2111/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0081 - val_loss: 0.0873\n",
      "Epoch 2112/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0081 - val_loss: 0.0873\n",
      "Epoch 2113/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0081 - val_loss: 0.0873\n",
      "Epoch 2114/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0080 - val_loss: 0.0873\n",
      "Epoch 2115/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0080 - val_loss: 0.0873\n",
      "Epoch 2116/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0080 - val_loss: 0.0873\n",
      "Epoch 2117/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0080 - val_loss: 0.0873\n",
      "Epoch 2118/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0080 - val_loss: 0.0873\n",
      "Epoch 2119/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0080 - val_loss: 0.0873\n",
      "Epoch 2120/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0079 - val_loss: 0.0873\n",
      "Epoch 2121/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0079 - val_loss: 0.0873\n",
      "Epoch 2122/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0079 - val_loss: 0.0873\n",
      "Epoch 2123/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0079 - val_loss: 0.0873\n",
      "Epoch 2124/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0079 - val_loss: 0.0873\n",
      "Epoch 2125/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0079 - val_loss: 0.0874\n",
      "Epoch 2126/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0079 - val_loss: 0.0873\n",
      "Epoch 2127/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0078 - val_loss: 0.0873\n",
      "Epoch 2128/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0078 - val_loss: 0.0873\n",
      "Epoch 2129/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0078 - val_loss: 0.0872\n",
      "Epoch 2130/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0078 - val_loss: 0.0873\n",
      "Epoch 2131/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0078 - val_loss: 0.0873\n",
      "Epoch 2132/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0078 - val_loss: 0.0873\n",
      "Epoch 2133/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0077 - val_loss: 0.0873\n",
      "Epoch 2134/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0077 - val_loss: 0.0873\n",
      "Epoch 2135/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0077 - val_loss: 0.0873\n",
      "Epoch 2136/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0077 - val_loss: 0.0873\n",
      "Epoch 2137/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0077 - val_loss: 0.0873\n",
      "Epoch 2138/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0077 - val_loss: 0.0873\n",
      "Epoch 2139/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0077 - val_loss: 0.0873\n",
      "Epoch 2140/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0077 - val_loss: 0.0873\n",
      "Epoch 2141/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0076 - val_loss: 0.0873\n",
      "Epoch 2142/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0076 - val_loss: 0.0873\n",
      "Epoch 2143/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0076 - val_loss: 0.0873\n",
      "Epoch 2144/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0076 - val_loss: 0.0873\n",
      "Epoch 2145/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0076 - val_loss: 0.0873\n",
      "Epoch 2146/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0076 - val_loss: 0.0873\n",
      "Epoch 2147/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0076 - val_loss: 0.0873\n",
      "Epoch 2148/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0076 - val_loss: 0.0873\n",
      "Epoch 2149/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0076 - val_loss: 0.0873\n",
      "Epoch 2150/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0076 - val_loss: 0.0873\n",
      "Epoch 2151/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0076 - val_loss: 0.0873\n",
      "Epoch 2152/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0076 - val_loss: 0.0873\n",
      "Epoch 2153/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0075 - val_loss: 0.0873\n",
      "Epoch 2154/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0075 - val_loss: 0.0873\n",
      "Epoch 2155/3000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0075 - val_loss: 0.0873\n",
      "Epoch 2156/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0075 - val_loss: 0.0873\n",
      "Epoch 2157/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0075 - val_loss: 0.0874\n",
      "Epoch 2158/3000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0075 - val_loss: 0.0873\n",
      "Epoch 2159/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0075 - val_loss: 0.0874\n",
      "Epoch 2160/3000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0075 - val_loss: 0.0873\n",
      "Epoch 2161/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0075 - val_loss: 0.0874\n",
      "Epoch 2162/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0075 - val_loss: 0.0872\n",
      "Epoch 2163/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0075 - val_loss: 0.0874\n",
      "Epoch 2164/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0075 - val_loss: 0.0872\n",
      "Epoch 2165/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0075 - val_loss: 0.0875\n",
      "Epoch 2166/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0075 - val_loss: 0.0871\n",
      "Epoch 2167/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0075 - val_loss: 0.0877\n",
      "Epoch 2168/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0075 - val_loss: 0.0869\n",
      "Epoch 2169/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0075 - val_loss: 0.0881\n",
      "Epoch 2170/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0076 - val_loss: 0.0866\n",
      "Epoch 2171/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0077 - val_loss: 0.0886\n",
      "Epoch 2172/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0078 - val_loss: 0.0863\n",
      "Epoch 2173/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0079 - val_loss: 0.0889\n",
      "Epoch 2174/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0079 - val_loss: 0.0863\n",
      "Epoch 2175/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0078 - val_loss: 0.0879\n",
      "Epoch 2176/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0075 - val_loss: 0.0873\n",
      "Epoch 2177/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0074 - val_loss: 0.0866\n",
      "Epoch 2178/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0076 - val_loss: 0.0882\n",
      "Epoch 2179/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0076 - val_loss: 0.0864\n",
      "Epoch 2180/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0075 - val_loss: 0.0870\n",
      "Epoch 2181/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0074 - val_loss: 0.0877\n",
      "Epoch 2182/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0075 - val_loss: 0.0863\n",
      "Epoch 2183/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0075 - val_loss: 0.0872\n",
      "Epoch 2184/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0074 - val_loss: 0.0872\n",
      "Epoch 2185/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0074 - val_loss: 0.0867\n",
      "Epoch 2186/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0074 - val_loss: 0.0874\n",
      "Epoch 2187/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0074 - val_loss: 0.0870\n",
      "Epoch 2188/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0074 - val_loss: 0.0869\n",
      "Epoch 2189/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0074 - val_loss: 0.0872\n",
      "Epoch 2190/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0073 - val_loss: 0.0869\n",
      "Epoch 2191/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0074 - val_loss: 0.0871\n",
      "Epoch 2192/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0073 - val_loss: 0.0870\n",
      "Epoch 2193/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0073 - val_loss: 0.0870\n",
      "Epoch 2194/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0073 - val_loss: 0.0871\n",
      "Epoch 2195/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0073 - val_loss: 0.0869\n",
      "Epoch 2196/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0073 - val_loss: 0.0871\n",
      "Epoch 2197/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0073 - val_loss: 0.0870\n",
      "Epoch 2198/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0073 - val_loss: 0.0869\n",
      "Epoch 2199/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0073 - val_loss: 0.0872\n",
      "Epoch 2200/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0073 - val_loss: 0.0870\n",
      "Epoch 2201/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0073 - val_loss: 0.0870\n",
      "Epoch 2202/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0073 - val_loss: 0.0873\n",
      "Epoch 2203/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0073 - val_loss: 0.0869\n",
      "Epoch 2204/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0073 - val_loss: 0.0871\n",
      "Epoch 2205/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0073 - val_loss: 0.0872\n",
      "Epoch 2206/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0073 - val_loss: 0.0869\n",
      "Epoch 2207/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0073 - val_loss: 0.0872\n",
      "Epoch 2208/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0073 - val_loss: 0.0871\n",
      "Epoch 2209/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0072 - val_loss: 0.0869\n",
      "Epoch 2210/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0072 - val_loss: 0.0873\n",
      "Epoch 2211/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0072 - val_loss: 0.0871\n",
      "Epoch 2212/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0072 - val_loss: 0.0870\n",
      "Epoch 2213/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0072 - val_loss: 0.0872\n",
      "Epoch 2214/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0072 - val_loss: 0.0870\n",
      "Epoch 2215/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0072 - val_loss: 0.0871\n",
      "Epoch 2216/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0072 - val_loss: 0.0872\n",
      "Epoch 2217/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0072 - val_loss: 0.0870\n",
      "Epoch 2218/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0072 - val_loss: 0.0871\n",
      "Epoch 2219/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0072 - val_loss: 0.0871\n",
      "Epoch 2220/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0072 - val_loss: 0.0871\n",
      "Epoch 2221/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0072 - val_loss: 0.0871\n",
      "Epoch 2222/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0072 - val_loss: 0.0871\n",
      "Epoch 2223/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0071 - val_loss: 0.0871\n",
      "Epoch 2224/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0071 - val_loss: 0.0871\n",
      "Epoch 2225/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0071 - val_loss: 0.0871\n",
      "Epoch 2226/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0071 - val_loss: 0.0871\n",
      "Epoch 2227/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0071 - val_loss: 0.0870\n",
      "Epoch 2228/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0071 - val_loss: 0.0871\n",
      "Epoch 2229/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0071 - val_loss: 0.0871\n",
      "Epoch 2230/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0071 - val_loss: 0.0870\n",
      "Epoch 2231/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0071 - val_loss: 0.0871\n",
      "Epoch 2232/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0071 - val_loss: 0.0870\n",
      "Epoch 2233/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0071 - val_loss: 0.0870\n",
      "Epoch 2234/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0071 - val_loss: 0.0871\n",
      "Epoch 2235/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0071 - val_loss: 0.0870\n",
      "Epoch 2236/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0070 - val_loss: 0.0870\n",
      "Epoch 2237/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0070 - val_loss: 0.0870\n",
      "Epoch 2238/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0070 - val_loss: 0.0869\n",
      "Epoch 2239/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0070 - val_loss: 0.0870\n",
      "Epoch 2240/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0070 - val_loss: 0.0870\n",
      "Epoch 2241/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0070 - val_loss: 0.0870\n",
      "Epoch 2242/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0070 - val_loss: 0.0870\n",
      "Epoch 2243/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0070 - val_loss: 0.0870\n",
      "Epoch 2244/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0070 - val_loss: 0.0870\n",
      "Epoch 2245/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0070 - val_loss: 0.0870\n",
      "Epoch 2246/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0069 - val_loss: 0.0869\n",
      "Epoch 2247/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0069 - val_loss: 0.0870\n",
      "Epoch 2248/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0069 - val_loss: 0.0870\n",
      "Epoch 2249/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0069 - val_loss: 0.0870\n",
      "Epoch 2250/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0069 - val_loss: 0.0870\n",
      "Epoch 2251/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0069 - val_loss: 0.0870\n",
      "Epoch 2252/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0069 - val_loss: 0.0870\n",
      "Epoch 2253/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0069 - val_loss: 0.0870\n",
      "Epoch 2254/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0069 - val_loss: 0.0870\n",
      "Epoch 2255/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0069 - val_loss: 0.0870\n",
      "Epoch 2256/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0069 - val_loss: 0.0870\n",
      "Epoch 2257/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0069 - val_loss: 0.0870\n",
      "Epoch 2258/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0069 - val_loss: 0.0870\n",
      "Epoch 2259/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0069 - val_loss: 0.0870\n",
      "Epoch 2260/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0069 - val_loss: 0.0870\n",
      "Epoch 2261/3000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0069 - val_loss: 0.0870\n",
      "Epoch 2262/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0069 - val_loss: 0.0870\n",
      "Epoch 2263/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0069 - val_loss: 0.0870\n",
      "Epoch 2264/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0069 - val_loss: 0.0870\n",
      "Epoch 2265/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0069 - val_loss: 0.0870\n",
      "Epoch 2266/3000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0069 - val_loss: 0.0870\n",
      "Epoch 2267/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0069 - val_loss: 0.0870\n",
      "Epoch 2268/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0069 - val_loss: 0.0870\n",
      "Epoch 2269/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0069 - val_loss: 0.0870\n",
      "Epoch 2270/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0069 - val_loss: 0.0870\n",
      "Epoch 2271/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0069 - val_loss: 0.0870\n",
      "Epoch 2272/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0068 - val_loss: 0.0870\n",
      "Epoch 2273/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0068 - val_loss: 0.0870\n",
      "Epoch 2274/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0068 - val_loss: 0.0870\n",
      "Epoch 2275/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0068 - val_loss: 0.0870\n",
      "Epoch 2276/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0068 - val_loss: 0.0870\n",
      "Epoch 2277/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0068 - val_loss: 0.0870\n",
      "Epoch 2278/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0068 - val_loss: 0.0870\n",
      "Epoch 2279/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0068 - val_loss: 0.0870\n",
      "Epoch 2280/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0068 - val_loss: 0.0870\n",
      "Epoch 2281/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0068 - val_loss: 0.0869\n",
      "Epoch 2282/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0068 - val_loss: 0.0870\n",
      "Epoch 2283/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0068 - val_loss: 0.0870\n",
      "Epoch 2284/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0068 - val_loss: 0.0869\n",
      "Epoch 2285/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0068 - val_loss: 0.0870\n",
      "Epoch 2286/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0068 - val_loss: 0.0870\n",
      "Epoch 2287/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0068 - val_loss: 0.0869\n",
      "Epoch 2288/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0068 - val_loss: 0.0869\n",
      "Epoch 2289/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0068 - val_loss: 0.0869\n",
      "Epoch 2290/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0068 - val_loss: 0.0870\n",
      "Epoch 2291/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0068 - val_loss: 0.0870\n",
      "Epoch 2292/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0068 - val_loss: 0.0870\n",
      "Epoch 2293/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0068 - val_loss: 0.0870\n",
      "Epoch 2294/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0068 - val_loss: 0.0869\n",
      "Epoch 2295/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0068 - val_loss: 0.0869\n",
      "Epoch 2296/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0068 - val_loss: 0.0869\n",
      "Epoch 2297/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0068 - val_loss: 0.0869\n",
      "Epoch 2298/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0068 - val_loss: 0.0869\n",
      "Epoch 2299/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0068 - val_loss: 0.0869\n",
      "Epoch 2300/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0067 - val_loss: 0.0869\n",
      "Epoch 2301/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0067 - val_loss: 0.0869\n",
      "Epoch 2302/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0067 - val_loss: 0.0869\n",
      "Epoch 2303/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0067 - val_loss: 0.0869\n",
      "Epoch 2304/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0067 - val_loss: 0.0869\n",
      "Epoch 2305/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0067 - val_loss: 0.0869\n",
      "Epoch 2306/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0067 - val_loss: 0.0869\n",
      "Epoch 2307/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0067 - val_loss: 0.0869\n",
      "Epoch 2308/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0067 - val_loss: 0.0869\n",
      "Epoch 2309/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0067 - val_loss: 0.0869\n",
      "Epoch 2310/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0067 - val_loss: 0.0869\n",
      "Epoch 2311/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0067 - val_loss: 0.0869\n",
      "Epoch 2312/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0067 - val_loss: 0.0869\n",
      "Epoch 2313/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0067 - val_loss: 0.0869\n",
      "Epoch 2314/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0067 - val_loss: 0.0869\n",
      "Epoch 2315/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0067 - val_loss: 0.0869\n",
      "Epoch 2316/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2317/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2318/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2319/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2320/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2321/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0066 - val_loss: 0.0868\n",
      "Epoch 2322/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0066 - val_loss: 0.0868\n",
      "Epoch 2323/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2324/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2325/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2326/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2327/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2328/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2329/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2330/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2331/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2332/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2333/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2334/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2335/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2336/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2337/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2338/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2339/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2340/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2341/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2342/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2343/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2344/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2345/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2346/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2347/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2348/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2349/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2350/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2351/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2352/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2353/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2354/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2355/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2356/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2357/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2358/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2359/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2360/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0066 - val_loss: 0.0869\n",
      "Epoch 2361/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2362/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2363/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2364/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2365/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2366/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2367/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2368/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2369/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2370/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2371/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2372/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2373/3000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2374/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2375/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2376/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2377/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2378/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2379/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2380/3000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2381/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2382/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2383/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2384/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2385/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2386/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2387/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2388/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2389/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2390/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2391/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2392/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2393/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2394/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2395/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2396/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2397/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2398/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2399/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2400/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2401/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2402/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2403/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2404/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2405/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2406/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2407/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2408/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2409/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2410/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2411/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2412/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2413/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2414/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2415/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2416/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2417/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2418/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2419/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2420/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2421/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2422/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2423/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2424/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2425/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2426/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2427/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2428/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2429/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2430/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2431/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2432/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2433/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0064 - val_loss: 0.0869\n",
      "Epoch 2434/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0064 - val_loss: 0.0869\n",
      "Epoch 2435/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0064 - val_loss: 0.0869\n",
      "Epoch 2436/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0064 - val_loss: 0.0869\n",
      "Epoch 2437/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0064 - val_loss: 0.0869\n",
      "Epoch 2438/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0064 - val_loss: 0.0869\n",
      "Epoch 2439/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0064 - val_loss: 0.0869\n",
      "Epoch 2440/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0064 - val_loss: 0.0869\n",
      "Epoch 2441/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0064 - val_loss: 0.0869\n",
      "Epoch 2442/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0064 - val_loss: 0.0869\n",
      "Epoch 2443/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0064 - val_loss: 0.0869\n",
      "Epoch 2444/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0064 - val_loss: 0.0869\n",
      "Epoch 2445/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0064 - val_loss: 0.0869\n",
      "Epoch 2446/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0064 - val_loss: 0.0870\n",
      "Epoch 2447/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0064 - val_loss: 0.0868\n",
      "Epoch 2448/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0064 - val_loss: 0.0870\n",
      "Epoch 2449/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0064 - val_loss: 0.0868\n",
      "Epoch 2450/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0064 - val_loss: 0.0870\n",
      "Epoch 2451/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0064 - val_loss: 0.0867\n",
      "Epoch 2452/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0064 - val_loss: 0.0872\n",
      "Epoch 2453/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0064 - val_loss: 0.0866\n",
      "Epoch 2454/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0065 - val_loss: 0.0874\n",
      "Epoch 2455/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0065 - val_loss: 0.0863\n",
      "Epoch 2456/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0066 - val_loss: 0.0877\n",
      "Epoch 2457/3000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0067 - val_loss: 0.0861\n",
      "Epoch 2458/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0068 - val_loss: 0.0880\n",
      "Epoch 2459/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0069 - val_loss: 0.0861\n",
      "Epoch 2460/3000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0069 - val_loss: 0.0875\n",
      "Epoch 2461/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0067 - val_loss: 0.0865\n",
      "Epoch 2462/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0065 - val_loss: 0.0865\n",
      "Epoch 2463/3000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0064 - val_loss: 0.0872\n",
      "Epoch 2464/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0065 - val_loss: 0.0860\n",
      "Epoch 2465/3000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0066 - val_loss: 0.0874\n",
      "Epoch 2466/3000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0066 - val_loss: 0.0864\n",
      "Epoch 2467/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0064 - val_loss: 0.0864\n",
      "Epoch 2468/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0064 - val_loss: 0.0871\n",
      "Epoch 2469/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0065 - val_loss: 0.0860\n",
      "Epoch 2470/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0065 - val_loss: 0.0869\n",
      "Epoch 2471/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0064 - val_loss: 0.0866\n",
      "Epoch 2472/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0064 - val_loss: 0.0863\n",
      "Epoch 2473/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0064 - val_loss: 0.0870\n",
      "Epoch 2474/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0064 - val_loss: 0.0863\n",
      "Epoch 2475/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0064 - val_loss: 0.0867\n",
      "Epoch 2476/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0063 - val_loss: 0.0867\n",
      "Epoch 2477/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0063 - val_loss: 0.0863\n",
      "Epoch 2478/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0064 - val_loss: 0.0868\n",
      "Epoch 2479/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0064 - val_loss: 0.0864\n",
      "Epoch 2480/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0063 - val_loss: 0.0866\n",
      "Epoch 2481/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0063 - val_loss: 0.0868\n",
      "Epoch 2482/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0063 - val_loss: 0.0864\n",
      "Epoch 2483/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0063 - val_loss: 0.0868\n",
      "Epoch 2484/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0063 - val_loss: 0.0867\n",
      "Epoch 2485/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0063 - val_loss: 0.0866\n",
      "Epoch 2486/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0063 - val_loss: 0.0868\n",
      "Epoch 2487/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0063 - val_loss: 0.0866\n",
      "Epoch 2488/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0063 - val_loss: 0.0867\n",
      "Epoch 2489/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0063 - val_loss: 0.0867\n",
      "Epoch 2490/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0063 - val_loss: 0.0866\n",
      "Epoch 2491/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0063 - val_loss: 0.0867\n",
      "Epoch 2492/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0063 - val_loss: 0.0866\n",
      "Epoch 2493/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0063 - val_loss: 0.0866\n",
      "Epoch 2494/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0062 - val_loss: 0.0866\n",
      "Epoch 2495/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0062 - val_loss: 0.0866\n",
      "Epoch 2496/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0062 - val_loss: 0.0866\n",
      "Epoch 2497/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0062 - val_loss: 0.0866\n",
      "Epoch 2498/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0062 - val_loss: 0.0866\n",
      "Epoch 2499/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0062 - val_loss: 0.0866\n",
      "Epoch 2500/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0062 - val_loss: 0.0865\n",
      "Epoch 2501/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0062 - val_loss: 0.0866\n",
      "Epoch 2502/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0062 - val_loss: 0.0865\n",
      "Epoch 2503/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0062 - val_loss: 0.0865\n",
      "Epoch 2504/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0062 - val_loss: 0.0866\n",
      "Epoch 2505/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0062 - val_loss: 0.0865\n",
      "Epoch 2506/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0062 - val_loss: 0.0866\n",
      "Epoch 2507/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0062 - val_loss: 0.0865\n",
      "Epoch 2508/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0062 - val_loss: 0.0865\n",
      "Epoch 2509/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0062 - val_loss: 0.0866\n",
      "Epoch 2510/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2511/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0062 - val_loss: 0.0865\n",
      "Epoch 2512/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0062 - val_loss: 0.0865\n",
      "Epoch 2513/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0061 - val_loss: 0.0864\n",
      "Epoch 2514/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2515/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2516/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2517/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2518/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2519/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2520/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2521/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2522/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2523/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2524/3000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2525/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2526/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2527/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2528/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2529/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2530/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2531/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2532/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2533/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2534/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2535/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2536/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2537/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2538/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2539/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2540/3000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2541/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2542/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2543/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2544/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2545/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2546/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2547/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2548/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2549/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2550/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2551/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2552/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2553/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2554/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2555/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2556/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2557/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2558/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2559/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2560/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2561/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2562/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2563/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2564/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0061 - val_loss: 0.0865\n",
      "Epoch 2565/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0061 - val_loss: 0.0866\n",
      "Epoch 2566/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0061 - val_loss: 0.0866\n",
      "Epoch 2567/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0061 - val_loss: 0.0866\n",
      "Epoch 2568/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0061 - val_loss: 0.0866\n",
      "Epoch 2569/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0061 - val_loss: 0.0866\n",
      "Epoch 2570/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0061 - val_loss: 0.0866\n",
      "Epoch 2571/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0061 - val_loss: 0.0866\n",
      "Epoch 2572/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0061 - val_loss: 0.0866\n",
      "Epoch 2573/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0061 - val_loss: 0.0866\n",
      "Epoch 2574/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0061 - val_loss: 0.0866\n",
      "Epoch 2575/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0061 - val_loss: 0.0866\n",
      "Epoch 2576/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0061 - val_loss: 0.0866\n",
      "Epoch 2577/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0061 - val_loss: 0.0866\n",
      "Epoch 2578/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0061 - val_loss: 0.0866\n",
      "Epoch 2579/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0061 - val_loss: 0.0866\n",
      "Epoch 2580/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0061 - val_loss: 0.0866\n",
      "Epoch 2581/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0061 - val_loss: 0.0866\n",
      "Epoch 2582/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0061 - val_loss: 0.0866\n",
      "Epoch 2583/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0061 - val_loss: 0.0866\n",
      "Epoch 2584/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0061 - val_loss: 0.0866\n",
      "Epoch 2585/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0061 - val_loss: 0.0866\n",
      "Epoch 2586/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0061 - val_loss: 0.0866\n",
      "Epoch 2587/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0061 - val_loss: 0.0866\n",
      "Epoch 2588/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0061 - val_loss: 0.0866\n",
      "Epoch 2589/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0061 - val_loss: 0.0866\n",
      "Epoch 2590/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0060 - val_loss: 0.0866\n",
      "Epoch 2591/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0060 - val_loss: 0.0865\n",
      "Epoch 2592/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0060 - val_loss: 0.0866\n",
      "Epoch 2593/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0060 - val_loss: 0.0866\n",
      "Epoch 2594/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0060 - val_loss: 0.0865\n",
      "Epoch 2595/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0060 - val_loss: 0.0865\n",
      "Epoch 2596/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0060 - val_loss: 0.0865\n",
      "Epoch 2597/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0060 - val_loss: 0.0865\n",
      "Epoch 2598/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0060 - val_loss: 0.0865\n",
      "Epoch 2599/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0060 - val_loss: 0.0865\n",
      "Epoch 2600/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0060 - val_loss: 0.0865\n",
      "Epoch 2601/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0060 - val_loss: 0.0865\n",
      "Epoch 2602/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0059 - val_loss: 0.0865\n",
      "Epoch 2603/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0059 - val_loss: 0.0865\n",
      "Epoch 2604/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0059 - val_loss: 0.0865\n",
      "Epoch 2605/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0059 - val_loss: 0.0865\n",
      "Epoch 2606/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0059 - val_loss: 0.0865\n",
      "Epoch 2607/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0059 - val_loss: 0.0864\n",
      "Epoch 2608/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0059 - val_loss: 0.0864\n",
      "Epoch 2609/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0059 - val_loss: 0.0864\n",
      "Epoch 2610/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0059 - val_loss: 0.0865\n",
      "Epoch 2611/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0059 - val_loss: 0.0864\n",
      "Epoch 2612/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0059 - val_loss: 0.0865\n",
      "Epoch 2613/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0059 - val_loss: 0.0865\n",
      "Epoch 2614/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0059 - val_loss: 0.0865\n",
      "Epoch 2615/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0059 - val_loss: 0.0864\n",
      "Epoch 2616/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0059 - val_loss: 0.0865\n",
      "Epoch 2617/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0059 - val_loss: 0.0864\n",
      "Epoch 2618/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0059 - val_loss: 0.0865\n",
      "Epoch 2619/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0059 - val_loss: 0.0864\n",
      "Epoch 2620/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0059 - val_loss: 0.0865\n",
      "Epoch 2621/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0059 - val_loss: 0.0864\n",
      "Epoch 2622/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0059 - val_loss: 0.0865\n",
      "Epoch 2623/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0059 - val_loss: 0.0864\n",
      "Epoch 2624/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0059 - val_loss: 0.0865\n",
      "Epoch 2625/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0059 - val_loss: 0.0864\n",
      "Epoch 2626/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0059 - val_loss: 0.0865\n",
      "Epoch 2627/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0059 - val_loss: 0.0864\n",
      "Epoch 2628/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0059 - val_loss: 0.0865\n",
      "Epoch 2629/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0059 - val_loss: 0.0864\n",
      "Epoch 2630/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0059 - val_loss: 0.0865\n",
      "Epoch 2631/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0059 - val_loss: 0.0864\n",
      "Epoch 2632/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0059 - val_loss: 0.0865\n",
      "Epoch 2633/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0059 - val_loss: 0.0864\n",
      "Epoch 2634/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0059 - val_loss: 0.0865\n",
      "Epoch 2635/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0059 - val_loss: 0.0863\n",
      "Epoch 2636/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0059 - val_loss: 0.0866\n",
      "Epoch 2637/3000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0059 - val_loss: 0.0863\n",
      "Epoch 2638/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0059 - val_loss: 0.0866\n",
      "Epoch 2639/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0059 - val_loss: 0.0862\n",
      "Epoch 2640/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0059 - val_loss: 0.0867\n",
      "Epoch 2641/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0059 - val_loss: 0.0861\n",
      "Epoch 2642/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0059 - val_loss: 0.0869\n",
      "Epoch 2643/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0059 - val_loss: 0.0861\n",
      "Epoch 2644/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0060 - val_loss: 0.0871\n",
      "Epoch 2645/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0060 - val_loss: 0.0860\n",
      "Epoch 2646/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0061 - val_loss: 0.0872\n",
      "Epoch 2647/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0061 - val_loss: 0.0858\n",
      "Epoch 2648/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0061 - val_loss: 0.0871\n",
      "Epoch 2649/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0060 - val_loss: 0.0859\n",
      "Epoch 2650/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0059 - val_loss: 0.0863\n",
      "Epoch 2651/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0059 - val_loss: 0.0865\n",
      "Epoch 2652/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0059 - val_loss: 0.0859\n",
      "Epoch 2653/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0060 - val_loss: 0.0866\n",
      "Epoch 2654/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0059 - val_loss: 0.0859\n",
      "Epoch 2655/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0058 - val_loss: 0.0859\n",
      "Epoch 2656/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0059 - val_loss: 0.0864\n",
      "Epoch 2657/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0059 - val_loss: 0.0858\n",
      "Epoch 2658/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0059 - val_loss: 0.0861\n",
      "Epoch 2659/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0058 - val_loss: 0.0864\n",
      "Epoch 2660/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0058 - val_loss: 0.0858\n",
      "Epoch 2661/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0058 - val_loss: 0.0863\n",
      "Epoch 2662/3000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0058 - val_loss: 0.0860\n",
      "Epoch 2663/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0058 - val_loss: 0.0858\n",
      "Epoch 2664/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0058 - val_loss: 0.0864\n",
      "Epoch 2665/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0058 - val_loss: 0.0858\n",
      "Epoch 2666/3000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0058 - val_loss: 0.0861\n",
      "Epoch 2667/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0058 - val_loss: 0.0862\n",
      "Epoch 2668/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0058 - val_loss: 0.0858\n",
      "Epoch 2669/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0058 - val_loss: 0.0862\n",
      "Epoch 2670/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0058 - val_loss: 0.0861\n",
      "Epoch 2671/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0058 - val_loss: 0.0859\n",
      "Epoch 2672/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0058 - val_loss: 0.0862\n",
      "Epoch 2673/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0058 - val_loss: 0.0861\n",
      "Epoch 2674/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0057 - val_loss: 0.0860\n",
      "Epoch 2675/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0057 - val_loss: 0.0863\n",
      "Epoch 2676/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0057 - val_loss: 0.0859\n",
      "Epoch 2677/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2678/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0057 - val_loss: 0.0862\n",
      "Epoch 2679/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0057 - val_loss: 0.0859\n",
      "Epoch 2680/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0057 - val_loss: 0.0862\n",
      "Epoch 2681/3000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2682/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0057 - val_loss: 0.0860\n",
      "Epoch 2683/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2684/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0057 - val_loss: 0.0860\n",
      "Epoch 2685/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0057 - val_loss: 0.0860\n",
      "Epoch 2686/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2687/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0057 - val_loss: 0.0860\n",
      "Epoch 2688/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2689/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2690/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0057 - val_loss: 0.0860\n",
      "Epoch 2691/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2692/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2693/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0057 - val_loss: 0.0860\n",
      "Epoch 2694/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2695/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0057 - val_loss: 0.0860\n",
      "Epoch 2696/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2697/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2698/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0057 - val_loss: 0.0860\n",
      "Epoch 2699/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2700/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2701/3000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2702/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2703/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2704/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2705/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2706/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2707/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2708/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2709/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2710/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2711/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2712/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2713/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2714/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2715/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2716/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2717/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2718/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2719/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2720/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2721/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2722/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2723/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2724/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2725/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2726/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2727/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2728/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2729/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2730/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2731/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2732/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2733/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2734/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2735/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2736/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2737/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2738/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2739/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2740/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2741/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2742/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2743/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2744/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2745/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2746/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2747/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2748/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2749/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2750/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2751/3000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2752/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2753/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2754/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2755/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2756/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2757/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2758/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2759/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2760/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2761/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2762/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0057 - val_loss: 0.0861\n",
      "Epoch 2763/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0056 - val_loss: 0.0861\n",
      "Epoch 2764/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0056 - val_loss: 0.0861\n",
      "Epoch 2765/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0056 - val_loss: 0.0861\n",
      "Epoch 2766/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0056 - val_loss: 0.0861\n",
      "Epoch 2767/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0056 - val_loss: 0.0861\n",
      "Epoch 2768/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0056 - val_loss: 0.0861\n",
      "Epoch 2769/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0056 - val_loss: 0.0861\n",
      "Epoch 2770/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0056 - val_loss: 0.0861\n",
      "Epoch 2771/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0056 - val_loss: 0.0861\n",
      "Epoch 2772/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0056 - val_loss: 0.0861\n",
      "Epoch 2773/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0056 - val_loss: 0.0861\n",
      "Epoch 2774/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0056 - val_loss: 0.0861\n",
      "Epoch 2775/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0056 - val_loss: 0.0861\n",
      "Epoch 2776/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0056 - val_loss: 0.0861\n",
      "Epoch 2777/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0056 - val_loss: 0.0861\n",
      "Epoch 2778/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0056 - val_loss: 0.0861\n",
      "Epoch 2779/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0056 - val_loss: 0.0860\n",
      "Epoch 2780/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0056 - val_loss: 0.0861\n",
      "Epoch 2781/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0056 - val_loss: 0.0860\n",
      "Epoch 2782/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0056 - val_loss: 0.0862\n",
      "Epoch 2783/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0056 - val_loss: 0.0860\n",
      "Epoch 2784/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0056 - val_loss: 0.0863\n",
      "Epoch 2785/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0056 - val_loss: 0.0859\n",
      "Epoch 2786/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0056 - val_loss: 0.0864\n",
      "Epoch 2787/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0056 - val_loss: 0.0858\n",
      "Epoch 2788/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0056 - val_loss: 0.0865\n",
      "Epoch 2789/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0057 - val_loss: 0.0856\n",
      "Epoch 2790/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0057 - val_loss: 0.0868\n",
      "Epoch 2791/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0057 - val_loss: 0.0854\n",
      "Epoch 2792/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0058 - val_loss: 0.0872\n",
      "Epoch 2793/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0059 - val_loss: 0.0852\n",
      "Epoch 2794/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0060 - val_loss: 0.0872\n",
      "Epoch 2795/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0059 - val_loss: 0.0853\n",
      "Epoch 2796/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0059 - val_loss: 0.0866\n",
      "Epoch 2797/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0057 - val_loss: 0.0858\n",
      "Epoch 2798/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0056 - val_loss: 0.0858\n",
      "Epoch 2799/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0056 - val_loss: 0.0864\n",
      "Epoch 2800/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0057 - val_loss: 0.0853\n",
      "Epoch 2801/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0057 - val_loss: 0.0866\n",
      "Epoch 2802/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0057 - val_loss: 0.0856\n",
      "Epoch 2803/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0057 - val_loss: 0.0860\n",
      "Epoch 2804/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0056 - val_loss: 0.0861\n",
      "Epoch 2805/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0056 - val_loss: 0.0856\n",
      "Epoch 2806/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0056 - val_loss: 0.0863\n",
      "Epoch 2807/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0056 - val_loss: 0.0857\n",
      "Epoch 2808/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0056 - val_loss: 0.0860\n",
      "Epoch 2809/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0056 - val_loss: 0.0860\n",
      "Epoch 2810/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0056 - val_loss: 0.0857\n",
      "Epoch 2811/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0056 - val_loss: 0.0860\n",
      "Epoch 2812/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0056 - val_loss: 0.0857\n",
      "Epoch 2813/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0056 - val_loss: 0.0859\n",
      "Epoch 2814/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0056 - val_loss: 0.0858\n",
      "Epoch 2815/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0056 - val_loss: 0.0858\n",
      "Epoch 2816/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0056 - val_loss: 0.0858\n",
      "Epoch 2817/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0055 - val_loss: 0.0858\n",
      "Epoch 2818/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0055 - val_loss: 0.0858\n",
      "Epoch 2819/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0056 - val_loss: 0.0858\n",
      "Epoch 2820/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0055 - val_loss: 0.0859\n",
      "Epoch 2821/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0055 - val_loss: 0.0857\n",
      "Epoch 2822/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0055 - val_loss: 0.0859\n",
      "Epoch 2823/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0055 - val_loss: 0.0857\n",
      "Epoch 2824/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0055 - val_loss: 0.0857\n",
      "Epoch 2825/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0055 - val_loss: 0.0859\n",
      "Epoch 2826/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0055 - val_loss: 0.0856\n",
      "Epoch 2827/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0055 - val_loss: 0.0859\n",
      "Epoch 2828/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0054 - val_loss: 0.0858\n",
      "Epoch 2829/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0055 - val_loss: 0.0857\n",
      "Epoch 2830/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0055 - val_loss: 0.0859\n",
      "Epoch 2831/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0054 - val_loss: 0.0856\n",
      "Epoch 2832/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0054 - val_loss: 0.0858\n",
      "Epoch 2833/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0054 - val_loss: 0.0857\n",
      "Epoch 2834/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0054 - val_loss: 0.0857\n",
      "Epoch 2835/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0054 - val_loss: 0.0859\n",
      "Epoch 2836/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0054 - val_loss: 0.0857\n",
      "Epoch 2837/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0054 - val_loss: 0.0859\n",
      "Epoch 2838/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0054 - val_loss: 0.0858\n",
      "Epoch 2839/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0054 - val_loss: 0.0858\n",
      "Epoch 2840/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0054 - val_loss: 0.0859\n",
      "Epoch 2841/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0054 - val_loss: 0.0857\n",
      "Epoch 2842/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0054 - val_loss: 0.0859\n",
      "Epoch 2843/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0054 - val_loss: 0.0857\n",
      "Epoch 2844/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0054 - val_loss: 0.0858\n",
      "Epoch 2845/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0054 - val_loss: 0.0858\n",
      "Epoch 2846/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0054 - val_loss: 0.0857\n",
      "Epoch 2847/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0054 - val_loss: 0.0858\n",
      "Epoch 2848/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0054 - val_loss: 0.0858\n",
      "Epoch 2849/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0054 - val_loss: 0.0858\n",
      "Epoch 2850/3000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0054 - val_loss: 0.0858\n",
      "Epoch 2851/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0054 - val_loss: 0.0858\n",
      "Epoch 2852/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0054 - val_loss: 0.0858\n",
      "Epoch 2853/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0054 - val_loss: 0.0858\n",
      "Epoch 2854/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0054 - val_loss: 0.0858\n",
      "Epoch 2855/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0054 - val_loss: 0.0858\n",
      "Epoch 2856/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0054 - val_loss: 0.0858\n",
      "Epoch 2857/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0054 - val_loss: 0.0858\n",
      "Epoch 2858/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0054 - val_loss: 0.0858\n",
      "Epoch 2859/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0054 - val_loss: 0.0858\n",
      "Epoch 2860/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0054 - val_loss: 0.0859\n",
      "Epoch 2861/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0054 - val_loss: 0.0859\n",
      "Epoch 2862/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0053 - val_loss: 0.0859\n",
      "Epoch 2863/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0054 - val_loss: 0.0859\n",
      "Epoch 2864/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2865/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2866/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2867/3000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2868/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0053 - val_loss: 0.0859\n",
      "Epoch 2869/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0053 - val_loss: 0.0859\n",
      "Epoch 2870/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0053 - val_loss: 0.0859\n",
      "Epoch 2871/3000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0053 - val_loss: 0.0859\n",
      "Epoch 2872/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0053 - val_loss: 0.0859\n",
      "Epoch 2873/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0053 - val_loss: 0.0859\n",
      "Epoch 2874/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2875/3000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2876/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2877/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2878/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2879/3000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2880/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2881/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2882/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2883/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2884/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2885/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2886/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2887/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2888/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2889/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2890/3000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2891/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2892/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2893/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2894/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2895/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2896/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2897/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2898/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2899/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2900/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2901/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2902/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2903/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2904/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2905/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2906/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2907/3000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2908/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2909/3000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2910/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2911/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2912/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2913/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2914/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2915/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2916/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2917/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2918/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2919/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2920/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2921/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2922/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2923/3000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2924/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2925/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2926/3000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2927/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2928/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2929/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2930/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2931/3000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2932/3000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2933/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2934/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2935/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2936/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2937/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2938/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2939/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2940/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2941/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2942/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2943/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2944/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2945/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2946/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2947/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2948/3000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2949/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2950/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2951/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0053 - val_loss: 0.0859\n",
      "Epoch 2952/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2953/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0053 - val_loss: 0.0859\n",
      "Epoch 2954/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0053 - val_loss: 0.0859\n",
      "Epoch 2955/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0053 - val_loss: 0.0859\n",
      "Epoch 2956/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2957/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2958/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2959/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2960/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2961/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2962/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2963/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0053 - val_loss: 0.0858\n",
      "Epoch 2964/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0052 - val_loss: 0.0858\n",
      "Epoch 2965/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0052 - val_loss: 0.0858\n",
      "Epoch 2966/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0053 - val_loss: 0.0859\n",
      "Epoch 2967/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0052 - val_loss: 0.0858\n",
      "Epoch 2968/3000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0052 - val_loss: 0.0858\n",
      "Epoch 2969/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0052 - val_loss: 0.0858\n",
      "Epoch 2970/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0052 - val_loss: 0.0858\n",
      "Epoch 2971/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0052 - val_loss: 0.0858\n",
      "Epoch 2972/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0052 - val_loss: 0.0858\n",
      "Epoch 2973/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0052 - val_loss: 0.0858\n",
      "Epoch 2974/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0052 - val_loss: 0.0858\n",
      "Epoch 2975/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0052 - val_loss: 0.0858\n",
      "Epoch 2976/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0052 - val_loss: 0.0858\n",
      "Epoch 2977/3000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0052 - val_loss: 0.0858\n",
      "Epoch 2978/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0052 - val_loss: 0.0858\n",
      "Epoch 2979/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0052 - val_loss: 0.0858\n",
      "Epoch 2980/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0052 - val_loss: 0.0858\n",
      "Epoch 2981/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0052 - val_loss: 0.0858\n",
      "Epoch 2982/3000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0052 - val_loss: 0.0858\n",
      "Epoch 2983/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0052 - val_loss: 0.0858\n",
      "Epoch 2984/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0052 - val_loss: 0.0859\n",
      "Epoch 2985/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0052 - val_loss: 0.0858\n",
      "Epoch 2986/3000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0052 - val_loss: 0.0859\n",
      "Epoch 2987/3000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0052 - val_loss: 0.0858\n",
      "Epoch 2988/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0052 - val_loss: 0.0859\n",
      "Epoch 2989/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0052 - val_loss: 0.0857\n",
      "Epoch 2990/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0052 - val_loss: 0.0860\n",
      "Epoch 2991/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0052 - val_loss: 0.0857\n",
      "Epoch 2992/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0052 - val_loss: 0.0860\n",
      "Epoch 2993/3000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0052 - val_loss: 0.0856\n",
      "Epoch 2994/3000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0052 - val_loss: 0.0861\n",
      "Epoch 2995/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0053 - val_loss: 0.0855\n",
      "Epoch 2996/3000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0053 - val_loss: 0.0863\n",
      "Epoch 2997/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0053 - val_loss: 0.0854\n",
      "Epoch 2998/3000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0053 - val_loss: 0.0865\n",
      "Epoch 2999/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0054 - val_loss: 0.0853\n",
      "Epoch 3000/3000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0054 - val_loss: 0.0867\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "3/3 [==============================] - 0s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "def process_images(image_paths, image_size=(64, 64), color_mode='grayscale'):\n",
    "    images = []\n",
    "    for filename in os.listdir(image_paths):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):  # Check for image files\n",
    "            img_path = os.path.join(image_paths, filename)\n",
    "            # Load the image in grayscale mode\n",
    "            img = load_img(img_path, color_mode=color_mode, target_size=image_size)\n",
    "            # Convert the image to an array\n",
    "            img_array = img_to_array(img)\n",
    "            # Normalize the image\n",
    "\n",
    "\n",
    "            img_array = img_array / 255.0\n",
    "            # Flatten the image array if needed\n",
    "            # img_array = img_array.reshape(-1)\n",
    "            images.append(img_array)\n",
    "    return np.array(images)\n",
    "\n",
    "heisenberg_Real_images = process_images(\"data/heisenberg_heisenberg/gernot\")\n",
    "heisenberg_BB_images = process_images(\"data/heisenberg_heisenberg/walter\")\n",
    "\n",
    "all_images = np.concatenate([heisenberg_Real_images, heisenberg_BB_images], axis=0)\n",
    "all_images_flat = all_images.reshape(all_images.shape[0], -1)\n",
    "\n",
    "train_x, val_x = train_test_split(all_images_flat, test_size=0.1, random_state=42)\n",
    "\n",
    "# build the auto-encoding layers\n",
    "autoencoder = Sequential()\n",
    "autoencoder.add(Dense(1024,  activation='elu', input_shape=(64*64,)))\n",
    "autoencoder.add(Dense(2048,  activation='elu'))\n",
    "autoencoder.add(Dense(1024,  activation='elu'))\n",
    "autoencoder.add(Dense(512,  activation='elu'))\n",
    "autoencoder.add(Dense(128,  activation='elu'))\n",
    "autoencoder.add(Dense(10,   activation='linear', name=\"bottleneck\"))\n",
    "autoencoder.add(Dense(128,  activation='elu'))\n",
    "autoencoder.add(Dense(512,  activation='elu'))\n",
    "autoencoder.add(Dense(1024,  activation='elu'))\n",
    "autoencoder.add(Dense(2048,  activation='elu'))\n",
    "autoencoder.add(Dense(64*64,  activation='sigmoid'))\n",
    "autoencoder.compile(loss='mean_squared_error', optimizer = Adam())\n",
    "\n",
    "'''\n",
    "NOTE:\n",
    "-----\n",
    "The Exponential Linear Unit (ELU) is an activation function for neural networks. \n",
    "In contrast to ReLUs (which you know), ELUs have negative values which allows them to push mean unit \n",
    "activations closer to zero like batch normalization but with lower computational complexity.\n",
    "'''    \n",
    "\n",
    "# train the model and finally assign the encoding to the decoder\n",
    "'''\n",
    "NOTE:\n",
    "-----\n",
    "make sure you understand, that you are training on train_x and not on train_y but train_x again for the reconstruction\n",
    "the same for the validation (val_x, val_x)\n",
    "'''\n",
    "trained_model = autoencoder.fit(\n",
    "    train_x, train_x, # Notice we use train_x for both input and output\n",
    "    batch_size=1024,\n",
    "    epochs=3000,\n",
    "    verbose=1,\n",
    "    validation_data=(val_x, val_x), # Notice we use val_x for both validation input and output\n",
    "    shuffle=True\n",
    ")\n",
    "encoder = Model(autoencoder.input, autoencoder.get_layer('bottleneck').output)\n",
    "\n",
    "encoded_data = encoder.predict(train_x)  # bottleneck representation\n",
    "\n",
    "decoded_output = autoencoder.predict(train_x)        # reconstruction\n",
    "encoding_dim = 10\n",
    "\n",
    "# return the decoder\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder = autoencoder.layers[-5](encoded_input)\n",
    "decoder = autoencoder.layers[-4](decoder)\n",
    "decoder = autoencoder.layers[-3](decoder)\n",
    "decoder = autoencoder.layers[-2](decoder)\n",
    "decoder = autoencoder.layers[-1](decoder)\n",
    "decoder = Model(encoded_input, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e146f1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Wählen Sie ein zufälliges Encoding aus, das Sie visualisieren möchten\n",
    "random_index = np.random.randint(len(encoded_data))\n",
    "sample_encoding = encoded_data[random_index].reshape(1, -1)\n",
    "\n",
    "# Verwenden Sie das Decoder-Modell, um das Bild zu rekonstruieren\n",
    "reconstructed_image = decoder.predict(sample_encoding)\n",
    "\n",
    "print\n",
    "# Bringen Sie das Bild in die ursprüngliche Form (28x28 Pixel)\n",
    "reconstructed_image = reconstructed_image.reshape(64, 64)\n",
    "\n",
    "# Visualisieren Sie das rekonstruierte Bild\n",
    "plt.imshow(reconstructed_image, cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
